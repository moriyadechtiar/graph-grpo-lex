{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9648ba0",
      "metadata": {
        "id": "e9648ba0"
      },
      "source": [
        "# Gated GRPO Training Contract2Graph Pipeline— VM‑Optimized (A100‑80GB)\n",
        "\n",
        "\n",
        "This notebook runs **GRPO** on top of our **SFT** adapter for *Llama‑3.1‑8B‑Instruct* on a A100‑80GB VM.  \n",
        "It logs to **Weights & Biases**, supports **resume / autosave**, **JSON-brace stopping** for efficient generation, and a gated GRPO approach.\n",
        "\n",
        "**Folders used**\n",
        "- SFT adapter: `~/ai/checkpoints/run14_2025-08-25_22-37/final/`\n",
        "- GRPO checkpoints/logs/outputs: `~/ai/checkpoints/run14_2025-08-25_22-37_grpo/`, `~/ai/logs/run14_2025-08-25_22-37_grpo/`, `~/ai/outputs/run14_2025-08-25_22-37_grpo/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b22ed25-f114-4ffe-b19f-5cc1248929d2",
      "metadata": {
        "id": "0b22ed25-f114-4ffe-b19f-5cc1248929d2",
        "outputId": "7f4b2afc-3ccf-44fc-cc13-46fa66f96370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flash-attn==2.5.8 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (2.5.8)\n",
            "Requirement already satisfied: torch in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from flash-attn==2.5.8) (2.3.0)\n",
            "Requirement already satisfied: einops in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from flash-attn==2.5.8) (0.8.1)\n",
            "Requirement already satisfied: packaging in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from flash-attn==2.5.8) (25.0)\n",
            "Requirement already satisfied: ninja in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from flash-attn==2.5.8) (1.13.0)\n",
            "Requirement already satisfied: filelock in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (4.14.1)\n",
            "Requirement already satisfied: sympy in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (1.13.1)\n",
            "Requirement already satisfied: networkx in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch->flash-attn==2.5.8) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn==2.5.8) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from jinja2->torch->flash-attn==2.5.8) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sympy->torch->flash-attn==2.5.8) (1.3.0)\n",
            "Requirement already satisfied: sentence-transformers in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (4.55.4)\n",
            "Requirement already satisfied: tqdm in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
            "Requirement already satisfied: scipy in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
            "Requirement already satisfied: requests in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
            "Requirement already satisfied: sympy in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "\n",
            "\n",
            "✅ Flash Attention installed. PLEASE RESTART THE KERNEL NOW.\n",
            "--> In the menu, go to Kernel > Restart Kernel...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === [Cell] 0 · System Setup & Dependencies ===\n",
        "# This cell should be run FIRST, and the kernel restarted immediately after.\n",
        "\n",
        "# We only need to install flash-attn\n",
        "# The --no-build-isolation flag helps it find your existing torch installation\n",
        "!pip install \"flash-attn==2.5.8\" --no-build-isolation\n",
        "!pip install sentence-transformers\n",
        "\n",
        "print(\"\\n\\n✅ Flash Attention installed. PLEASE RESTART THE KERNEL NOW.\")\n",
        "print(\"--> In the menu, go to Kernel > Restart Kernel...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "544e11d2-d64d-4de1-83ea-9238c9f1fc97",
      "metadata": {
        "id": "544e11d2-d64d-4de1-83ea-9238c9f1fc97",
        "outputId": "4aee6fb9-2e02-4122-d3d5-cfa4ca751f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU free/total before load: 69.2/85.0 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "free, total = torch.cuda.mem_get_info()\n",
        "print(f\"GPU free/total before load: {free/1e9:.1f}/{total/1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75aec493",
      "metadata": {
        "id": "75aec493",
        "outputId": "73444768-9366-4593-89e2-b2ce9b479a1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/ubuntu/ai/env/miniconda/envs/llm/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find GRPO_training_minigraph_builder_vm_FINAL.ipynb.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoriya-dechtiar\u001b[0m (\u001b[33mm-dechtiar\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ubuntu/ai/wandb/wandb/run-20250923_183241-myi6m8f3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval/runs/myi6m8f3' target=\"_blank\">ai_grpo_2025-09-23_18-32</a></strong> to <a href='https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval' target=\"_blank\">https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval/runs/myi6m8f3' target=\"_blank\">https://wandb.ai/m-dechtiar/llama31_grpo_minigraph_customReward_customEval/runs/myi6m8f3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CKPT: /home/ubuntu/ai/checkpoints/ai_grpo\n",
            "LOG: /home/ubuntu/ai/logs/ai_grpo\n",
            "OUT: /home/ubuntu/ai/outputs/ai_grpo\n"
          ]
        }
      ],
      "source": [
        "# === [Cell] 1 · VM init (paths, caches, W&B) ===\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import os, wandb\n",
        "\n",
        "HF_DATASET_ID=\"moriyad/clause_minigraph_builder_grpo\"\n",
        "\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"  # before importing transformers logs\n",
        "from transformers.utils import logging as hf_logging\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Caching is incompatible with gradient checkpointing*\", module=\"transformers.models.llama.modeling_llama\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"`use_cache=True` is incompatible with gradient checkpointing*\")\n",
        "\n",
        "BASE = Path.home() / \"ai\"\n",
        "for d in [\"checkpoints\",\"logs\",\"outputs\",\"wandb\",\"hf_cache\",\"hf_datasets_cache\",\"hf_transformers_cache\"]:\n",
        "    (BASE/d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SFT_RUN_DIR = Path(\"~/ai\").expanduser()\n",
        "#MODEL_DIR   = (SFT_RUN_DIR / \"adapter-20250827-142825\") original SFT run\n",
        "CKPT_DIR    = BASE / \"checkpoints\" / (SFT_RUN_DIR.name + \"_grpo\")\n",
        "LOG_DIR     = BASE / \"logs\" / (SFT_RUN_DIR.name + \"_grpo\")\n",
        "OUT_DIR     = BASE / \"outputs\" / (SFT_RUN_DIR.name + \"_grpo\")\n",
        "for p in (CKPT_DIR, LOG_DIR, OUT_DIR): p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"GRPO_training_minigraph_builder_vm_FINAL.ipynb\"\n",
        "os.environ.setdefault(\"HF_HOME\", str(BASE / \"hf_cache\"))\n",
        "os.environ.setdefault(\"HF_DATASETS_CACHE\", str(BASE / \"hf_datasets_cache\"))\n",
        "os.environ.setdefault(\"TRANSFORMERS_CACHE\", str(BASE / \"hf_transformers_cache\"))\n",
        "os.environ.setdefault(\"WANDB_DIR\", str(BASE / \"wandb\"))\n",
        "os.environ.setdefault(\"WANDB_CACHE_DIR\", str(BASE / \"wandb/cache\"))\n",
        "os.environ.setdefault(\"WANDB_PROJECT\", \"llama31_grpo_minigraph_customReward_customEval\")\n",
        "\n",
        "try: wandb.finish()\n",
        "except: pass\n",
        "wandb.login()\n",
        "run_id = f\"{SFT_RUN_DIR.name}_grpo_{datetime.now().strftime('%Y-%m-%d_%H-%M')}\"\n",
        "wandb.init(project=os.environ[\"WANDB_PROJECT\"], name=run_id, reinit=True, config={\"sft_run\": str(SFT_RUN_DIR)})\n",
        "print(\"CKPT:\", CKPT_DIR); print(\"LOG:\", LOG_DIR); print(\"OUT:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c87e2a92-baae-4d2f-9a8b-319901727252",
      "metadata": {
        "id": "c87e2a92-baae-4d2f-9a8b-319901727252"
      },
      "outputs": [],
      "source": [
        "#[Cell] 2 - Load base model (4-bit) with FLASH ATTN + apply SFT adapter (GPU-pinned, safe fallbacks) ===\n",
        "import os, torch, wandb\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "BASE_MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "#MODEL_DIR   = (SFT_RUN_DIR / \"adapter-20250827-142825\") #- Original SFT qlora model\n",
        "MODEL_DIR   = (SFT_RUN_DIR / \"notebooks/checkpoints/grpo_final_embed_stopper_gated_final\") #from latest checkpoint\n",
        "#4-bit NF4 on A100\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "#Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token or tokenizer.pad_token\n",
        "\n",
        "def _print_gpu():\n",
        "    try:\n",
        "        free, total = torch.cuda.mem_get_info()\n",
        "        print(f\"GPU free/total: {free/1e9:.1f} / {total/1e9:.1f} GB\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"Loading base model (4-bit) with FlashAttention-2…\")\n",
        "_print_gpu()\n",
        "\n",
        "common_kwargs = dict(\n",
        "    quantization_config=bnb,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=\"flash_attention_2\",   # <<<< ENABLE FA2\n",
        ")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL_ID,\n",
        "        device_map={\"\": \"cuda:0\"},\n",
        "        **common_kwargs,\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(\"[Retry] memory-constrained auto mapping… Reason:\", e)\n",
        "    try:\n",
        "        max_mem = {0: \"78GiB\", \"cpu\": \"0GiB\"}\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL_ID,\n",
        "            device_map=\"auto\",\n",
        "            max_memory=max_mem,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "    except ValueError as e2:\n",
        "        print(\"[Retry] CPU offload last resort… Reason:\", e2)\n",
        "        offload_dir = os.path.join(os.getcwd(), \"offload\")\n",
        "        os.makedirs(offload_dir, exist_ok=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL_ID,\n",
        "            device_map=\"auto\",\n",
        "            offload_folder=offload_dir,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "\n",
        "#special tokens and resize embeddings\n",
        "try:\n",
        "    eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    if eot_id is None or eot_id == tokenizer.unk_token_id:\n",
        "        tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<|eot_id|>\"]})\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "        eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "except Exception:\n",
        "    eot_id = None\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Applying SFT adapter from\", MODEL_DIR)\n",
        "model = PeftModel.from_pretrained(model, MODEL_DIR, is_trainable=True)\n",
        "\n",
        "#perf & training\n",
        "#use_cache=False for training\n",
        "model.config.use_cache = False\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "#enabled for training only\n",
        "try:\n",
        "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
        "except TypeError:\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "_print_gpu()\n",
        "print(\"Model ready (FA2, 4-bit NF4).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f964dc5a-1218-4d4c-8c68-9fc31282f1df",
      "metadata": {
        "id": "f964dc5a-1218-4d4c-8c68-9fc31282f1df",
        "outputId": "038f8950-efc1-494c-c5b0-2c92f9dbf309"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval-only model ready (FA2, 4-bit NF4, adapters frozen).\n"
          ]
        }
      ],
      "source": [
        "#[Cell] 2b Alternative for Eval-only setup (not for training)\n",
        "import os, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "BASE_MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "MODEL_DIR     = (SFT_RUN_DIR / \"notebooks/checkpoints/grpo_final_embed_stopper_gated_final\")\n",
        "\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token or tokenizer.pad_token\n",
        "\n",
        "common_kwargs = dict(\n",
        "    quantization_config=bnb,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    device_map={\"\": \"cuda:0\"},\n",
        "    **common_kwargs,\n",
        ")\n",
        "\n",
        "try:\n",
        "    eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    if eot_id is None or eot_id == tokenizer.unk_token_id:\n",
        "        tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<|eot_id|>\"]})\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "model = PeftModel.from_pretrained(model, MODEL_DIR, is_trainable=False)\n",
        "\n",
        "model.config.use_cache = True\n",
        "model.eval()\n",
        "try:\n",
        "    model.gradient_checkpointing_disable()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "print(\"Eval-only model ready (FA2, 4-bit NF4, adapters frozen).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db9d0a7-899c-4eeb-9fc0-07b88e25e5ff",
      "metadata": {
        "id": "5db9d0a7-899c-4eeb-9fc0-07b88e25e5ff"
      },
      "outputs": [],
      "source": [
        "#[Cell] 2b - evaluation helpers and execution\n",
        "import json, gc, re, numpy as np\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "#helpers\n",
        "def _safe_eos_ids(tok):\n",
        "    ids = []\n",
        "    for t in [\"<|eot_id|>\", \"<|eos|>\", tok.eos_token]:\n",
        "        if not t: continue\n",
        "        try:\n",
        "            i = tok.convert_tokens_to_ids(t) if isinstance(t, str) else t\n",
        "            if i is not None and i != tok.unk_token_id: ids.append(i)\n",
        "        except: pass\n",
        "    if tok.eos_token_id is not None: ids.append(tok.eos_token_id)\n",
        "    seen=set(); out=[]\n",
        "    for i in ids:\n",
        "        if i not in seen: seen.add(i); out.append(i)\n",
        "    return out or [tok.eos_token_id]\n",
        "\n",
        "class JsonStopper(StoppingCriteria):\n",
        "    \"\"\"Stop when top-level braces look balanced (quick & dirty).\"\"\"\n",
        "    def __init__(self, tokenizer, input_len):\n",
        "        self.tok = tokenizer; self.input_len = input_len\n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        s = self.tok.decode(input_ids[0, self.input_len:], skip_special_tokens=True)\n",
        "        return s.count('{')>0 and s.count('{')==s.count('}')\n",
        "\n",
        "def _deep_safe_json(x, max_depth=3):\n",
        "    obj = x\n",
        "    for _ in range(max_depth):\n",
        "        if isinstance(obj, (dict, list)): return obj\n",
        "        if obj is None: return {}\n",
        "        s = str(obj).strip()\n",
        "        b, e = s.find(\"{\"), s.rfind(\"}\")\n",
        "        cand = s[b:e+1] if (b != -1 and e != -1 and e > b) else s\n",
        "        try:\n",
        "            obj = json.loads(cand); continue\n",
        "        except Exception:\n",
        "            break\n",
        "    return {}\n",
        "\n",
        "def _extract_nodes(obj):\n",
        "    arr = obj.get(\"nodes\", []) if isinstance(obj, dict) else []\n",
        "    if isinstance(arr, dict): arr = [arr]\n",
        "    out=[]\n",
        "    for it in arr:\n",
        "        if isinstance(it, dict): out.append(it)\n",
        "        elif isinstance(it, str):\n",
        "            try:\n",
        "                d = json.loads(it)\n",
        "                if isinstance(d, dict): out.append(d)\n",
        "            except: pass\n",
        "    return out\n",
        "\n",
        "def _extract_edges(obj):\n",
        "    arr = obj.get(\"edges\", []) if isinstance(obj, dict) else []\n",
        "    if isinstance(arr, dict): arr = [arr]\n",
        "    out=[]\n",
        "    for it in arr:\n",
        "        if isinstance(it, dict): out.append(it)\n",
        "        elif isinstance(it, str):\n",
        "            try:\n",
        "                d = json.loads(it)\n",
        "                if isinstance(d, dict): out.append(d)\n",
        "            except: pass\n",
        "    return out\n",
        "\n",
        "COMPANY_SUFFIX_RE = re.compile(r\"\\b(inc\\.?|ltd\\.?|llc|l\\.l\\.c\\.|corp\\.?|co\\.?|ag|gmbh)\\b\", re.I)\n",
        "WS_RE = re.compile(r\"\\s+\")\n",
        "def _norm(s):\n",
        "    if not isinstance(s, str): s = str(s) if s is not None else \"\"\n",
        "    s = s.lower().replace(\"&\",\"and\")\n",
        "    s = COMPANY_SUFFIX_RE.sub(\"\", s)\n",
        "    return WS_RE.sub(\" \", s).strip()\n",
        "\n",
        "def _toks(s): return re.findall(r\"[a-z0-9]+\", s.lower())\n",
        "def _jacc(a,b):\n",
        "    sa,sb=set(_toks(a)),set(_toks(b))\n",
        "    if not sa or not sb: return 1.0 if a.strip()==b.strip() and a.strip()!=\"\" else 0.0\n",
        "    return len(sa&sb)/max(1,len(sa|sb))\n",
        "\n",
        "PCT_RE=re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*%\"); MONEY_RE=re.compile(r\"(\\$|usd)\\s*([\\d,]+(?:\\.\\d+)?)\",re.I)\n",
        "DAYS_RE=re.compile(r\"(\\d+)\\s*days?\"); YEARS_RE=re.compile(r\"(\\d+)\\s*years?\")\n",
        "NUM_WORDS={\"zero\":0,\"one\":1,\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"seven\":7,\"eight\":8,\"nine\":9,\n",
        "           \"ten\":10,\"eleven\":11,\"twelve\":12,\"thirteen\":13,\"fourteen\":14,\"fifteen\":15,\"sixteen\":16,\n",
        "           \"seventeen\":17,\"eighteen\":18,\"nineteen\":19,\"twenty\":20,\"thirty\":30,\"forty\":40,\"fifty\":50,\n",
        "           \"sixty\":60,\"seventy\":70,\"eighty\":80,\"ninety\":90}\n",
        "def _w2n(s):\n",
        "    s=s.lower()\n",
        "    for w,n in NUM_WORDS.items():\n",
        "        if re.search(rf\"\\b{w}\\b\", s): return n\n",
        "    return None\n",
        "\n",
        "def _canon_value(text):\n",
        "    s=_norm(text)\n",
        "    m=PCT_RE.search(s)\n",
        "    if m: return f\"{float(m.group(1)):.0f}%\"\n",
        "    if \"percent\" in s:\n",
        "        n=_w2n(s)\n",
        "        if n is not None: return f\"{n}%\"\n",
        "    m=MONEY_RE.search(s)\n",
        "    if m: return f\"usd {m.group(2).replace(',','')}\"\n",
        "    m=DAYS_RE.search(s)\n",
        "    if m: return f\"{int(m.group(1))} days\"\n",
        "    m=YEARS_RE.search(s)\n",
        "    if m: return f\"{int(m.group(1))} years\"\n",
        "    return s\n",
        "\n",
        "def _keytext(n):\n",
        "    t=(n.get(\"type\") or \"\").upper(); a=n.get(\"attrs\",{}) or {}; nid=n.get(\"id\",\"\") or \"\"\n",
        "    if t==\"CLAUSE\":\n",
        "        k=a.get(\"id\") or nid or a.get(\"title\") or \"\"; return t,_norm(k)\n",
        "    if t==\"DEFINED_TERM\":\n",
        "        k=a.get(\"term\") or nid.split(\":\",1)[-1]; return t,_norm(k)\n",
        "    if t==\"PARTY\":\n",
        "        k=a.get(\"name\") or a.get(\"text\") or nid.split(\":\",1)[-1]; return t,_norm(k)\n",
        "    if t==\"VALUE\":\n",
        "        k=a.get(\"text\") or nid.split(\":\",1)[-1]; return t,_canon_value(k)\n",
        "    k=a.get(\"text\") or a.get(\"term\") or a.get(\"name\") or nid; return t,_norm(k)\n",
        "\n",
        "THRESH={\"CLAUSE\":0.90,\"DEFINED_TERM\":0.80,\"PARTY\":0.85,\"VALUE\":0.75}\n",
        "def _sim(t,a,b):\n",
        "    if t==\"CLAUSE\": return 1.0 if a==b else _jacc(a,b)\n",
        "    if t in (\"DEFINED_TERM\",\"PARTY\"): return _jacc(a,b)\n",
        "    if t==\"VALUE\":\n",
        "        if a==b and (a.endswith(\"%\") or a.endswith(\"days\") or a.endswith(\"years\") or a.startswith(\"usd\")): return 1.0\n",
        "        return _jacc(a,b)\n",
        "    return _jacc(a,b)\n",
        "\n",
        "def _bucket(nodes):\n",
        "    b=defaultdict(list)\n",
        "    for n in nodes:\n",
        "        t,kt=_keytext(n)\n",
        "        if t and kt: b[t].append(kt)\n",
        "    return b\n",
        "\n",
        "def _match_type(G_list, P_list, t):\n",
        "    if not G_list or not P_list: return 0\n",
        "    pairs=[]\n",
        "    for i,g in enumerate(G_list):\n",
        "        for j,p in enumerate(P_list):\n",
        "            s=_sim(t,g,p)\n",
        "            if s>=THRESH.get(t,0.8): pairs.append((s,i,j))\n",
        "    pairs.sort(reverse=True)\n",
        "    used_i=set(); used_j=set(); tp=0\n",
        "    for s,i,j in pairs:\n",
        "        if i in used_i or j in used_j: continue\n",
        "        used_i.add(i); used_j.add(j); tp+=1\n",
        "    return tp\n",
        "\n",
        "def _edge_triplet(e, node_map):\n",
        "    def pick(d, keys):\n",
        "        for k in keys:\n",
        "            if k in d and d[k] is not None:\n",
        "                return d[k]\n",
        "        return None\n",
        "    typ = (pick(e, [\"type\",\"edge_type\",\"label\"]) or \"\").upper()\n",
        "    raw_src = pick(e, [\"src\",\"source\",\"from\"])\n",
        "    raw_tgt = pick(e, [\"tgt\",\"target\",\"to\"])\n",
        "    def resolve(v):\n",
        "        if v is None: return \"\"\n",
        "        v_str = str(v)\n",
        "        if v_str in node_map:\n",
        "            return node_map[v_str]\n",
        "        return _norm(v_str)\n",
        "    return (resolve(raw_src), typ, resolve(raw_tgt))\n",
        "\n",
        "def _prf1(tp,fp,fn):\n",
        "    p=tp/(tp+fp) if (tp+fp) else 0.0\n",
        "    r=tp/(tp+fn) if (tp+fn) else 0.0\n",
        "    f=2*p*r/(p+r) if (p+r) else 0.0\n",
        "    return p,r,f\n",
        "\n",
        "#eval\n",
        "def evaluate_model(model, tokenizer, dataset, system_prompt, max_samples=200, batch_size=4, max_new_tokens=1024):\n",
        "    \"\"\"dataset must have columns: 'prompt' and 'completion' (or 'clean_completion').\"\"\"\n",
        "    #examples\n",
        "    n = len(dataset)\n",
        "    use = min(max_samples, n)\n",
        "    idxs = np.random.choice(n, use, replace=False) if use < n else np.arange(n)\n",
        "    sub = dataset.select(idxs)\n",
        "    prompts = sub[\"prompt\"]\n",
        "    gold_key = \"clean_completion\" if \"clean_completion\" in sub.column_names else \"completion\"\n",
        "    golds = sub[gold_key]\n",
        "\n",
        "    #generation\n",
        "    tok = tokenizer\n",
        "    old_pad, old_trunc = tok.padding_side, getattr(tok, \"truncation_side\", \"right\")\n",
        "    tok.padding_side = tok.truncation_side = \"left\"\n",
        "    if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "    EOS = _safe_eos_ids(tok); PAD = tok.pad_token_id or tok.eos_token_id\n",
        "\n",
        "    preds=[]\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        chats = [tok.apply_chat_template(\n",
        "                    [{\"role\":\"system\",\"content\": system_prompt},\n",
        "                     {\"role\":\"user\",\"content\": p}],\n",
        "                    tokenize=False, add_generation_prompt=True)\n",
        "                 for p in prompts[i:i+batch_size]]\n",
        "        batch = tok(chats, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "        stopper = StoppingCriteriaList([JsonStopper(tok, input_len=batch[\"input_ids\"].shape[1])])\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(\n",
        "                **batch,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=False, temperature=None, top_p=None, top_k=None,\n",
        "                use_cache=True,\n",
        "                eos_token_id=EOS, pad_token_id=PAD,\n",
        "                stopping_criteria=stopper,\n",
        "            )\n",
        "        gen = tok.batch_decode(out[:, batch[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "        preds.extend(gen)\n",
        "        del out, batch; torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    tok.padding_side, tok.truncation_side = old_pad, old_trunc\n",
        "\n",
        "    #scoring\n",
        "    strict_tp=strict_fp=strict_fn=0\n",
        "    fuzzy_tp=fuzzy_fp=fuzzy_fn=0\n",
        "    e_tp=e_fp=e_fn=0\n",
        "    exact=invalid=0\n",
        "\n",
        "    def setify_strict(nodes):\n",
        "        S=set()\n",
        "        for nn in nodes:\n",
        "            t=(nn.get(\"type\") or \"\").upper(); a=nn.get(\"attrs\",{}) or {}; nid=nn.get(\"id\",\"\") or \"\"\n",
        "            k=a.get(\"name\") or a.get(\"term\") or a.get(\"text\") or nid\n",
        "            k=_norm(k)\n",
        "            if t and k: S.add((t,k))\n",
        "        return S\n",
        "\n",
        "    for gstr,pstr in zip(golds,preds):\n",
        "        G_json=_deep_safe_json(gstr); P_json=_deep_safe_json(pstr)\n",
        "        G_nodes=_extract_nodes(G_json)\n",
        "        try:\n",
        "            P_nodes=_extract_nodes(P_json)\n",
        "        except Exception:\n",
        "            P_nodes=[]; invalid+=1\n",
        "\n",
        "        # strict nodes\n",
        "        Gs, Ps = setify_strict(G_nodes), setify_strict(P_nodes)\n",
        "        if Gs==Ps: exact+=1\n",
        "        strict_tp+=len(Gs&Ps); strict_fp+=len(Ps-Gs); strict_fn+=len(Gs-Ps)\n",
        "\n",
        "        # fuzzy nodes\n",
        "        Gb,Pb=_bucket(G_nodes),_bucket(P_nodes)\n",
        "        for t in (set(Gb)|set(Pb)):\n",
        "            tp=_match_type(Gb.get(t,[]), Pb.get(t,[]), t)\n",
        "            fp=len(Pb.get(t,[]))-tp; fn=len(Gb.get(t,[]))-tp\n",
        "            fuzzy_tp+=tp; fuzzy_fp+=fp; fuzzy_fn+=fn\n",
        "\n",
        "        # edges\n",
        "        def build_map(nodes):\n",
        "            m={}\n",
        "            for n in nodes:\n",
        "                nid=n.get(\"id\") or \"\"\n",
        "                tt=_keytext(n)\n",
        "                if nid: m[str(nid)] = f\"{tt[0]}|{tt[1]}\"\n",
        "            return m\n",
        "        Gmap,Pmap=build_map(G_nodes),build_map(P_nodes)\n",
        "        Ge=set(_edge_triplet(e,Gmap) for e in _extract_edges(G_json))\n",
        "        Pe=set(_edge_triplet(e,Pmap) for e in _extract_edges(P_json))\n",
        "        e_tp+=len(Ge&Pe); e_fp+=len(Pe-Ge); e_fn+=len(Ge-Pe)\n",
        "\n",
        "    sp,sr,sf1 = _prf1(strict_tp,strict_fp,strict_fn)\n",
        "    fp_,fr_,ff1 = _prf1(fuzzy_tp,fuzzy_fp,fuzzy_fn)\n",
        "    ep,er,ef1   = _prf1(e_tp,e_fp,e_fn)\n",
        "\n",
        "    return {\n",
        "        \"gen_strict_micro_precision\": sp,\n",
        "        \"gen_strict_micro_recall\":    sr,\n",
        "        \"gen_strict_micro_f1\":        sf1,\n",
        "        \"gen_fuzzy_micro_precision\":  fp_,\n",
        "        \"gen_fuzzy_micro_recall\":     fr_,\n",
        "        \"gen_fuzzy_micro_f1\":         ff1,\n",
        "        \"gen_edges_micro_precision\":  ep,\n",
        "        \"gen_edges_micro_recall\":     er,\n",
        "        \"gen_edges_micro_f1\":         ef1,\n",
        "        \"gen_exact_match\":            exact/max(1,len(prompts)),\n",
        "        \"gen_invalid_json_rate\":      invalid/max(1,len(prompts)),\n",
        "        \"gen_num_samples\":            len(prompts),\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16339b3a-5498-46a9-aaa0-737891317dd2",
      "metadata": {
        "id": "16339b3a-5498-46a9-aaa0-737891317dd2",
        "outputId": "d070324a-aa5c-440f-da3c-0420f1cc40f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and cleaning the dataset...\n",
            "\n",
            "Parse success (train): 2071/2071 = 100.0%\n",
            "\n",
            "Dataset after cleaning:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'contract_id', 'clause_id', 'prompt', 'completion', 'clean_completion', 'clean_parse_ok'],\n",
            "        num_rows: 2071\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'contract_id', 'clause_id', 'prompt', 'completion', 'clean_completion', 'clean_parse_ok'],\n",
            "        num_rows: 262\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'contract_id', 'clause_id', 'prompt', 'completion', 'clean_completion', 'clean_parse_ok'],\n",
            "        num_rows: 266\n",
            "    })\n",
            "})\n",
            "\n",
            "Example of a cleaned completion:\n",
            "{\"contract_id\": \"AIRSPANNETWORKSINC_04_11_2000-EX-10.5-Distributor Agreement\", \"nodes\": [{\"id\": \"10\", \"title\": \"10\", \"level\": 1, \"type\": \"CLAUSE\", \"attrs\": {\"title\": \"10\"}}, {\"id\": \"10.3\", \"title\": \"10.3\", \"level\": 2, \"type\": \"CLAUSE\", \"attrs\": {\"title\": \"10.3\"}}, {\"id\": \"party:Airspan\", \"name\": \"Airspan\", \"type\": \"PARTY\", \"attrs\": {\"name\": \"Airspan\"}}, {\"id\": \"party:Distributor\", \"name\": \"Distributor\", \"type\": \"PARTY\", \"attrs\": {\"name\": \"Distributor\"}}, {\"id\": \"term:Agreement\", \"name\": \"Agreement\", \"type\": \"DEFINED_TERM\", \"attrs\": {\"name\": \"Agreement\"}}, {\"id\": \"term:Confidential Information\", \"name\": \"Confidential Information\", \"type\": \"DEFINED_TERM\", \"attrs\": {\"name\": \"Confidential Information\"}}], \"edges\": [{\"src\": \"10.3\", \"tgt\": \"10\", \"type\": \"IS_PART_OF\"}, {\"src\": \"10.3\", \"tgt\": \"party:Airspan\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"10.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"10.3\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"10.3\", \"tgt\": \"term:Confidential Information\", \"type\": \"USES\"}]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map (num_proc=2): 100%|█████████████████████████████████████████████████████████████████| 2071/2071 [00:01<00:00, 1564.72 examples/s]\n",
            "Map (num_proc=2): 100%|████████████████████████████████████████████████████████████████████| 262/262 [00:01<00:00, 218.90 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and validation datasets formatted for SFT.\n",
            "train: 2071 examples, eval: 262 examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#[Cell] 3 Data Loading and Robust Preprocessing\n",
        "import re, json\n",
        "from functools import partial\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "#Robust JSON parsing\n",
        "_JSON_BLOCK = re.compile(\n",
        "    r\"(?s)```(?:json)?\\s*(\\{.*?\\})\\s*```\"   # fenced ```json { ... } ```\n",
        "    r\"|(\\{.*\\})\"                             # or the first {...} span\n",
        ")\n",
        "\n",
        "_SMART = {\n",
        "    \"\\u2018\": \"'\", \"\\u2019\": \"'\",\n",
        "    \"\\u201c\": '\"', \"\\u201d\": '\"',\n",
        "    \"\\u00a0\": \" \",\n",
        "}\n",
        "\n",
        "def _normalize_quotes(s: str) -> str:\n",
        "    for k, v in _SMART.items():\n",
        "        s = s.replace(k, v)\n",
        "    return s\n",
        "\n",
        "def deep_safe_json(x, max_depth=3):\n",
        "    \"\"\"\n",
        "    Tries to coerce x into a dict (or list) by repeatedly:\n",
        "      1) extracting a fenced or first {...} JSON block,\n",
        "      2) normalizing smart quotes / code fences,\n",
        "      3) relaxing single-quoted keys/values -> double quotes.\n",
        "    Returns {} on failure.\n",
        "    \"\"\"\n",
        "    obj = x\n",
        "    for _ in range(max_depth):\n",
        "        if isinstance(obj, (dict, list)):\n",
        "            return obj\n",
        "        if obj is None:\n",
        "            return {}\n",
        "        s = _normalize_quotes(str(obj).strip())\n",
        "\n",
        "        #prefer fenced block, else first {...}\n",
        "        m = _JSON_BLOCK.search(s)\n",
        "        cand = (m.group(1) or m.group(2)) if m else s\n",
        "        cand = cand.strip()\n",
        "        if cand.startswith(\"```\"):\n",
        "            cand = cand.strip(\"`\").strip()\n",
        "            if cand.lower().startswith(\"json\"):\n",
        "                cand = cand[4:].lstrip()\n",
        "\n",
        "        #strict parse\n",
        "        try:\n",
        "            obj = json.loads(cand)\n",
        "            continue\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        #relaxed\n",
        "        try:\n",
        "            cand2 = re.sub(r\"([{\\s,])'([^']+?)'\\s*:\", r'\\1\"\\2\":', cand)  # keys\n",
        "            cand2 = re.sub(r\":\\s*'([^']*?)'\", r': \"\\1\"', cand2)         # string values\n",
        "            obj = json.loads(cand2)\n",
        "            continue\n",
        "        except Exception:\n",
        "            break\n",
        "    return {}\n",
        "\n",
        "#normalize\n",
        "def sanitize_and_format_completion(example):\n",
        "    \"\"\"\n",
        "    - Parse completion JSON robustly\n",
        "    - Ensure 'nodes' and 'edges' are lists\n",
        "    - Normalize a few schema quirks (e.g., 'node_type'->'type', fix 'clause_id: ')\n",
        "    - Store canonical JSON into 'clean_completion'\n",
        "    - Add 'clean_parse_ok' flag for filtering/stats\n",
        "    \"\"\"\n",
        "    raw = example.get(\"completion\", \"\")\n",
        "    parsed = deep_safe_json(raw)\n",
        "\n",
        "    ok = isinstance(parsed, dict)\n",
        "    if not ok:\n",
        "        # fallback: keep raw string so the model still sees signal\n",
        "        example[\"clean_completion\"] = raw if isinstance(raw, str) else json.dumps(raw, ensure_ascii=False)\n",
        "        example[\"clean_parse_ok\"] = False\n",
        "        return example\n",
        "\n",
        "    if \"clause_id: \" in parsed and \"clause_id\" not in parsed:\n",
        "        parsed[\"clause_id\"] = parsed.pop(\"clause_id: \")\n",
        "\n",
        "    nodes = parsed.get(\"nodes\") or []\n",
        "    edges = parsed.get(\"edges\") or []\n",
        "    if isinstance(nodes, dict): nodes = [nodes]\n",
        "    if isinstance(edges, dict): edges = [edges]\n",
        "\n",
        "    #normalize nodes -> ensure 'type' and 'attrs'\n",
        "    norm_nodes = []\n",
        "    for n in nodes if isinstance(nodes, list) else []:\n",
        "        if not isinstance(n, dict):\n",
        "            try:\n",
        "                n = json.loads(n)\n",
        "            except Exception:\n",
        "                continue\n",
        "        n = dict(n)\n",
        "        if \"type\" not in n and \"node_type\" in n:\n",
        "            n[\"type\"] = n.pop(\"node_type\")\n",
        "        n.setdefault(\"attrs\", {})\n",
        "        for k in (\"title\", \"name\", \"term\", \"text\"):\n",
        "            if k in n and k not in n[\"attrs\"]:\n",
        "                n[\"attrs\"][k] = n[k]\n",
        "        norm_nodes.append(n)\n",
        "\n",
        "    # normalize edges -> accept src/source/from & tgt/target/to, uppercase 'type'\n",
        "    norm_edges = []\n",
        "    for e in edges if isinstance(edges, list) else []:\n",
        "        if not isinstance(e, dict):\n",
        "            try:\n",
        "                e = json.loads(e)\n",
        "            except Exception:\n",
        "                continue\n",
        "        e = dict(e)\n",
        "        e.setdefault(\"src\", e.get(\"source\", e.get(\"from\")))\n",
        "        e.setdefault(\"tgt\", e.get(\"target\", e.get(\"to\")))\n",
        "        if \"type\" in e and isinstance(e[\"type\"], str):\n",
        "            e[\"type\"] = e[\"type\"].upper()\n",
        "        norm_edges.append(e)\n",
        "\n",
        "    parsed[\"nodes\"] = norm_nodes\n",
        "    parsed[\"edges\"] = norm_edges\n",
        "    example[\"clean_completion\"] = json.dumps(parsed, ensure_ascii=False)\n",
        "    example[\"clean_parse_ok\"] = True\n",
        "    return example\n",
        "\n",
        "#load and clean the dataset\n",
        "print(\"Loading and cleaning the dataset...\")\n",
        "HF_DATASET_ID = \"moriyad/clause_minigraph_builder_clean\"\n",
        "HF_MODEL_ID   = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "dataset = load_dataset(HF_DATASET_ID)\n",
        "cleaned_dataset = dataset.map(sanitize_and_format_completion, num_proc=2)\n",
        "\n",
        "ok_train = sum(int(x) for x in cleaned_dataset[\"train\"][\"clean_parse_ok\"])\n",
        "print(f\"\\nParse success (train): {ok_train}/{len(cleaned_dataset['train'])} = {ok_train/len(cleaned_dataset['train']):.1%}\")\n",
        "print(\"\\nDataset after cleaning:\")\n",
        "print(cleaned_dataset)\n",
        "\n",
        "def first_non_empty(ds_split):\n",
        "    for rec in ds_split:\n",
        "        try:\n",
        "            obj = json.loads(rec[\"clean_completion\"])\n",
        "            if (obj.get(\"nodes\") or obj.get(\"edges\")):\n",
        "                return obj\n",
        "        except Exception:\n",
        "            pass\n",
        "    try:\n",
        "        return json.loads(ds_split[0][\"clean_completion\"])\n",
        "    except Exception:\n",
        "        return {\"nodes\": [], \"edges\": []}\n",
        "\n",
        "print(\"\\nExample of a cleaned completion:\")\n",
        "pretty = first_non_empty(cleaned_dataset[\"train\"])\n",
        "print(json.dumps(pretty, ensure_ascii=False)[:1200])\n",
        "\n",
        "#chat template formatting\n",
        "SYS_PROMPT = \"You are a legal minigraph extractor. Return ONLY valid JSON with 'nodes' and 'edges'.\"\n",
        "\n",
        "def create_chat_format(example, tokenizer):\n",
        "    return {\n",
        "        \"text\": tokenizer.apply_chat_template(\n",
        "            [\n",
        "                {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": example[\"prompt\"]},\n",
        "                {\"role\": \"assistant\", \"content\": example[\"clean_completion\"]},\n",
        "            ],\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False,\n",
        "        )\n",
        "    }\n",
        "\n",
        "#tokenizer + pad token\n",
        "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "train_dataset = cleaned_dataset[\"train\"].map(\n",
        "    partial(create_chat_format, tokenizer=tokenizer),\n",
        "    num_proc=2,\n",
        "    remove_columns=cleaned_dataset[\"train\"].column_names,\n",
        ")\n",
        "eval_dataset = cleaned_dataset[\"validation\"].map(\n",
        "    partial(create_chat_format, tokenizer=tokenizer),\n",
        "    num_proc=2,\n",
        "    remove_columns=cleaned_dataset[\"validation\"].column_names,\n",
        ")\n",
        "print(\"\\nTraining and validation datasets formatted for SFT.\")\n",
        "print(f\"train: {len(train_dataset)} examples, eval: {len(eval_dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0cfd3ad-5486-45d6-b69c-2e35f164a720",
      "metadata": {
        "id": "d0cfd3ad-5486-45d6-b69c-2e35f164a720"
      },
      "outputs": [],
      "source": [
        "#robust evaluation\n",
        "def evaluate_model_debug(\n",
        "    model, tokenizer, dataset, system_prompt,\n",
        "    max_samples=200, batch_size=4, max_new_tokens=1024,\n",
        "    use_json_stopper=True, schema_strict=True,\n",
        "    gold_field=\"completion\",\n",
        "    print_samples=3\n",
        "):\n",
        "    import json, gc, re, numpy as np, torch\n",
        "    from collections import defaultdict\n",
        "    from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "    #helpers\n",
        "    def _safe_eos_ids(tok):\n",
        "        ids = []\n",
        "        for t in [\"<|eot_id|>\", \"<|eos|>\", tok.eos_token]:\n",
        "            if not t: continue\n",
        "            try:\n",
        "                i = tok.convert_tokens_to_ids(t) if isinstance(t, str) else t\n",
        "                if i is not None and i != tok.unk_token_id: ids.append(i)\n",
        "            except: pass\n",
        "        if tok.eos_token_id is not None: ids.append(tok.eos_token_id)\n",
        "        seen=set(); out=[]\n",
        "        for i in ids:\n",
        "            if i not in seen: seen.add(i); out.append(i)\n",
        "        return out or [tok.eos_token_id]\n",
        "\n",
        "    class JsonStopper(StoppingCriteria):\n",
        "        def __init__(self, tokenizer, input_len):\n",
        "            self.tok = tokenizer; self.input_len = input_len\n",
        "        def __call__(self, input_ids, scores, **kwargs):\n",
        "            s = self.tok.decode(input_ids[0, self.input_len:], skip_special_tokens=True)\n",
        "            opens = s.count(\"{\"); closes = s.count(\"}\")\n",
        "            return ('\"nodes\"' in s or \"'nodes'\" in s) and opens>0 and opens==closes\n",
        "\n",
        "    def deep_json(x, want_nodes_edges=True):\n",
        "        \"\"\"Parse JSON; if object lacks nodes/edges (when want_nodes_edges), return (None, reason).\"\"\"\n",
        "        if isinstance(x, (dict, list)):\n",
        "            obj = x\n",
        "        else:\n",
        "            s = (x if isinstance(x, str) else str(x or \"\")).strip()\n",
        "            b, e = s.find(\"{\"), s.rfind(\"}\")\n",
        "            cand = s[b:e+1] if (b!=-1 and e!=-1 and e>b) else s\n",
        "            try:\n",
        "                obj = json.loads(cand)\n",
        "            except Exception as e:\n",
        "                return None, f\"json_error: {e}\"\n",
        "        if want_nodes_edges:\n",
        "            if not isinstance(obj, dict):\n",
        "                return None, \"not_object\"\n",
        "            if \"nodes\" not in obj or \"edges\" not in obj:\n",
        "                return None, \"missing_nodes_edges\"\n",
        "            if not isinstance(obj.get(\"nodes\"), list) or not isinstance(obj.get(\"edges\"), list):\n",
        "                return None, \"bad_types\"\n",
        "        return obj, \"\"\n",
        "\n",
        "    def extract_nodes(obj):\n",
        "        return obj.get(\"nodes\", []) if isinstance(obj, dict) else []\n",
        "\n",
        "    def extract_edges(obj):\n",
        "        return obj.get(\"edges\", []) if isinstance(obj, dict) else []\n",
        "\n",
        "    COMPANY_SUFFIX_RE = re.compile(r\"\\b(inc\\.?|ltd\\.?|llc|l\\.l\\.c\\.|corp\\.?|co\\.?|ag|gmbh)\\b\", re.I)\n",
        "    WS_RE = re.compile(r\"\\s+\")\n",
        "    def norm(s):\n",
        "        if not isinstance(s, str): s = str(s) if s is not None else \"\"\n",
        "        s = s.lower().replace(\"&\",\"and\")\n",
        "        s = COMPANY_SUFFIX_RE.sub(\"\", s)\n",
        "        return WS_RE.sub(\" \", s).strip()\n",
        "\n",
        "    def toks(s): return re.findall(r\"[a-z0-9]+\", s.lower())\n",
        "    def jacc(a,b):\n",
        "        sa,sb=set(toks(a)),set(toks(b))\n",
        "        if not sa or not sb: return 1.0 if a.strip()==b.strip() and a.strip()!=\"\" else 0.0\n",
        "        return len(sa&sb)/max(1,len(sa|sb))\n",
        "\n",
        "    PCT_RE=re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*%\"); MONEY_RE=re.compile(r\"(\\$|usd)\\s*([\\d,]+(?:\\.\\d+)?)\",re.I)\n",
        "    DAYS_RE=re.compile(r\"(\\d+)\\s*days?\"); YEARS_RE=re.compile(r\"(\\d+)\\s*years?\")\n",
        "    NUM_WORDS={\"zero\":0,\"one\":1,\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"seven\":7,\"eight\":8,\"nine\":9,\n",
        "               \"ten\":10,\"eleven\":11,\"twelve\":12,\"thirteen\":13,\"fourteen\":14,\"fifteen\":15,\"sixteen\":16,\n",
        "               \"seventeen\":17,\"eighteen\":18,\"nineteen\":19,\"twenty\":20,\"thirty\":30,\"forty\":40,\"fifty\":50,\n",
        "               \"sixty\":60,\"seventy\":70,\"eighty\":80,\"ninety\":90}\n",
        "    def w2n(s):\n",
        "        s=s.lower()\n",
        "        for w,n in NUM_WORDS.items():\n",
        "            if re.search(rf\"\\b{w}\\b\", s): return n\n",
        "        return None\n",
        "    def canon_value(text):\n",
        "        s=norm(text)\n",
        "        m=PCT_RE.search(s)\n",
        "        if m: return f\"{float(m.group(1)):.0f}%\"\n",
        "        if \"percent\" in s:\n",
        "            n=w2n(s)\n",
        "            if n is not None: return f\"{n}%\"\n",
        "        m=MONEY_RE.search(s)\n",
        "        if m: return f\"usd {m.group(2).replace(',','')}\"\n",
        "        m=DAYS_RE.search(s)\n",
        "        if m: return f\"{int(m.group(1))} days\"\n",
        "        m=YEARS_RE.search(s)\n",
        "        if m: return f\"{int(m.group(1))} years\"\n",
        "        return s\n",
        "\n",
        "    def keytext(n):\n",
        "        t=(n.get(\"type\") or \"\").upper(); a=n.get(\"attrs\",{}) or {}; nid=n.get(\"id\",\"\") or \"\"\n",
        "        if t==\"CLAUSE\":\n",
        "            k=a.get(\"id\") or nid or a.get(\"title\") or \"\"; return t, norm(k)\n",
        "        if t==\"DEFINED_TERM\":\n",
        "            k=a.get(\"term\") or nid.split(\":\",1)[-1]; return t, norm(k)\n",
        "        if t==\"PARTY\":\n",
        "            k=a.get(\"name\") or a.get(\"text\") or nid.split(\":\",1)[-1]; return t, norm(k)\n",
        "        if t==\"VALUE\":\n",
        "            k=a.get(\"text\") or nid.split(\":\",1)[-1]; return t, canon_value(k)\n",
        "        k=a.get(\"text\") or a.get(\"term\") or a.get(\"name\") or nid; return t, norm(k)\n",
        "\n",
        "    THRESH={\"CLAUSE\":0.90,\"DEFINED_TERM\":0.80,\"PARTY\":0.85,\"VALUE\":0.75}\n",
        "    def sim(t,a,b):\n",
        "        if t==\"CLAUSE\": return 1.0 if a==b else jacc(a,b)\n",
        "        if t in (\"DEFINED_TERM\",\"PARTY\"): return jacc(a,b)\n",
        "        if t==\"VALUE\":\n",
        "            if a==b and (a.endswith(\"%\") or a.endswith(\"days\") or a.endswith(\"years\") or a.startswith(\"usd\")): return 1.0\n",
        "            return jacc(a,b)\n",
        "        return jacc(a,b)\n",
        "\n",
        "    def bucket(nodes):\n",
        "        b=defaultdict(list)\n",
        "        for n in nodes:\n",
        "            t,kt=keytext(n)\n",
        "            if t and kt: b[t].append(kt)\n",
        "        return b\n",
        "\n",
        "    def match_type(G_list, P_list, t):\n",
        "        if not G_list or not P_list: return 0\n",
        "        pairs=[]\n",
        "        for i,g in enumerate(G_list):\n",
        "            for j,p in enumerate(P_list):\n",
        "                s=sim(t,g,p)\n",
        "                if s>=THRESH.get(t,0.8): pairs.append((s,i,j))\n",
        "        pairs.sort(reverse=True)\n",
        "        used_i=set(); used_j=set(); tp=0\n",
        "        for s,i,j in pairs:\n",
        "            if i in used_i or j in used_j: continue\n",
        "            used_i.add(i); used_j.add(j); tp+=1\n",
        "        return tp\n",
        "\n",
        "    def edge_triplet(e, node_map):\n",
        "        def pick(d, keys):\n",
        "            for k in keys:\n",
        "                if k in d and d[k] is not None:\n",
        "                    return d[k]\n",
        "            return None\n",
        "        typ = (pick(e, [\"type\",\"edge_type\",\"label\"]) or \"\").upper()\n",
        "        raw_src = pick(e, [\"src\",\"source\",\"from\"])\n",
        "        raw_tgt = pick(e, [\"tgt\",\"target\",\"to\"])\n",
        "        def resolve(v):\n",
        "            if v is None: return \"\"\n",
        "            v_str = str(v)\n",
        "            if v_str in node_map: return node_map[v_str]\n",
        "            return norm(v_str)\n",
        "        return (resolve(raw_src), typ, resolve(raw_tgt))\n",
        "\n",
        "    def prf1(tp,fp,fn):\n",
        "        p=tp/(tp+fp) if (tp+fp) else 0.0\n",
        "        r=tp/(tp+fn) if (tp+fn) else 0.0\n",
        "        f=2*p*r/(p+r) if (p+r) else 0.0\n",
        "        return p,r,f\n",
        "\n",
        "    n = len(dataset)\n",
        "    use = min(max_samples, n)\n",
        "    idxs = np.random.choice(n, use, replace=False) if use < n else np.arange(n)\n",
        "    sub = dataset.select(idxs)\n",
        "    prompts = sub[\"prompt\"]\n",
        "    gold_key = gold_field if gold_field in sub.column_names else (\"clean_completion\" if \"clean_completion\" in sub.column_names else \"completion\")\n",
        "    golds = sub[gold_key]\n",
        "\n",
        "    tok = tokenizer\n",
        "    old_pad, old_trunc = tok.padding_side, getattr(tok, \"truncation_side\", \"right\")\n",
        "    tok.padding_side = tok.truncation_side = \"left\"\n",
        "    if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "    EOS = _safe_eos_ids(tok); PAD = tok.pad_token_id or tok.eos_token_id\n",
        "\n",
        "    preds=[]\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        chats = [tok.apply_chat_template(\n",
        "                    [{\"role\":\"system\",\"content\": system_prompt},\n",
        "                     {\"role\":\"user\",\"content\": p}],\n",
        "                    tokenize=False, add_generation_prompt=True)\n",
        "                 for p in prompts[i:i+batch_size]]\n",
        "        batch = tok(chats, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "        stopper = StoppingCriteriaList([JsonStopper(tok, input_len=batch[\"input_ids\"].shape[1])]) if use_json_stopper else StoppingCriteriaList([])\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(\n",
        "                **batch,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=False, temperature=None, top_p=None, top_k=None,\n",
        "                use_cache=True,\n",
        "                eos_token_id=EOS, pad_token_id=PAD,\n",
        "                stopping_criteria=stopper,\n",
        "            )\n",
        "        gen = tok.batch_decode(out[:, batch[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "        preds.extend(gen)\n",
        "        del out, batch; torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    tok.padding_side, tok.truncation_side = old_pad, old_trunc\n",
        "\n",
        "    print(\"\\n--- SAMPLE PROMPTS & PREDICTIONS ---\")\n",
        "    for i in range(min(print_samples, len(prompts))):\n",
        "        print(f\"\\n[Prompt {i}] {prompts[i][:300]}...\")\n",
        "        print(f\"[Pred  {i}] {preds[i][:300]}...\")\n",
        "\n",
        "    strict_tp=strict_fp=strict_fn=0\n",
        "    fuzzy_tp=fuzzy_fp=fuzzy_fn=0\n",
        "    e_tp=e_fp=e_fn=0\n",
        "    exact=invalid=0\n",
        "\n",
        "    gold_nodes_total=gold_edges_total=0\n",
        "    pred_nodes_total=pred_edges_total=0\n",
        "\n",
        "    def normalize_node_schema(n: dict) -> dict:\n",
        "        \"\"\"Unify node shape to: {'id': str, 'type': UPPER, 'attrs': {...}}.\"\"\"\n",
        "        n = dict(n or {})\n",
        "        out = {\"id\": n.get(\"id\", \"\"), \"type\": \"\", \"attrs\": {}}\n",
        "        t = (n.get(\"type\") or n.get(\"node_type\") or \"\").upper()\n",
        "        out[\"type\"] = t\n",
        "\n",
        "        attrs = {}\n",
        "        if isinstance(n.get(\"attrs\"), dict):\n",
        "            attrs.update(n[\"attrs\"])\n",
        "\n",
        "        for k in (\"title\", \"level\", \"text\", \"term\", \"name\", \"role\", \"address\"):\n",
        "            if k in n and k not in attrs:\n",
        "                attrs[k] = n[k]\n",
        "\n",
        "        out[\"attrs\"] = attrs\n",
        "        return out\n",
        "\n",
        "    #strict nodes\n",
        "    def setify_strict(nodes):\n",
        "        S=set()\n",
        "        for nn in nodes:\n",
        "            t=(nn.get(\"type\") or \"\").upper()\n",
        "            a=nn.get(\"attrs\",{}) or {}\n",
        "            nid=nn.get(\"id\",\"\") or \"\"\n",
        "            k=a.get(\"name\") or a.get(\"term\") or a.get(\"text\") or nid\n",
        "            k=norm(k)\n",
        "            if t and k: S.add((t,k))\n",
        "        return S\n",
        "\n",
        "    for gstr,pstr in zip(golds,preds):\n",
        "        G_json, g_err = deep_json(gstr, want_nodes_edges=schema_strict)\n",
        "        if G_json is None:\n",
        "            invalid += 1\n",
        "            continue\n",
        "        P_json, p_err = deep_json(pstr, want_nodes_edges=schema_strict)\n",
        "        if P_json is None:\n",
        "            invalid += 1\n",
        "            continue\n",
        "\n",
        "        G_nodes_raw = extract_nodes(G_json)\n",
        "        P_nodes_raw = extract_nodes(P_json)\n",
        "\n",
        "        #normalize both sides\n",
        "        G_nodes = [normalize_node_schema(x) for x in G_nodes_raw if isinstance(x, dict)]\n",
        "        P_nodes = [normalize_node_schema(x) for x in P_nodes_raw if isinstance(x, dict)]\n",
        "\n",
        "        #keep edges\n",
        "        G_edges = extract_edges(G_json)\n",
        "        P_edges = extract_edges(P_json)\n",
        "        Gs, Ps = setify_strict(G_nodes), setify_strict(P_nodes)\n",
        "\n",
        "        #exact matches\n",
        "        if (Gs or Ps) and (Gs == Ps):\n",
        "            exact += 1\n",
        "\n",
        "        gold_nodes_total += len(G_nodes); gold_edges_total += len(G_edges)\n",
        "        pred_nodes_total += len(P_nodes); pred_edges_total += len(P_edges)\n",
        "\n",
        "        #strict nodes\n",
        "        if Gs==Ps: exact+=1\n",
        "        strict_tp+=len(Gs&Ps); strict_fp+=len(Ps-Gs); strict_fn+=len(Gs-Ps)\n",
        "\n",
        "        #fuzzy nodes\n",
        "        def bucket(nodes):\n",
        "            b=defaultdict(list)\n",
        "            for n in nodes:\n",
        "                t,kt=keytext(n)\n",
        "                if t and kt: b[t].append(kt)\n",
        "            return b\n",
        "        Gb,Pb=bucket(G_nodes),bucket(P_nodes)\n",
        "        for t in (set(Gb)|set(Pb)):\n",
        "            tp=match_type(Gb.get(t,[]), Pb.get(t,[]), t)\n",
        "            fp=len(Pb.get(t,[]))-tp; fn=len(Gb.get(t,[]))-tp\n",
        "            fuzzy_tp+=tp; fuzzy_fp+=fp; fuzzy_fn+=fn\n",
        "\n",
        "        #edges\n",
        "        def build_map(nodes):\n",
        "            m={}\n",
        "            for n in nodes:\n",
        "                nid=n.get(\"id\") or \"\"\n",
        "                tt=keytext(n)\n",
        "                if nid: m[str(nid)] = f\"{tt[0]}|{tt[1]}\"\n",
        "            return m\n",
        "        Gmap,Pmap=build_map(G_nodes),build_map(P_nodes)\n",
        "        def edge_triplet(e, node_map):\n",
        "            def pick(d, keys):\n",
        "                for k in keys:\n",
        "                    if k in d and d[k] is not None:\n",
        "                        return d[k]\n",
        "                return None\n",
        "            typ = (pick(e, [\"type\",\"edge_type\",\"label\"]) or \"\").upper()\n",
        "            raw_src = pick(e, [\"src\",\"source\",\"from\"])\n",
        "            raw_tgt = pick(e, [\"tgt\",\"target\",\"to\"])\n",
        "            def resolve(v):\n",
        "                if v is None: return \"\"\n",
        "                v_str = str(v)\n",
        "                if v_str in node_map: return node_map[v_str]\n",
        "                return norm(v_str)\n",
        "            return (resolve(raw_src), typ, resolve(raw_tgt))\n",
        "        Ge=set(edge_triplet(e,Gmap) for e in G_edges)\n",
        "        Pe=set(edge_triplet(e,Pmap) for e in P_edges)\n",
        "        e_tp+=len(Ge&Pe); e_fp+=len(Pe-Ge); e_fn+=len(Ge-Pe)\n",
        "\n",
        "    sp,sr,sf1 = prf1(strict_tp,strict_fp,strict_fn)\n",
        "    fp_,fr_,ff1 = prf1(fuzzy_tp,fuzzy_fp,fuzzy_fn)\n",
        "    ep,er,ef1   = prf1(e_tp,e_fp,e_fn)\n",
        "\n",
        "    print(\"\\n--- AUDIT COUNTS ---\")\n",
        "    print(f\"Gold avg nodes/edges: {gold_nodes_total/max(1,use):.2f} / {gold_edges_total/max(1,use):.2f}\")\n",
        "    print(f\"Pred avg nodes/edges: {pred_nodes_total/max(1,use):.2f} / {pred_edges_total/max(1,use):.2f}\")\n",
        "\n",
        "    return {\n",
        "        \"gen_strict_micro_precision\": sp,\n",
        "        \"gen_strict_micro_recall\":    sr,\n",
        "        \"gen_strict_micro_f1\":        sf1,\n",
        "        \"gen_fuzzy_micro_precision\":  fp_,\n",
        "        \"gen_fuzzy_micro_recall\":     fr_,\n",
        "        \"gen_fuzzy_micro_f1\":         ff1,\n",
        "        \"gen_edges_micro_precision\":  ep,\n",
        "        \"gen_edges_micro_recall\":     er,\n",
        "        \"gen_edges_micro_f1\":         ef1,\n",
        "        \"gen_exact_match\":            exact/max(1,use),\n",
        "        \"gen_invalid_json_rate\":      invalid/max(1,use),\n",
        "        \"gen_num_samples\":            use,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb1f7b6-cc15-4bb4-b565-a355cfeab16b",
      "metadata": {
        "id": "deb1f7b6-cc15-4bb4-b565-a355cfeab16b",
        "outputId": "23997f5d-8353-4eb7-80bc-e15707fa7373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- SAMPLE PROMPTS & PREDICTIONS ---\n",
            "\n",
            "[Prompt 0] {\"instruction\": \"Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\\n\\nOutput ONLY a single, strict JSON object with this str...\n",
            "[Pred  0] {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.2\", \"node_type\": \"CLAUSE\", \"title\": \"11.2\", \"level\": 2}, {\"id\": \"11.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.2.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"pa...\n",
            "\n",
            "[Prompt 1] {\"instruction\": \"Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\\n\\nOutput ONLY a single, strict JSON object with this str...\n",
            "[Pred  1] {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"6\", \"node_type\": \"CLAUSE\", \"title\": \"6\", \"level\": 1}, {\"id\": \"party:Licensee\", \"node_type\": \"PARTY\", \"name\": \"Licensee\"}, {\"id\": \"party:Licensor\", \"nod...\n",
            "\n",
            "--- AUDIT COUNTS ---\n",
            "Gold avg nodes/edges: 5.26 / 4.20\n",
            "Pred avg nodes/edges: 5.16 / 4.26\n",
            "{'gen_strict_micro_precision': 0.8062015503875969, 'gen_strict_micro_recall': 0.7908745247148289, 'gen_strict_micro_f1': 0.7984644913627639, 'gen_fuzzy_micro_precision': 0.8178294573643411, 'gen_fuzzy_micro_recall': 0.8022813688212928, 'gen_fuzzy_micro_f1': 0.8099808061420345, 'gen_edges_micro_precision': 0.6666666666666666, 'gen_edges_micro_recall': 0.6761904761904762, 'gen_edges_micro_f1': 0.6713947990543735, 'gen_exact_match': 0.64, 'gen_invalid_json_rate': 0.02, 'gen_num_samples': 50}\n"
          ]
        }
      ],
      "source": [
        "#Cell 4a - run evaluation test\n",
        "from datasets import load_dataset\n",
        "\n",
        "metrics = evaluate_model_debug(\n",
        "    model, tokenizer, cleaned_dataset[\"validation\"],\n",
        "    system_prompt=SYS_PROMPT,\n",
        "    max_samples=50, batch_size=4, max_new_tokens=2048,\n",
        "    use_json_stopper=False,\n",
        "    schema_strict=True,\n",
        "    gold_field=\"completion\",\n",
        "    print_samples=2\n",
        ")\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc62cc3-1af9-4a47-a0fd-df460145bdd5",
      "metadata": {
        "id": "9fc62cc3-1af9-4a47-a0fd-df460145bdd5",
        "outputId": "2b42ef80-4e06-42d9-9bc0-b84cae10c200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- SAMPLE PROMPTS & PREDICTIONS ---\n",
            "\n",
            "[Prompt 0] {\"instruction\": \"Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\\n\\nOutput ONLY a single, strict JSON object with this str...\n",
            "[Pred  0] {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.5\", \"node_type\": \"CLAUSE\", \"title\": \"10.5\", \"level\": 2}, {\"id\": \"10.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"10.5.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"pa...\n",
            "\n",
            "[Prompt 1] {\"instruction\": \"Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\\n\\nOutput ONLY a single, strict JSON object with this str...\n",
            "[Pred  1] {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.16\", \"node_type\": \"CLAUSE\", \"title\": \"5.16\", \"level\": 2}, {\"id\": \"5.16.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.16.3\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"te...\n",
            "\n",
            "--- AUDIT COUNTS ---\n",
            "Gold avg nodes/edges: 6.29 / 5.18\n",
            "Pred avg nodes/edges: 6.16 / 5.26\n",
            "{'gen_strict_micro_precision': 0.7905844155844156, 'gen_strict_micro_recall': 0.7748607796340493, 'gen_strict_micro_f1': 0.7826436319807151, 'gen_fuzzy_micro_precision': 0.7978896103896104, 'gen_fuzzy_micro_recall': 0.7820206841686556, 'gen_fuzzy_micro_f1': 0.7898754519887505, 'gen_edges_micro_precision': 0.6615969581749049, 'gen_edges_micro_recall': 0.6711668273866924, 'gen_edges_micro_f1': 0.6663475347056007, 'gen_exact_match': 0.53, 'gen_invalid_json_rate': 0.015, 'gen_num_samples': 200}\n"
          ]
        }
      ],
      "source": [
        "#Cell 4b - run full evaluation test\n",
        "\n",
        "metrics = evaluate_model_debug(\n",
        "    model, tokenizer, cleaned_dataset[\"validation\"],\n",
        "    system_prompt=SYS_PROMPT,\n",
        "    max_samples=200, batch_size=4, max_new_tokens=2048,\n",
        "    use_json_stopper=False,\n",
        "    schema_strict=True,\n",
        "    gold_field=\"completion\",\n",
        "    print_samples=2\n",
        ")\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "11254be7-782e-4e2a-a806-0c63fac33f1d",
      "metadata": {
        "id": "11254be7-782e-4e2a-a806-0c63fac33f1d"
      },
      "outputs": [],
      "source": [
        "#@title Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7cd5ef-87d6-4998-b7d6-dd255e0d1607",
      "metadata": {
        "id": "6e7cd5ef-87d6-4998-b7d6-dd255e0d1607"
      },
      "outputs": [],
      "source": [
        "#@title helpers\n",
        "    def _deep_safe_json(self, x, max_depth=3):\n",
        "        obj = x\n",
        "        for _ in range(max_depth):\n",
        "            if isinstance(obj, (dict, list)):\n",
        "                return obj\n",
        "            if obj is None:\n",
        "                return {}\n",
        "            s = str(obj).strip()\n",
        "            b, e = s.find(\"{\"), s.rfind(\"}\")\n",
        "            cand = s[b:e+1] if (b != -1 and e != -1 and e > b) else s\n",
        "            try:\n",
        "                obj = json.loads(cand); continue\n",
        "            except Exception:\n",
        "                break\n",
        "        return {}\n",
        "\n",
        "    def _extract_nodes(self, obj):\n",
        "        arr = obj.get(\"nodes\", []) if isinstance(obj, dict) else []\n",
        "        if isinstance(arr, dict): arr = [arr]\n",
        "        out=[]\n",
        "        for it in arr:\n",
        "            if isinstance(it, dict): out.append(it)\n",
        "            elif isinstance(it, str):\n",
        "                try:\n",
        "                    d = json.loads(it)\n",
        "                    if isinstance(d, dict): out.append(d)\n",
        "                except: pass\n",
        "        return out\n",
        "\n",
        "    def _extract_edges(self, obj):\n",
        "        arr = obj.get(\"edges\", []) if isinstance(obj, dict) else []\n",
        "        if isinstance(arr, dict): arr = [arr]\n",
        "        out=[]\n",
        "        for it in arr:\n",
        "            if isinstance(it, dict): out.append(it)\n",
        "            elif isinstance(it, str):\n",
        "                try:\n",
        "                    d = json.loads(it)\n",
        "                    if isinstance(d, dict): out.append(d)\n",
        "                except: pass\n",
        "        return out\n",
        "\n",
        "    def _edge_triplet(self, e, node_map):\n",
        "        def pick(d, keys):\n",
        "            for k in keys:\n",
        "                if k in d and d[k] is not None:\n",
        "                    return d[k]\n",
        "            return None\n",
        "        typ = (pick(e, [\"type\",\"edge_type\",\"label\"]) or \"\").upper()\n",
        "        raw_src = pick(e, [\"src\",\"source\",\"from\"])\n",
        "        raw_tgt = pick(e, [\"tgt\",\"target\",\"to\"])\n",
        "        def resolve(v):\n",
        "            if v is None: return \"\"\n",
        "            v_str = str(v)\n",
        "            if v_str in node_map:\n",
        "                return node_map[v_str]\n",
        "            return self._norm(v_str)\n",
        "        return (resolve(raw_src), typ, resolve(raw_tgt))\n",
        "\n",
        "    # ----- normalization & matching -----\n",
        "    COMPANY_SUFFIX_RE = re.compile(r\"\\b(inc\\.?|ltd\\.?|llc|l\\.l\\.c\\.|corp\\.?|co\\.?|ag|gmbh)\\b\", re.I)\n",
        "    WS_RE = re.compile(r\"\\s+\")\n",
        "    def _norm(self, s):\n",
        "        if not isinstance(s, str): s = str(s) if s is not None else \"\"\n",
        "        s = s.lower().replace(\"&\",\"and\")\n",
        "        s = self.COMPANY_SUFFIX_RE.sub(\"\", s)\n",
        "        return self.WS_RE.sub(\" \", s).strip()\n",
        "\n",
        "    def _toks(self, s): return re.findall(r\"[a-z0-9]+\", s.lower())\n",
        "    def _jacc(self, a,b):\n",
        "        sa,sb=set(self._toks(a)),set(self._toks(b))\n",
        "        if not sa or not sb: return 1.0 if a.strip()==b.strip() and a.strip()!=\"\" else 0.0\n",
        "        return len(sa&sb)/max(1,len(sa|sb))\n",
        "\n",
        "    PCT_RE=re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*%\"); MONEY_RE=re.compile(r\"(\\$|usd)\\s*([\\d,]+(?:\\.\\d+)?)\",re.I)\n",
        "    DAYS_RE=re.compile(r\"(\\d+)\\s*days?\"); YEARS_RE=re.compile(r\"(\\d+)\\s*years?\")\n",
        "    NUM_WORDS={\"zero\":0,\"one\":1,\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"seven\":7,\"eight\":8,\"nine\":9,\n",
        "               \"ten\":10,\"eleven\":11,\"twelve\":12,\"thirteen\":13,\"fourteen\":14,\"fifteen\":15,\"sixteen\":16,\n",
        "               \"seventeen\":17,\"eighteen\":18,\"nineteen\":19,\"twenty\":20,\"thirty\":30,\"forty\":40,\"fifty\":50,\n",
        "               \"sixty\":60,\"seventy\":70,\"eighty\":80,\"ninety\":90}\n",
        "    def _w2n(self,s):\n",
        "        s=s.lower()\n",
        "        for w,n in self.NUM_WORDS.items():\n",
        "            if re.search(rf\"\\b{w}\\b\", s): return n\n",
        "        return None\n",
        "\n",
        "    def _canon_value(self, text):\n",
        "        s=self._norm(text)\n",
        "        m=self.PCT_RE.search(s)\n",
        "        if m: return f\"{float(m.group(1)):.0f}%\"\n",
        "        if \"percent\" in s:\n",
        "            n=self._w2n(s)\n",
        "            if n is not None: return f\"{n}%\"\n",
        "        m=self.MONEY_RE.search(s)\n",
        "        if m: return f\"usd {m.group(2).replace(',','')}\"\n",
        "        m=self.DAYS_RE.search(s)\n",
        "        if m: return f\"{int(m.group(1))} days\"\n",
        "        m=self.YEARS_RE.search(s)\n",
        "        if m: return f\"{int(m.group(1))} years\"\n",
        "        return s\n",
        "\n",
        "    def _keytext(self, n):\n",
        "        t=(n.get(\"type\") or \"\").upper(); a=n.get(\"attrs\",{}) or {}; nid=n.get(\"id\",\"\") or \"\"\n",
        "        if t==\"CLAUSE\":\n",
        "            k=a.get(\"id\") or nid or a.get(\"title\") or \"\"; return t,self._norm(k)\n",
        "        if t==\"DEFINED_TERM\":\n",
        "            k=a.get(\"term\") or nid.split(\":\",1)[-1]; return t,self._norm(k)\n",
        "        if t==\"PARTY\":\n",
        "            k=a.get(\"name\") or a.get(\"text\") or nid.split(\":\",1)[-1]; return t,self._norm(k)\n",
        "        if t==\"VALUE\":\n",
        "            k=a.get(\"text\") or nid.split(\":\",1)[-1]; return t,self._canon_value(k)\n",
        "        k=a.get(\"text\") or a.get(\"term\") or a.get(\"name\") or nid; return t,self._norm(k)\n",
        "\n",
        "    THRESH={\"CLAUSE\":0.90,\"DEFINED_TERM\":0.80,\"PARTY\":0.85,\"VALUE\":0.75}\n",
        "    def _sim(self,t,a,b):\n",
        "        if t==\"CLAUSE\": return 1.0 if a==b else self._jacc(a,b)\n",
        "        if t==\"DEFINED_TERM\": return self._jacc(a,b)\n",
        "        if t==\"PARTY\": return self._jacc(a,b)\n",
        "        if t==\"VALUE\":\n",
        "            if a==b and (a.endswith(\"%\") or a.endswith(\"days\") or a.endswith(\"years\") or a.startswith(\"usd\")): return 1.0\n",
        "            return self._jacc(a,b)\n",
        "        return self._jacc(a,b)\n",
        "\n",
        "    def _bucket(self, nodes):\n",
        "        b=defaultdict(list)\n",
        "        for n in nodes:\n",
        "            t,kt=self._keytext(n)\n",
        "            if t and kt: b[t].append(kt)\n",
        "        return b\n",
        "\n",
        "    def _match_type(self, G_list, P_list, t):\n",
        "        if not G_list or not P_list: return 0\n",
        "        pairs=[]\n",
        "        for i,g in enumerate(G_list):\n",
        "            for j,p in enumerate(P_list):\n",
        "                s=self._sim(t,g,p)\n",
        "                if s>=self.THRESH.get(t,0.8): pairs.append((s,i,j))\n",
        "        pairs.sort(reverse=True)\n",
        "        used_i=set(); used_j=set(); tp=0\n",
        "        for s,i,j in pairs:\n",
        "            if i in used_i or j in used_j: continue\n",
        "            used_i.add(i); used_j.add(j); tp+=1\n",
        "        return tp\n",
        "\n",
        "    def _prf1(self,tp,fp,fn):\n",
        "        p=tp/(tp+fp) if (tp+fp) else 0.0\n",
        "        r=tp/(tp+fn) if (tp+fn) else 0.0\n",
        "        f=2*p*r/(p+r) if (p+r) else 0.0\n",
        "        return p,r,f\n",
        "\n",
        "    # ----- generation -----\n",
        "    def _generate_texts(self, model, prompts):\n",
        "        tok = self.tokenizer\n",
        "        old_pad, old_trunc = tok.padding_side, getattr(tok, \"truncation_side\", \"right\")\n",
        "        tok.padding_side = tok.truncation_side = \"left\"\n",
        "        if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "        EOS = _safe_eos_ids(tok)\n",
        "        PAD = tok.pad_token_id or tok.eos_token_id\n",
        "\n",
        "        outs=[]\n",
        "        for i in range(0, len(prompts), self.gen_batch_size):\n",
        "            texts = [tok.apply_chat_template(\n",
        "                        [{\"role\": \"system\",\"content\": self.sys_prompt},\n",
        "                         {\"role\": \"user\",\"content\": p}],\n",
        "                        tokenize=False, add_generation_prompt=True)\n",
        "                     for p in prompts[i:i+self.gen_batch_size]]\n",
        "            batch = tok(texts, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "            stop = StoppingCriteriaList([JsonStopper(tok, input_len=batch[\"input_ids\"].shape[1])])\n",
        "            with torch.no_grad():\n",
        "                out = model.generate(\n",
        "                    **batch,\n",
        "                    max_new_tokens=self.gen_max_new_tokens,\n",
        "                    min_new_tokens=1,\n",
        "                    do_sample=False, temperature=None, top_p=None, top_k=None,\n",
        "                    use_cache=True,\n",
        "                    eos_token_id=EOS, pad_token_id=PAD,\n",
        "                    max_time=60,  # per-call safety cap\n",
        "                    stopping_criteria=stop,\n",
        "                )\n",
        "            gen = tok.batch_decode(out[:, batch[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "            outs.extend(gen)\n",
        "            del out, batch\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "        tok.padding_side, tok.truncation_side = old_pad, old_trunc\n",
        "        return outs\n",
        "\n",
        "    # ----- metrics (nodes + edges) -----\n",
        "    def compute_node_metrics(self, model):\n",
        "        n = len(self.eval_ds_raw)\n",
        "        use = min(self.gen_max_samples, n)\n",
        "        idxs = np.random.choice(n, use, replace=False) if use < n else np.arange(n)\n",
        "        sub = self.eval_ds_raw.select(idxs)\n",
        "        prompts = sub[\"prompt\"]\n",
        "        gold_key = \"clean_completion\" if \"clean_completion\" in sub.column_names else \"completion\"\n",
        "        golds = sub[gold_key]\n",
        "\n",
        "        preds = self._generate_texts(model, prompts)\n",
        "\n",
        "        strict_tp=strict_fp=strict_fn=0\n",
        "        fuzzy_tp=fuzzy_fp=fuzzy_fn=0\n",
        "        e_tp=e_fp=e_fn=0\n",
        "        exact=invalid=0\n",
        "\n",
        "        def setify_strict(nodes):\n",
        "            S=set()\n",
        "            for nn in nodes:\n",
        "                t=(nn.get(\"type\") or \"\").upper(); a=nn.get(\"attrs\",{}) or {}; nid=nn.get(\"id\",\"\") or \"\"\n",
        "                k=a.get(\"name\") or a.get(\"term\") or a.get(\"text\") or nid\n",
        "                k=self._norm(k)\n",
        "                if t and k: S.add((t,k))\n",
        "            return S\n",
        "\n",
        "        for gstr,pstr in zip(golds,preds):\n",
        "            G_json=self._deep_safe_json(gstr); P_json=self._deep_safe_json(pstr)\n",
        "            G_nodes=self._extract_nodes(G_json)\n",
        "            try:\n",
        "                P_nodes=self._extract_nodes(P_json)\n",
        "            except Exception:\n",
        "                P_nodes=[]; invalid+=1\n",
        "\n",
        "            # strict nodes\n",
        "            Gs, Ps = setify_strict(G_nodes), setify_strict(P_nodes)\n",
        "            if Gs==Ps: exact+=1\n",
        "            strict_tp+=len(Gs&Ps); strict_fp+=len(Ps-Gs); strict_fn+=len(Gs-Ps)\n",
        "\n",
        "            # fuzzy nodes\n",
        "            Gb,Pb=self._bucket(G_nodes),self._bucket(P_nodes)\n",
        "            for t in (set(Gb)|set(Pb)):\n",
        "                tp=self._match_type(Gb.get(t,[]), Pb.get(t,[]), t)\n",
        "                fp=len(Pb.get(t,[]))-tp; fn=len(Gb.get(t,[]))-tp\n",
        "                fuzzy_tp+=tp; fuzzy_fp+=fp; fuzzy_fn+=fn\n",
        "\n",
        "            # edges (strict on (src,type,tgt) triples)\n",
        "            def build_map(nodes):\n",
        "                m={}\n",
        "                for n in nodes:\n",
        "                    nid=n.get(\"id\") or \"\"\n",
        "                    tt=self._keytext(n)\n",
        "                    if nid: m[str(nid)] = f\"{tt[0]}|{tt[1]}\"\n",
        "                return m\n",
        "            Gmap,Pmap=build_map(G_nodes),build_map(P_nodes)\n",
        "            Ge=set(self._edge_triplet(e,Gmap) for e in self._extract_edges(G_json))\n",
        "            Pe=set(self._edge_triplet(e,Pmap) for e in self._extract_edges(P_json))\n",
        "            e_tp+=len(Ge&Pe); e_fp+=len(Pe-Ge); e_fn+=len(Ge-Pe)\n",
        "\n",
        "        sp,sr,sf1 = self._prf1(strict_tp,strict_fp,strict_fn)\n",
        "        fp_,fr_,ff1 = self._prf1(fuzzy_tp,fuzzy_fp,fuzzy_fn)\n",
        "        ep,er,ef1   = self._prf1(e_tp,e_fp,e_fn)\n",
        "\n",
        "        return {\n",
        "            \"gen_strict_micro_precision\": sp,\n",
        "            \"gen_strict_micro_recall\":    sr,\n",
        "            \"gen_strict_micro_f1\":        sf1,\n",
        "            \"gen_fuzzy_micro_precision\":  fp_,\n",
        "            \"gen_fuzzy_micro_recall\":     fr_,\n",
        "            \"gen_fuzzy_micro_f1\":         ff1,\n",
        "            \"gen_edges_micro_precision\":  ep,\n",
        "            \"gen_edges_micro_recall\":     er,\n",
        "            \"gen_edges_micro_f1\":         ef1,\n",
        "            \"gen_exact_match\":            exact/max(1,len(prompts)),\n",
        "            \"gen_invalid_json_rate\":      invalid/max(1,len(prompts)),\n",
        "            \"gen_num_samples\":            len(prompts),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21779ce5-b962-4681-be2f-da1d1b083cf7",
      "metadata": {
        "id": "21779ce5-b962-4681-be2f-da1d1b083cf7",
        "outputId": "03bcb1e1-4c48-45ff-f369-56b2c3fb52b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading base model (4-bit) with FlashAttention-2…\n",
            "GPU free/total: 69.2 / 85.0 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:13<00:00,  3.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying SFT adapter from /home/ubuntu/ai/adapter-20250827-142825\n",
            "GPU free/total: 61.3 / 85.0 GB\n",
            "Model ready (FA2, 4-bit NF4).\n"
          ]
        }
      ],
      "source": [
        "#@title [Cell] 2 execution for train setup - Load base model (4-bit) + apply SFT adapter\n",
        "import os, torch, wandb\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "BASE_MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "#MODEL_DIR   = (SFT_RUN_DIR / \"adapter-20250827-142825\") #- Original SFT qlora model\n",
        "MODEL_DIR   = (SFT_RUN_DIR / \"notebooks/checkpoints/grpo_final_gen_equal_batch_short_eval\")\n",
        "# ---- 4-bit NF4 on A100; bf16 math ----\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token or tokenizer.pad_token\n",
        "\n",
        "def _print_gpu():\n",
        "    try:\n",
        "        free, total = torch.cuda.mem_get_info()\n",
        "        print(f\"GPU free/total: {free/1e9:.1f} / {total/1e9:.1f} GB\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"Loading base model (4-bit) with FlashAttention-2…\")\n",
        "_print_gpu()\n",
        "\n",
        "common_kwargs = dict(\n",
        "    quantization_config=bnb,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_MODEL_ID,\n",
        "        device_map={\"\": \"cuda:0\"},\n",
        "        **common_kwargs,\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(\"[Retry] memory-constrained auto mapping… Reason:\", e)\n",
        "    try:\n",
        "        max_mem = {0: \"78GiB\", \"cpu\": \"0GiB\"}\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL_ID,\n",
        "            device_map=\"auto\",\n",
        "            max_memory=max_mem,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "    except ValueError as e2:\n",
        "        print(\"[Retry] CPU offload last resort… Reason:\", e2)\n",
        "        offload_dir = os.path.join(os.getcwd(), \"offload\")\n",
        "        os.makedirs(offload_dir, exist_ok=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            BASE_MODEL_ID,\n",
        "            device_map=\"auto\",\n",
        "            offload_folder=offload_dir,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "\n",
        "try:\n",
        "    eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    if eot_id is None or eot_id == tokenizer.unk_token_id:\n",
        "        tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<|eot_id|>\"]})\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "        eot_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "except Exception:\n",
        "    eot_id = None\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"Applying SFT adapter from\", MODEL_DIR)\n",
        "model = PeftModel.from_pretrained(model, MODEL_DIR, is_trainable=True)\n",
        "model.config.use_cache = False\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "try:\n",
        "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
        "except TypeError:\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "_print_gpu()\n",
        "print(\"Model ready (FA2, 4-bit NF4).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91333f25-ecb6-43e2-a626-b0afec05e94b",
      "metadata": {
        "id": "91333f25-ecb6-43e2-a626-b0afec05e94b",
        "outputId": "1926949c-d0be-4915-d27d-fa5c705079f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'contract_id', 'clause_id', 'prompt', 'completion'],\n",
              "    num_rows: 1312\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Cell 3a Training - Data load and clean\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "import re\n",
        "\n",
        "HF_DATASET_ID = \"moriyad/clause_minigraph_builder_grpo\"\n",
        "\n",
        "ds = load_dataset(HF_DATASET_ID)\n",
        "\n",
        "def deep_safe_json(x, max_depth=3):\n",
        "    obj = x\n",
        "    for _ in range(max_depth):\n",
        "        if isinstance(obj, (dict, list)): return obj\n",
        "        if isinstance(obj, str):\n",
        "            s = obj.strip()\n",
        "            b, e = s.find(\"{\"), s.rfind(\"}\")\n",
        "            cand = s[b:e+1] if (b != -1 and e != -1 and e > b) else s\n",
        "            try:\n",
        "                obj = json.loads(cand); continue\n",
        "            except Exception:\n",
        "                break\n",
        "        break\n",
        "    return {}\n",
        "\n",
        "\n",
        "DATE_RE = re.compile(r\"(Cutting Knowledge Date:.*\\n|Today Date:.*\\n)\")\n",
        "\n",
        "strip_dates = lambda ex: {\n",
        "    **ex,\n",
        "    \"clean_instruction\": DATE_RE.sub(\"\", ex[\"clean_instruction\"]).strip()\n",
        "}\n",
        "ds[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b123765-21ef-403b-84cb-271c8b90afb2",
      "metadata": {
        "id": "6b123765-21ef-403b-84cb-271c8b90afb2",
        "outputId": "611ce059-d4f5-4112-fec9-942bdc6e5a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1312 | Eval slice: 64\n"
          ]
        }
      ],
      "source": [
        "eval_ds_full  = (ds[\"validation\"])\n",
        "train_ds_full = ds[\"train\"]\n",
        "#small evaluation slice for quick periodic eval\n",
        "EVAL_SLICE = min(64, len(ds[\"validation\"]))\n",
        "eval_ds_small = (ds[\"validation\"]).select(range(EVAL_SLICE))\n",
        "\n",
        "print(\"Train size:\", len(train_ds_full), \"| Eval slice:\", len(eval_ds_small))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb97846d-4138-45ba-ad1d-b11270dac762",
      "metadata": {
        "id": "eb97846d-4138-45ba-ad1d-b11270dac762",
        "outputId": "48a3afef-0642-41e4-9c23-52ba9cc2f77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 3b Training - Building the gold index for scoring\n",
        "\n",
        "from typing import Any, Dict, Iterable, Tuple\n",
        "\n",
        "def build_gold_index(ds_train_full: Iterable[Dict[str, Any]]) -> Dict[Tuple[str, str], Any]:\n",
        "    \"\"\"\n",
        "    Build a dictionary {(contract_id, clause_id): completion_value}.\n",
        "    Supports records shaped like:\n",
        "      {\n",
        "        \"contract_id\": \"...\",\n",
        "        \"clause_id\": \"...\",          # or nested: \"clause\": {\"id\": \"...\"}\n",
        "        \"completion\": {...}          # gold completion (dict/string), preferred\n",
        "        # (fallback) \"gold\": {...}   # if 'completion' missing\n",
        "      }\n",
        "    \"\"\"\n",
        "    index: Dict[Tuple[str, str], Any] = {}\n",
        "    for row in ds_train_full:\n",
        "        if isinstance(row, str):\n",
        "            try:\n",
        "                ex = json.loads(row)\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"bad row, skipping \")\n",
        "                continue\n",
        "        elif isinstance(row, dict):\n",
        "            ex = row\n",
        "        else:\n",
        "            print(f\"row is something else {type(row)}\")\n",
        "            continue\n",
        "\n",
        "        cid = ex.get(\"contract_id\")\n",
        "        clid = ex.get(\"clause_id\")\n",
        "        if clid is None:\n",
        "            clause_obj = ex.get(\"clause\") or {}\n",
        "            clid = clause_obj.get(\"id\")\n",
        "        if not cid or not clid:\n",
        "            continue\n",
        "\n",
        "        key = (str(cid), str(clid))\n",
        "\n",
        "        if \"completion\" in ex:\n",
        "            index[key] = ex[\"completion\"]\n",
        "        elif \"gold\" in ex:\n",
        "            index[key] = ex[\"gold\"]\n",
        "        else:\n",
        "            continue\n",
        "    return index\n",
        "\n",
        "type(train_ds_full)\n",
        "ds_train_index = build_gold_index(train_ds_full)\n",
        "ds_eval_index = build_gold_index(eval_ds_full)\n",
        "full_index = ds_train_index | ds_eval_index\n",
        "print(len(full_index))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52239b3b-4ace-4d89-9541-3c449d26aef4",
      "metadata": {
        "id": "52239b3b-4ace-4d89-9541-3c449d26aef4",
        "outputId": "e2023d4b-fa50-4b0d-cc90-4a4fd27bea86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\n",
            "\n",
            "Output ONLY a single, strict JSON object with this structure:\n",
            "\n",
            "{\n",
            " \"contract_id\": \"...\",\n",
            " \"nodes\": [ ... ],\n",
            " \"edges\": [ ... ]\n",
            "}\n",
            "\n",
            " \n",
            "REASONING PROCESS\n",
            " \n",
            "1.  **Isolate Core Text:** First, mentally separate the core contractual prose from any 'noise' like Tables of Contents, redaction headers, or formatting artifacts. Your analysis should ONLY focus on the contractual prose.\n",
            "2.  **Create Primary Node:** Create the `CLAUSE` node for the clause you were given.\n",
            "3.  **Infer and Create Parent Node:** Analyze the clause `id` and `level` to infer the parent clause ID. Create the parent `CLAUSE` node.\n",
            "4.  **Scan and Create Nodes:** Read the core text to identify all other entities (Referenced Clauses, Defined Terms, Parties, Values) and create their corresponding nodes according to the rules below.\n",
            "5.  **Create Edges:** Link the primary clause node to all other created nodes using the appropriate edge types.\n",
            "\n",
            " \n",
            "NODE RULES\n",
            " \n",
            "- CLAUSE:\n",
            "  { \"id\": \"<clause-id>\", \"node_type\": \"CLAUSE\", \"title\": \"<title>\", \"level\": <int> }\n",
            "  Rule: Create a node for the input clause, its inferred parent, and any clauses it explicitly references.\n",
            "\n",
            "- DEFINED_TERM:\n",
            "  { \"id\": \"term:<Canonical Term>\", \"node_type\": \"DEFINED_TERM\", \"name\": \"<Canonical Term>\" }\n",
            "  Rule: Create for terms with special meaning (quoted, ALL CAPS, or explicitly defined). Canonicalize the name (e.g., \"this Agreement\" becomes \"Agreement\"; use Title Case).\n",
            "\n",
            "- PARTY:\n",
            "  { \"id\": \"party:<Party Name>\", \"node_type\": \"PARTY\", \"name\": \"<Party Name>\" }\n",
            "  Rule: Only for legal entities or defined roles (e.g., \"Licensor\", \"the Supplier\"). Canonicalize by removing articles (\"the\", \"a\").\n",
            "\n",
            "- VALUE:\n",
            "  { \"id\": \"value:<literal text>\", \"node_type\": \"VALUE\", \"unit\": \"Currency|Percentage|Days|Months|Years\", \"text\": \"<literal text>\" }\n",
            "  Rule: Extract specific amounts, durations, etc.\n",
            "\n",
            " \n",
            "EDGE RULES\n",
            " \n",
            "Format: { \"src\":\"<id>\", \"tgt\":\"<id>\", \"type\":\"<EDGE_TYPE>\" }\n",
            "\n",
            "- IS_PART_OF: CLAUSE → parent CLAUSE\n",
            "  Rule: Infer parent from child's ID. Numeric: \"3.4\" → \"3\"; \"14.2\" → \"ARTICLE 14\". Non-numeric: For an ID like \"(h)\", look for context in the text like \"Section 3.2(h)\" to infer the parent is \"3.2\".\n",
            "\n",
            "- DEFINES: CLAUSE → DEFINED_TERM\n",
            "  Rule: Use when the clause introduces a definition (“X shall mean...”, “(the ‘X’)”).\n",
            "\n",
            "- USES: CLAUSE → DEFINED_TERM\n",
            "  Rule: Use when a defined term is mentioned but not defined in this clause. Be thorough and include all capitalized, multi-word legal concepts (e.g., \"Material Change\", \"Product Prices\").\n",
            "\n",
            "- REFERENCES: CLAUSE → CLAUSE\n",
            "  Rule: Use for explicit cross-references like “Section 3.2” or “Article 10”.\n",
            "\n",
            "- MENTIONS_PARTY: CLAUSE → PARTY\n",
            "  Rule: Create an edge for every mentioned party.\n",
            "\n",
            "- CONTAINS: CLAUSE → VALUE\n",
            "  Rule: Create an edge for every extracted value.\n",
            "\n",
            " \n",
            "CRITICAL CLARIFICATIONS\n",
            " \n",
            "1.  **Reference Typing is Key:** Any cross-reference to another part of the document (e.g., \"Article 5\", \"Exhibit B\") MUST be created as a `CLAUSE` node. It is NEVER a `DEFINED_TERM`.\n",
            "2.  **No Duplicates:** Output each unique node and edge only once. If no nodes or edges can be created, output empty arrays.\n",
            "3.  **Sort for Consistency:** Sort nodes by ID and edges by `src`, `type`, then `tgt`.\n",
            "{'contract_id': 'AIRSPANNETWORKSINC_04_11_2000-EX-10.5-Distributor Agreement', 'clause': {'id': '10.3', 'title': '10.3', 'text': '10.3 Distributor covenants and agrees that it will use the Confidential Information solely for the performance of services under this Agreement, and shall not disclose such Confidential Information to any other person (including Airspan employees in any other division, group, or entity), firm, or corporation.'}}\n"
          ]
        }
      ],
      "source": [
        "rowprmpt = ds[\"train\"][0][\"prompt\"]\n",
        "objprompt = json.loads(rowprmpt)\n",
        "print(objprompt.get(\"instruction\"))\n",
        "print(objprompt.get(\"input\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dff6e458-9302-422d-be83-bddcce6ad01d",
      "metadata": {
        "id": "dff6e458-9302-422d-be83-bddcce6ad01d",
        "outputId": "0589b4cd-6ded-4986-b16e-020aa60f445e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYour task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\\n\\nOutput ONLY a single, strict JSON object with this structure:\\n\\n{\\n \"contract_id\": \"...\",\\n \"nodes\": [ ... ],\\n \"edges\": [ ... ]\\n}\\n\\n \\nREASONING PROCESS\\n \\n1.  **Isolate Core Text:** First, mentally separate the core contractual prose from any \\'noise\\' like Tables of Contents, redaction headers, or formatting artifacts. Your analysis should ONLY focus on the contractual prose.\\n2.  **Create Primary Node:** Create the `CLAUSE` node for the clause you were given.\\n3.  **Infer and Create Parent Node:** Analyze the clause `id` and `level` to infer the parent clause ID. Create the parent `CLAUSE` node.\\n4.  **Scan and Create Nodes:** Read the core text to identify all other entities (Referenced Clauses, Defined Terms, Parties, Values) and create their corresponding nodes according to the rules below.\\n5.  **Create Edges:** Link the primary clause node to all other created nodes using the appropriate edge types.\\n\\n \\nNODE RULES\\n \\n- CLAUSE:\\n  { \"id\": \"<clause-id>\", \"node_type\": \"CLAUSE\", \"title\": \"<title>\", \"level\": <int> }\\n  Rule: Create a node for the input clause, its inferred parent, and any clauses it explicitly references.\\n\\n- DEFINED_TERM:\\n  { \"id\": \"term:<Canonical Term>\", \"node_type\": \"DEFINED_TERM\", \"name\": \"<Canonical Term>\" }\\n  Rule: Create for terms with special meaning (quoted, ALL CAPS, or explicitly defined). Canonicalize the name (e.g., \"this Agreement\" becomes \"Agreement\"; use Title Case).\\n\\n- PARTY:\\n  { \"id\": \"party:<Party Name>\", \"node_type\": \"PARTY\", \"name\": \"<Party Name>\" }\\n  Rule: Only for legal entities or defined roles (e.g., \"Licensor\", \"the Supplier\"). Canonicalize by removing articles (\"the\", \"a\").\\n\\n- VALUE:\\n  { \"id\": \"value:<literal text>\", \"node_type\": \"VALUE\", \"unit\": \"Currency|Percentage|Days|Months|Years\", \"text\": \"<literal text>\" }\\n  Rule: Extract specific amounts, durations, etc.\\n\\n \\nEDGE RULES\\n \\nFormat: { \"src\":\"<id>\", \"tgt\":\"<id>\", \"type\":\"<EDGE_TYPE>\" }\\n\\n- IS_PART_OF: CLAUSE → parent CLAUSE\\n  Rule: Infer parent from child\\'s ID. Numeric: \"3.4\" → \"3\"; \"14.2\" → \"ARTICLE 14\". Non-numeric: For an ID like \"(h)\", look for context in the text like \"Section 3.2(h)\" to infer the parent is \"3.2\".\\n\\n- DEFINES: CLAUSE → DEFINED_TERM\\n  Rule: Use when the clause introduces a definition (“X shall mean...”, “(the ‘X’)”).\\n\\n- USES: CLAUSE → DEFINED_TERM\\n  Rule: Use when a defined term is mentioned but not defined in this clause. Be thorough and include all capitalized, multi-word legal concepts (e.g., \"Material Change\", \"Product Prices\").\\n\\n- REFERENCES: CLAUSE → CLAUSE\\n  Rule: Use for explicit cross-references like “Section 3.2” or “Article 10”.\\n\\n- MENTIONS_PARTY: CLAUSE → PARTY\\n  Rule: Create an edge for every mentioned party.\\n\\n- CONTAINS: CLAUSE → VALUE\\n  Rule: Create an edge for every extracted value.\\n\\n \\nCRITICAL CLARIFICATIONS\\n \\n1.  **Reference Typing is Key:** Any cross-reference to another part of the document (e.g., \"Article 5\", \"Exhibit B\") MUST be created as a `CLAUSE` node. It is NEVER a `DEFINED_TERM`.\\n2.  **No Duplicates:** Output each unique node and edge only once. If no nodes or edges can be created, output empty arrays.\\n3.  **Sort for Consistency:** Sort nodes by ID and edges by `src`, `type`, then `tgt`. Generate EXACTLY the JSON object {...} with no additional text before or after. End immediately after the closing brace }.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{\\'contract_id\\': \\'AIRSPANNETWORKSINC_04_11_2000-EX-10.5-Distributor Agreement\\', \\'clause\\': {\\'id\\': \\'10.3\\', \\'title\\': \\'10.3\\', \\'text\\': \\'10.3 Distributor covenants and agrees that it will use the Confidential Information solely for the performance of services under this Agreement, and shall not disclose such Confidential Information to any other person (including Airspan employees in any other division, group, or entity), firm, or corporation.\\'}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title Cell 3c Training - Further cleanup and special tokens validation\n",
        "\n",
        "import re, json\n",
        "\n",
        "def _strip_knowledge_banner(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    lines = text.splitlines()\n",
        "    while lines and (\n",
        "        re.match(r'^\\s*system\\s*$', lines[0], flags=re.I) or\n",
        "        re.match(r'^\\s*(Cutting\\s*Knowledge\\s*Date|Knowledge\\s*cutoff)\\s*:', lines[0], flags=re.I) or\n",
        "        re.match(r'^\\s*(Today\\s*Date|Current\\s*date)\\s*:', lines[0], flags=re.I) or\n",
        "        re.match(r'^\\s*$', lines[0])\n",
        "    ):\n",
        "        lines.pop(0)\n",
        "    return \"\\n\".join(lines).lstrip(\"\\n\")\n",
        "\n",
        "def _strip_banner_from_rendered_prompt(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes the Llama-style knowledge banner that the chat template injects\n",
        "    at the start of the system block. Only touches the first system section.\n",
        "    \"\"\"\n",
        "    sys_hdr = \"<|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
        "    i = prompt.find(sys_hdr)\n",
        "    if i == -1:\n",
        "        return prompt\n",
        "    start = i + len(sys_hdr)\n",
        "\n",
        "    j = prompt.find(\"<|start_header_id|>user<|end_header_id|>\", start)\n",
        "    if j == -1:\n",
        "        j = prompt.find(\"<|eot_id|><|start_header_id|>user<|end_header_id|>\", start)\n",
        "    end = j if j != -1 else len(prompt)\n",
        "\n",
        "    sys_block = prompt[start:end]\n",
        "    lines = sys_block.splitlines()\n",
        "\n",
        "    k = 0\n",
        "    while k < len(lines) and (\n",
        "        re.match(r'^\\s*system\\s*$', lines[k], flags=re.I) or\n",
        "        re.match(r'^\\s*(Cutting\\s*Knowledge\\s*Date|Knowledge\\s*cutoff)\\s*:\\s*.*$', lines[k], flags=re.I) or\n",
        "        re.match(r'^\\s*(Today\\s*Date|Current\\s*date)\\s*:\\s*.*$', lines[k], flags=re.I) or\n",
        "        re.match(r'^\\s*$', lines[k])\n",
        "    ):\n",
        "        k += 1\n",
        "\n",
        "    cleaned_sys = \"\\n\".join(lines[k:])\n",
        "    return prompt[:start] + cleaned_sys + prompt[end:]\n",
        "\n",
        "def create_chat_prompt_grpo(example, tokenizer):\n",
        "    objprompt   = json.loads(example[\"prompt\"])\n",
        "    instruction = _strip_knowledge_banner(objprompt.get(\"instruction\") or \"\")\n",
        "    user_input  = objprompt.get(\"input\") or \"\"\n",
        "\n",
        "    instruction += \" Generate EXACTLY the JSON object {...} with no additional text before or after. End immediately after the closing brace }.\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": instruction},\n",
        "        {\"role\": \"user\",   \"content\": user_input},\n",
        "    ]\n",
        "    rendered = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "    rendered = _strip_banner_from_rendered_prompt(rendered)\n",
        "    return {\"prompt\": rendered}\n",
        "\n",
        "keep_cols = {\"prompt\", \"contract_id\", \"clause_id\", \"completion\"}\n",
        "train_ds = train_ds_full.map(\n",
        "    lambda ex: create_chat_prompt_grpo(ex, tokenizer),\n",
        "    remove_columns=[c for c in train_ds_full.column_names if c not in keep_cols]\n",
        ")\n",
        "eval_ds_small = eval_ds_small.map(\n",
        "    lambda ex: create_chat_prompt_grpo(ex, tokenizer),\n",
        "    remove_columns=[c for c in eval_ds_small.column_names if c not in keep_cols]\n",
        ")\n",
        "\n",
        "eval_ds_full = eval_ds_full.map(\n",
        "    lambda ex: create_chat_prompt_grpo(ex, tokenizer),\n",
        "    remove_columns=[c for c in eval_ds_full.column_names if c not in keep_cols]\n",
        ")\n",
        "train_ds[0][\"prompt\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f25340-8a4f-40ba-be56-6490cb120d59",
      "metadata": {
        "id": "11f25340-8a4f-40ba-be56-6490cb120d59",
        "outputId": "671fb109-022d-468f-88ee-a7fcb64b1d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.3 AIRSPANNETWORKSINC_04_11_2000-EX-10.5-Distributor Agreement\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 3d Training - Helpers for fetching gold completions\n",
        "\n",
        "import re, json, ast\n",
        "from typing import Tuple\n",
        "\n",
        "_USER_BLOCK_RE = re.compile(\n",
        "    r\"<\\|start_header_id\\|>user<\\|end_header_id\\|>\\s*(.*?)\\s*<\\|eot_id\\|>\",\n",
        "    re.S\n",
        ")\n",
        "\n",
        "def _parse_user_obj(user_content: str):\n",
        "    \"\"\"\n",
        "    Parse the user content into a dict. Try JSON first; if it fails, try Python literal.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return json.loads(user_content)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        obj = ast.literal_eval(user_content)\n",
        "        if isinstance(obj, dict):\n",
        "            return obj\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    i, j = user_content.find(\"{\"), user_content.rfind(\"}\")\n",
        "    if i != -1 and j != -1 and j > i:\n",
        "        snippet = user_content[i:j+1]\n",
        "        try:\n",
        "            return json.loads(snippet)\n",
        "        except Exception:\n",
        "            try:\n",
        "                obj = ast.literal_eval(snippet)\n",
        "                if isinstance(obj, dict):\n",
        "                    return obj\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    raise ValueError(f\"User content not parseable as JSON/Python dict.\\nHead: {user_content[:200]}\")\n",
        "\n",
        "def extract_clause_id_contract_id_from_prompt(templated_prompt: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Given a Llama-3.x chat-templated prompt string, extract (clause_id, contract_id)\n",
        "    from the user turn JSON/dict.\n",
        "    \"\"\"\n",
        "    m = _USER_BLOCK_RE.search(templated_prompt)\n",
        "    if not m:\n",
        "        raise ValueError(\"Could not find <user> block in the chat-templated prompt.\")\n",
        "\n",
        "    user_content = m.group(1).strip()\n",
        "    obj = _parse_user_obj(user_content)\n",
        "\n",
        "    contract_id = obj.get(\"contract_id\")\n",
        "    clause = obj.get(\"clause\") or {}\n",
        "    clause_id = clause.get(\"id\")\n",
        "\n",
        "    if not contract_id or not clause_id:\n",
        "        raise ValueError(f\"Missing ids in user payload. Got keys: {list(obj.keys())}\")\n",
        "\n",
        "    return str(clause_id), str(contract_id)\n",
        "\n",
        "cid, contract = extract_clause_id_contract_id_from_prompt(train_ds[0][\"prompt\"])\n",
        "print(cid, contract)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95f0b24-2068-4d65-a293-b7ca50348431",
      "metadata": {
        "id": "f95f0b24-2068-4d65-a293-b7ca50348431",
        "outputId": "b1d1b717-56b1-4e3b-ba81-257b82eeb0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'src': '10.3', 'tgt': '10', 'type': 'IS_PART_OF'}, {'src': '10.3', 'tgt': 'party:Airspan', 'type': 'MENTIONS_PARTY'}, {'src': '10.3', 'tgt': 'party:Distributor', 'type': 'MENTIONS_PARTY'}, {'src': '10.3', 'tgt': 'term:Agreement', 'type': 'USES'}, {'src': '10.3', 'tgt': 'term:Confidential Information', 'type': 'USES'}]\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 3e Training - Helpers for fetching gold completions\n",
        "# build this once at startup:\n",
        "# gold_index = build_gold_index(ds_train_full)\n",
        "\n",
        "def fetch_gold_completions(clause_id: str, contract_id: str, gold_index: Dict[Tuple[str, str], Any]):\n",
        "    \"\"\"\n",
        "    Look up the gold completion by (contract_id, clause_id).\n",
        "    Provide `gold_index` if you built it (recommended). If not provided, raise.\n",
        "    \"\"\"\n",
        "    if gold_index is None:\n",
        "        raise ValueError(\"gold_index is required. Build it with build_gold_index(ds_train_full) and pass it in.\")\n",
        "    return gold_index.get((str(contract_id), str(clause_id)))\n",
        "\n",
        "gold = fetch_gold_completions(cid, contract, full_index)\n",
        "gold_obj = json.loads(gold)\n",
        "print(gold_obj.get(\"edges\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f12f04e-00ad-4c65-862b-3d5531a95702",
      "metadata": {
        "id": "3f12f04e-00ad-4c65-862b-3d5531a95702",
        "outputId": "3694c208-5ad2-4201-c7cc-cbd6b4d22947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['contract_id', 'clause_id', 'prompt', 'completion'],\n",
            "    num_rows: 188\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(eval_ds_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbb8d6e-61da-40ce-b026-95914474c546",
      "metadata": {
        "id": "4bbb8d6e-61da-40ce-b026-95914474c546",
        "outputId": "fa0e2996-f03a-4881-b93b-40e8e9f3abcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example of a Refactored Entry ---\n",
            "\n",
            "[START OF PROMPT]\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Your task is to act as a legal graph extractor. From this single clause, create a self-contained set of nodes and edges that are explicitly supported by the text. Follow the reasoning process, rules, and clarifications below.\n",
            "\n",
            "Output ONLY a single, strict JSON object with this structure:\n",
            "\n",
            "{\n",
            " \"contract_id\": \"...\",\n",
            " \"nodes\": [ ... ],\n",
            " \"edges\": [ ... ]\n",
            "}\n",
            "\n",
            " \n",
            "REASONING PROCESS\n",
            " \n",
            "1.  **Isolate Core Text:** First, mentally separate the core c...\n",
            "\n",
            "[END OF PROMPT]\n",
            "ss, rules, and clarifications below.\n",
            "\n",
            "Output ONLY a single, strict JSON object with this structure:\n",
            "\n",
            "{\n",
            " \"contract_id\": \"...\",\n",
            " \"nodes\": [ ... ],\n",
            " \"edges\": [ ... ]\n",
            "}\n",
            "\n",
            " \n",
            "REASONING PROCESS\n",
            " \n",
            "1.  **Isolate Core Text:** First, mentally separate the core contractual prose from any 'noise' like Tables of Contents, redaction headers, or formatting artifacts. Your analysis should ONLY focus on the contractual prose.\n",
            "2.  **Create Primary Node:** Create the `CLAUSE` node for the clause you were given.\n",
            "3.  **Infer and Create Parent Node:** Analyze the clause `id` and `level` to infer the parent clause ID. Create the parent `CLAUSE` node.\n",
            "4.  **Scan and Create Nodes:** Read the core text to identify all other entities (Referenced Clauses, Defined Terms, Parties, Values) and create their corresponding nodes according to the rules below.\n",
            "5.  **Create Edges:** Link the primary clause node to all other created nodes using the appropriate edge types.\n",
            "\n",
            " \n",
            "NODE RULES\n",
            " \n",
            "- CLAUSE:\n",
            "  { \"id\": \"<clause-id>\", \"node_type\": \"CLAUSE\", \"title\": \"<title>\", \"level\": <int> }\n",
            "  Rule: Create a node for the input clause, its inferred parent, and any clauses it explicitly references.\n",
            "\n",
            "- DEFINED_TERM:\n",
            "  { \"id\": \"term:<Canonical Term>\", \"node_type\": \"DEFINED_TERM\", \"name\": \"<Canonical Term>\" }\n",
            "  Rule: Create for terms with special meaning (quoted, ALL CAPS, or explicitly defined). Canonicalize the name (e.g., \"this Agreement\" becomes \"Agreement\"; use Title Case).\n",
            "\n",
            "- PARTY:\n",
            "  { \"id\": \"party:<Party Name>\", \"node_type\": \"PARTY\", \"name\": \"<Party Name>\" }\n",
            "  Rule: Only for legal entities or defined roles (e.g., \"Licensor\", \"the Supplier\"). Canonicalize by removing articles (\"the\", \"a\").\n",
            "\n",
            "- VALUE:\n",
            "  { \"id\": \"value:<literal text>\", \"node_type\": \"VALUE\", \"unit\": \"Currency|Percentage|Days|Months|Years\", \"text\": \"<literal text>\" }\n",
            "  Rule: Extract specific amounts, durations, etc.\n",
            "\n",
            " \n",
            "EDGE RULES\n",
            " \n",
            "Format: { \"src\":\"<id>\", \"tgt\":\"<id>\", \"type\":\"<EDGE_TYPE>\" }\n",
            "\n",
            "- IS_PART_OF: CLAUSE → parent CLAUSE\n",
            "  Rule: Infer parent from child's ID. Numeric: \"3.4\" → \"3\"; \"14.2\" → \"ARTICLE 14\". Non-numeric: For an ID like \"(h)\", look for context in the text like \"Section 3.2(h)\" to infer the parent is \"3.2\".\n",
            "\n",
            "- DEFINES: CLAUSE → DEFINED_TERM\n",
            "  Rule: Use when the clause introduces a definition (“X shall mean...”, “(the ‘X’)”).\n",
            "\n",
            "- USES: CLAUSE → DEFINED_TERM\n",
            "  Rule: Use when a defined term is mentioned but not defined in this clause. Be thorough and include all capitalized, multi-word legal concepts (e.g., \"Material Change\", \"Product Prices\").\n",
            "\n",
            "- REFERENCES: CLAUSE → CLAUSE\n",
            "  Rule: Use for explicit cross-references like “Section 3.2” or “Article 10”.\n",
            "\n",
            "- MENTIONS_PARTY: CLAUSE → PARTY\n",
            "  Rule: Create an edge for every mentioned party.\n",
            "\n",
            "- CONTAINS: CLAUSE → VALUE\n",
            "  Rule: Create an edge for every extracted value.\n",
            "\n",
            " \n",
            "CRITICAL CLARIFICATIONS\n",
            " \n",
            "1.  **Reference Typing is Key:** Any cross-reference to another part of the document (e.g., \"Article 5\", \"Exhibit B\") MUST be created as a `CLAUSE` node. It is NEVER a `DEFINED_TERM`.\n",
            "2.  **No Duplicates:** Output each unique node and edge only once. If no nodes or edges can be created, output empty arrays.\n",
            "3.  **Sort for Consistency:** Sort nodes by ID and edges by `src`, `type`, then `tgt`. Generate EXACTLY the JSON object {...} with no additional text before or after. End immediately after the closing brace }.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "{'contract_id': 'NEOMEDIATECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT', 'clause': {'id': '18.2', 'title': '18.2', 'text': '18.2 The parties hereof intend to form a long-term relationship. To this end, if both parties wish to renew this Agreement, the parties shall agree on such intention in writing at least thirty(30) days before the expiry of the current Term of the Agreement. The parties shall agree on the terms and conditions of the renewal, and enter into a new agreement within sixty(60) days from the expiry of this Agreement. During this sixty(60) days period, both parties shall continue to perform their respective obligation under the same terms and conditions of this Agreement.'}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "...\n",
            "\n",
            "[completion]\n",
            "{\"contract_id\": \"NEOMEDIATECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}, {\"id\": \"value:30 days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"thirty(30) days\"}, {\"id\": \"value:60 days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty(60) days\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\", \"tgt\": \"term:Term\", \"type\": \"USES\"}, {\"src\": \"18.2\", \"tgt\": \"value:30 days\", \"type\": \"CONTAINS\"}, {\"src\": \"18.2\", \"tgt\": \"value:60 days\", \"type\": \"CONTAINS\"}]}\n",
            "\n",
            "[CLAUSE_ID]\n",
            "18.2\n",
            "\n",
            "[CONTRACT_ID]\n",
            "NEOMEDIATECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\n"
          ]
        }
      ],
      "source": [
        "# --- Verify the Output ---\n",
        "print(\"\\n--- Example of a Refactored Entry ---\")\n",
        "example_entry = eval_ds_full[0]\n",
        "\n",
        "print(\"\\n[START OF PROMPT]\")\n",
        "print(example_entry[\"prompt\"][:500] + \"...\")\n",
        "print(\"\\n[END OF PROMPT]\")\n",
        "print(example_entry[\"prompt\"][250:] + \"...\")\n",
        "\n",
        "print(\"\\n[completion]\")\n",
        "print(example_entry[\"completion\"])\n",
        "\n",
        "print(\"\\n[CLAUSE_ID]\")\n",
        "print(example_entry[\"clause_id\"])\n",
        "\n",
        "print(\"\\n[CONTRACT_ID]\")\n",
        "print(example_entry[\"contract_id\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4e1dbd-61fd-49eb-aa75-7e17c817a33f",
      "metadata": {
        "id": "fa4e1dbd-61fd-49eb-aa75-7e17c817a33f",
        "outputId": "e0a86a87-a4e2-4ab6-f792-cb06f5d28fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis of Ground-Truth Completion Lengths (in tokens):\n",
            "Max length: 469\n",
            "Mean length: 264.57\n",
            "95th percentile: 409.45000000000005\n",
            "99th percentile: 432.8900000000001\n",
            "\n",
            "--- Recommendation ---\n",
            "Set 'max_new_tokens' to a value safely above the max, like 515 or 476\n",
            "Analysis of Training Prompt Lengths (in tokens):\n",
            "Prompt Max length: 1191\n",
            "Prompt Mean length: 1052.99\n",
            "Prompt 95th percentile: 1129.0\n",
            "Prompt 99th percentile: 1150.0\n"
          ]
        }
      ],
      "source": [
        "# Get the column name for the ground-truth JSON\n",
        "gold_key = \"completion\" if \"completion\" in train_ds.column_names else \"completion\"\n",
        "prompt_lengths = [len(tokenizer.encode(text)) for text in train_ds[\"prompt\"]]\n",
        "# Calculate the token length for each completion\n",
        "token_lengths = [len(tokenizer.encode(text)) for text in train_ds[\"completion\"]]\n",
        "\n",
        "# --- Analyze the results ---\n",
        "import numpy as np\n",
        "\n",
        "max_len = np.max(token_lengths)\n",
        "mean_len = np.mean(token_lengths)\n",
        "p95_len = np.percentile(token_lengths, 95)\n",
        "p99_len = np.percentile(token_lengths, 99)\n",
        "\n",
        "prmax_len = np.max(prompt_lengths)\n",
        "prmean_len = np.mean(prompt_lengths)\n",
        "prp95_len = np.percentile(prompt_lengths, 95)\n",
        "prp99_len = np.percentile(prompt_lengths, 99)\n",
        "\n",
        "print(f\"Analysis of Ground-Truth Completion Lengths (in tokens):\")\n",
        "print(f\"Max length: {max_len}\")\n",
        "print(f\"Mean length: {mean_len:.2f}\")\n",
        "print(f\"95th percentile: {p95_len}\")\n",
        "print(f\"99th percentile: {p99_len}\")\n",
        "print(\"\\n--- Recommendation ---\")\n",
        "print(f\"Set 'max_new_tokens' to a value safely above the max, like {int(max_len * 1.1)} or {int(p99_len * 1.1)}\")\n",
        "print(f\"Analysis of Training Prompt Lengths (in tokens):\")\n",
        "print(f\"Prompt Max length: {prmax_len}\")\n",
        "print(f\"Prompt Mean length: {prmean_len:.2f}\")\n",
        "print(f\"Prompt 95th percentile: {prp95_len}\")\n",
        "print(f\"Prompt 99th percentile: {prp99_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee20540-1d85-423e-b511-acda42bc8a90",
      "metadata": {
        "id": "8ee20540-1d85-423e-b511-acda42bc8a90"
      },
      "outputs": [],
      "source": [
        "#@title Cell 4a Training - GRPO Configurations\n",
        "\n",
        "train_generation_kwargs = {\n",
        "    \"do_sample\": True, \"temperature\": 0.4, \"top_p\": 0.9,\n",
        "    \"use_cache\": True,\n",
        "    \"eos_token_id\": [tokenizer.eos_token_id],\n",
        "    \"pad_token_id\": tokenizer.pad_token_id,\n",
        "    \"max_new_tokens\": 400,\n",
        "    \"eos_token_id\": [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")],\n",
        "    \"repetition_penalty\": 1.2,\n",
        "    \"length_penalty\": 1.0,\n",
        "}\n",
        "\n",
        "eval_generation_kwargs = {\n",
        "    \"do_sample\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"top_p\": 1.0, \"top_k\": 0,\n",
        "    \"max_new_tokens\": 400,\n",
        "    \"eos_token_id\": [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")],\n",
        "    \"early_stopping\": True,\n",
        "    \"repetition_penalty\": 1.2,\n",
        "    \"length_penalty\": 1.0,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "103e9843-c8aa-45ce-a828-c91fbd84849a",
      "metadata": {
        "id": "103e9843-c8aa-45ce-a828-c91fbd84849a"
      },
      "outputs": [],
      "source": [
        "#@title Cell 4b Training - GRPO Configurations in trl\n",
        "from transformers import GenerationConfig\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "\n",
        "grpo_cfg = GRPOConfig(\n",
        "    run_name=\"customReward_customEval\",\n",
        "    report_to=[\"wandb\"],\n",
        "    max_steps=1000,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-6,\n",
        "    bf16=True,\n",
        "\n",
        "    num_generations=4,\n",
        "    max_prompt_length=1280,\n",
        "    max_completion_length=500,\n",
        "    generation_kwargs=train_generation_kwargs,\n",
        "    generation_batch_size=4,\n",
        "\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=1,\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    remove_unused_columns=False,\n",
        "    dataloader_num_workers=2,\n",
        "    torch_empty_cache_steps=1,\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "grpo_cfg.generation_kwargs.update({\n",
        "    \"eos_token_id\": tokenizer.convert_tokens_to_ids(tokenizer.eos_token),\n",
        "    \"pad_token_id\": tokenizer.convert_tokens_to_ids(tokenizer.pad_token),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f14dcda-b382-4dcf-a8e3-7737400bad73",
      "metadata": {
        "id": "6f14dcda-b382-4dcf-a8e3-7737400bad73"
      },
      "outputs": [],
      "source": [
        "#@title Cell 4c Training - Custom Stopping Criteria\n",
        "\n",
        "import re, json, torch\n",
        "from transformers import StoppingCriteria\n",
        "\n",
        "class SmartNewJsonStopper(StoppingCriteria):\n",
        "    \"\"\"\n",
        "    Regex-only stopper:\n",
        "      1) cut to text AFTER assistant header\n",
        "      2) find:  \"nodes\": [ ... ], \"edges\":\n",
        "         (optionally require non-empty nodes)\n",
        "      3) then see a final `]}`\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        min_new_chars: int = 80,\n",
        "        max_scan_chars: int = 6000,\n",
        "        require_nonempty_nodes: bool = True,\n",
        "        debug: bool = False,\n",
        "    ):\n",
        "        self.tok = tokenizer\n",
        "        self.min_new_chars = int(min_new_chars)\n",
        "        self.max_scan_chars = int(max_scan_chars)\n",
        "        self.require_nonempty_nodes = bool(require_nonempty_nodes)\n",
        "        self.debug = bool(debug)\n",
        "\n",
        "        self.assistant_marks = [\n",
        "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        "            \"<|assistant|>\\n\\n\",\n",
        "            \"<|assistant|>\",\n",
        "            \"\\nassistant\\n\\n\",\n",
        "            \"assistant\\n\\n\",\n",
        "            \"assistant\\n\",\n",
        "        ]\n",
        "\n",
        "        if self.require_nonempty_nodes:\n",
        "            self.re_nodes_edges = re.compile(\n",
        "                r'\"nodes\"\\s*:\\s*\\[\\s*(?!\\])[\\s\\S]*?\\]\\s*,\\s*\"edges\"\\s*:',\n",
        "                re.DOTALL\n",
        "            )\n",
        "        else:\n",
        "            self.re_nodes_edges = re.compile(\n",
        "                r'\"nodes\"\\s*:\\s*\\[[\\s\\S]*?\\]\\s*,\\s*\"edges\"\\s*:',\n",
        "                re.DOTALL\n",
        "            )\n",
        "\n",
        "        self.re_close = re.compile(r'\\]\\s*\\}')\n",
        "\n",
        "    def _suffix_after_assistant(self, text: str) -> str:\n",
        "        cut = -1\n",
        "        for m in self.assistant_marks:\n",
        "            j = text.rfind(m)\n",
        "            if j >= 0:\n",
        "                cut = max(cut, j + len(m))\n",
        "        return text[cut:] if cut >= 0 else text\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        B = input_ids.shape[0]\n",
        "        if self.debug:\n",
        "            print(f\"[stopper] called batch={B}\")\n",
        "\n",
        "        done_flags = []\n",
        "        for b in range(B):\n",
        "            tail = self.tok.decode(input_ids[b][-self.max_scan_chars:], skip_special_tokens=True)\n",
        "            suffix = self._suffix_after_assistant(tail)\n",
        "\n",
        "            is_this_row_done = False\n",
        "            if len(suffix) >= self.min_new_chars:\n",
        "                m = self.re_nodes_edges.search(suffix)\n",
        "                if m and self.re_close.search(suffix[m.end():]):\n",
        "                    if self.debug:\n",
        "                        print(f\"[stopper] TRIGGER condition met for row={b}\")\n",
        "                    is_this_row_done = True\n",
        "\n",
        "            done_flags.append(is_this_row_done)\n",
        "\n",
        "        if all(done_flags):\n",
        "            if self.debug:\n",
        "                print(f\"--- SmartNewJsonStopper: ALL {B} sequences are done. Stopping. ---\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "json_stopper = SmartNewJsonStopper(tokenizer, min_new_chars=20, max_scan_chars=4000, require_nonempty_nodes=True, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70183d4-59a7-40df-8be5-c84214903c73",
      "metadata": {
        "id": "f70183d4-59a7-40df-8be5-c84214903c73"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Cell 4d Training - Custom GRPO Trainer Class\n",
        "\n",
        "#latest working version\n",
        "from trl import GRPOTrainer\n",
        "from torch.utils.data import Subset\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "class GRPOTrainerWithEvalControls(GRPOTrainer):\n",
        "\n",
        "    def __init__(self, *args, eval_generation_kwargs=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self._eval_generation_kwargs = eval_generation_kwargs or {}\n",
        "        self._final_eval_done = False\n",
        "        self._saved_small_eval = None\n",
        "        self._full_eval_ds = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _sanitize_sc(sc_like) -> StoppingCriteriaList:\n",
        "        \"\"\"Keep only real StoppingCriteria subclasses; drop base/invalid entries.\"\"\"\n",
        "        def _valid(c): return isinstance(c, StoppingCriteria) and (type(c) is not StoppingCriteria)\n",
        "        if sc_like is None:\n",
        "            keep = []\n",
        "        elif isinstance(sc_like, StoppingCriteriaList):\n",
        "            keep = [c for c in sc_like if _valid(c)]\n",
        "        elif isinstance(sc_like, (list, tuple)):\n",
        "            keep = [c for c in sc_like if _valid(c)]\n",
        "        elif _valid(sc_like):\n",
        "            keep = [sc_like]\n",
        "        else:\n",
        "            keep = []\n",
        "        return StoppingCriteriaList(keep)\n",
        "\n",
        "    def set_eval_datasets(self, small_eval_ds, full_eval_ds):\n",
        "        self._saved_small_eval = small_eval_ds\n",
        "        self._full_eval_ds = full_eval_ds\n",
        "        self.eval_dataset = small_eval_ds\n",
        "\n",
        "    def _generate_completions(self, dataset, *args, **kwargs):\n",
        "        gen_kwargs = dict(kwargs.get(\"generation_kwargs\", {}))\n",
        "        sc = self._sanitize_sc(gen_kwargs.get(\"stopping_criteria\", None))\n",
        "\n",
        "        ext = getattr(self, \"_ext_stopper\", None)\n",
        "        if ext:\n",
        "            if isinstance(ext, (list, tuple)):\n",
        "                for c in ext:\n",
        "                    if all(c is not e for e in sc):\n",
        "                        sc.append(c)\n",
        "            else:\n",
        "                if all(ext is not e for e in sc):\n",
        "                    sc.append(ext)\n",
        "\n",
        "        if all(getattr(e, \"__class__\", None) is not json_stopper.__class__ for e in sc):\n",
        "            sc.append(json_stopper)\n",
        "\n",
        "        gen_kwargs[\"stopping_criteria\"] = sc\n",
        "        kwargs[\"generation_kwargs\"] = gen_kwargs\n",
        "        return super()._generate_completions(dataset, *args, **kwargs)\n",
        "\n",
        "    def _generate(self, *args, **kwargs):\n",
        "        sc = self._sanitize_sc(kwargs.get(\"stopping_criteria\", None))\n",
        "\n",
        "        ext = getattr(self, \"_ext_stopper\", None)\n",
        "        if ext:\n",
        "            if isinstance(ext, (list, tuple)):\n",
        "                for c in ext:\n",
        "                    if all(c is not e for e in sc):\n",
        "                        sc.append(c)\n",
        "            else:\n",
        "                if all(ext is not e for e in sc):\n",
        "                    sc.append(ext)\n",
        "\n",
        "        if all(getattr(e, \"__class__\", None) is not json_stopper.__class__ for e in sc):\n",
        "            sc.append(json_stopper)\n",
        "\n",
        "        kwargs[\"stopping_criteria\"] = sc\n",
        "\n",
        "        # train vs eval\n",
        "        if self.model.training:\n",
        "            kwargs.setdefault(\"do_sample\", True)\n",
        "            kwargs.setdefault(\"temperature\", 0.001)\n",
        "            kwargs.setdefault(\"num_return_sequences\", getattr(self.args, \"num_generations\", 4))\n",
        "            kwargs.setdefault(\"use_cache\", False)\n",
        "            kwargs.setdefault(\"min_new_tokens\", 16)             # guard in TRAIN too\n",
        "        else:\n",
        "            for k, v in self._eval_generation_kwargs.items():\n",
        "                kwargs.setdefault(k, v)\n",
        "            kwargs.setdefault(\"use_cache\", True)\n",
        "            kwargs.setdefault(\"min_new_tokens\", 16)\n",
        "\n",
        "        kwargs.setdefault(\"max_new_tokens\", getattr(self.args, \"max_completion_length\", 500))\n",
        "\n",
        "        return self.model.generate(**kwargs)\n",
        "\n",
        "    def _maybe_switch_to_full_eval(self):\n",
        "        if self._final_eval_done or self._full_eval_ds is None:\n",
        "            return\n",
        "        self.eval_dataset = self._full_eval_ds\n",
        "        self._final_eval_done = True\n",
        "\n",
        "    def evaluation_loop(self, *args, **kwargs):\n",
        "        state = getattr(self, \"state\", None)\n",
        "        at_end = state is not None and state.global_step >= self.args.max_steps\n",
        "        if at_end:\n",
        "            self._maybe_switch_to_full_eval()\n",
        "        return super().evaluation_loop(*args, **kwargs)\n",
        "\n",
        "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str=\"eval\"):\n",
        "        ds = eval_dataset or self.eval_dataset\n",
        "        base = super().evaluate(ds, ignore_keys, metric_key_prefix)\n",
        "        print(f\"[gen-eval-base] {base}\")\n",
        "        return base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56178722-ea11-4c07-926b-bc214b6dba50",
      "metadata": {
        "id": "56178722-ea11-4c07-926b-bc214b6dba50"
      },
      "outputs": [],
      "source": [
        "#@title Cell 5a Training - Reward Function Helpers\n",
        "\n",
        "#granular bad scores\n",
        "import json, re\n",
        "from typing import Any, Dict, List, Tuple, Set\n",
        "\n",
        "EDGE_TYPES = {\"IS_PART_OF\",\"REFERENCES\",\"DEFINES\",\"USES\",\"MENTION_PARTY\",\"CONTAINS\"}\n",
        "NODE_TYPES = {\"CLAUSE\",\"DEFINED_TERM\",\"PARTY\",\"VALUE\"}\n",
        "\n",
        "#helpers\n",
        "def _balanced_braces(s: str) -> bool:\n",
        "    cnt = 0\n",
        "    for ch in s:\n",
        "        if ch == \"{\": cnt += 1\n",
        "        elif ch == \"}\": cnt -= 1\n",
        "        if cnt < 0: return False\n",
        "    return cnt == 0\n",
        "\n",
        "def _ends_clean(s: str) -> bool:\n",
        "    t = s.rstrip()\n",
        "    return t.endswith(\"}\")\n",
        "\n",
        "def _graph_sets(obj: Dict) -> Tuple[Set[Tuple], Set[Tuple]]:\n",
        "    nodes = {(n.get(\"id\",\"\"), (n.get(\"node_type\",\"\") or \"\").upper()) for n in obj.get(\"nodes\", []) if isinstance(n, dict)}\n",
        "    edges = {(\n",
        "        e.get(\"src\",\"\"), e.get(\"tgt\",\"\"),\n",
        "        (e.get(\"type\",\"\") or \"\").upper()\n",
        "    ) for e in obj.get(\"edges\", []) if isinstance(e, dict)}\n",
        "    return nodes, edges\n",
        "\n",
        "def _f1(pred: Set[Tuple], gold: Set[Tuple]) -> float:\n",
        "    if not pred and not gold: return 1.0\n",
        "    if not pred or not gold:  return 0.0\n",
        "    tp = len(pred & gold)\n",
        "    if tp == 0: return 0.0\n",
        "    prec = tp / len(pred); rec = tp / len(gold)\n",
        "    return 2*prec*rec/(prec+rec)\n",
        "\n",
        "#reward\n",
        "def shaped_reward(completion: str, gold: Dict, f1_weight: float = 0.30) -> float:\n",
        "    s = completion or \"\"\n",
        "    score = 0.0\n",
        "\n",
        "    # A) token-level shape (0.12)\n",
        "    t = s.lstrip()\n",
        "    if t.startswith(\"{\"): score += 0.03\n",
        "    if s.rstrip().endswith(\"}\"): score += 0.03\n",
        "    if _balanced_braces(s): score += 0.04\n",
        "    if \"```\" in s: score -= 0.02  # discourage fences\n",
        "\n",
        "    # B) strict parse (0.10)\n",
        "    parsed = None\n",
        "    try:\n",
        "        parsed = json.loads(s)\n",
        "        score += 0.10\n",
        "    except Exception:\n",
        "        # no JSON → stop here; we still return early-shaping score\n",
        "        return max(0.0, score)\n",
        "\n",
        "    if not isinstance(parsed, dict):\n",
        "        return max(0.0, score)  # we only accept dict at top-level\n",
        "\n",
        "    # C) top-level keys / arrays (0.20)\n",
        "    nodes = parsed.get(\"nodes\", None)\n",
        "    edges = parsed.get(\"edges\", None)\n",
        "\n",
        "    # nodes presence/shape\n",
        "    if \"nodes\" in parsed: score += 0.05\n",
        "    if isinstance(nodes, list): score += 0.03\n",
        "    if isinstance(nodes, list) and len(nodes) > 0: score += 0.07\n",
        "\n",
        "    # edges presence/shape\n",
        "    if \"edges\" in parsed: score += 0.05\n",
        "    if isinstance(edges, list): score += 0.03\n",
        "    if isinstance(edges, list) and len(edges) > 0: score += 0.07\n",
        "\n",
        "    # D) item quality (0.18)\n",
        "    #   nodes quality (0.09)\n",
        "    if isinstance(nodes, list) and len(nodes) > 0:\n",
        "        good = 0\n",
        "        for n in nodes:\n",
        "            if isinstance(n, dict) and n.get(\"id\") and (n.get(\"node_type\",\"\").upper() in NODE_TYPES):\n",
        "                good += 1\n",
        "        score += 0.09 * (good / max(1, len(nodes)))\n",
        "\n",
        "    #   edges quality (0.09)\n",
        "    if isinstance(edges, list) and len(edges) > 0:\n",
        "        good = 0\n",
        "        for e in edges:\n",
        "            if (isinstance(e, dict) and e.get(\"src\") and e.get(\"tgt\")\n",
        "                and (e.get(\"type\",\"\").upper() in EDGE_TYPES)):\n",
        "                good += 1\n",
        "        score += 0.09 * (good / max(1, len(edges)))\n",
        "\n",
        "        # small uniqueness bonus\n",
        "        if len({(e.get(\"src\",\"\"), e.get(\"tgt\",\"\"), e.get(\"type\",\"\")) for e in edges if isinstance(e, dict)}) == len(edges):\n",
        "            score += 0.02\n",
        "\n",
        "    # E) closure & compactness (0.10)\n",
        "    if _ends_clean(s): score += 0.05\n",
        "    try:\n",
        "        compact = json.dumps(parsed, separators=(\",\",\":\"))\n",
        "        if len(s) > 0 and (len(s) - len(compact))/len(s) < 0.15:\n",
        "            score += 0.05\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # F) task score vs gold (0.30 by default; tune 0.40 later in training)\n",
        "    try:\n",
        "        pn, pe = _graph_sets(parsed)\n",
        "        if isinstance(gold, str):\n",
        "            gold = json.loads(gold)\n",
        "        gn, ge = _graph_sets(gold if isinstance(gold, dict) else {})\n",
        "        fn, fe = _f1(pn, gn), _f1(pe, ge)\n",
        "        h = 0.0 if (fn+fe) == 0.0 else (2*fn*fe)/(fn+fe)\n",
        "        score += f1_weight * h\n",
        "    except Exception:\n",
        "        # if anything fails here, keep the structural reward only\n",
        "        pass\n",
        "\n",
        "    # clamp\n",
        "    return max(0.0, min(1.0, score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa615ba-b424-4f95-81aa-42c824ebee22",
      "metadata": {
        "id": "3aa615ba-b424-4f95-81aa-42c824ebee22"
      },
      "outputs": [],
      "source": [
        "#@title Cell 5b Training - Reward Group Adapter\n",
        "\n",
        "import hashlib, numpy as np\n",
        "from typing import List\n",
        "\n",
        "def _prompt_key(p: str) -> str:\n",
        "    import hashlib\n",
        "    return hashlib.sha1(p.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def reward_group_adapter(prompts: List[str], completions: List[str], **kwargs) -> List[float]:\n",
        "    num_prompts = len(prompts)\n",
        "    num_completions = len(completions)\n",
        "    assert num_prompts > 0 and num_completions % num_prompts == 0, \\\n",
        "        f\"Shape mismatch: prompts={num_prompts}, completions={num_completions}\"\n",
        "    group_size = num_completions // num_prompts\n",
        "\n",
        "    # fetch gold once per prompt\n",
        "    gold_cache, golds = {}, []\n",
        "    for p in prompts:\n",
        "        k = _prompt_key(p)\n",
        "        if k not in gold_cache:\n",
        "            cid, contid = extract_clause_id_contract_id_from_prompt(p)\n",
        "            gold_cache[k] = fetch_gold_completions(cid, contid, gold_index=full_index)\n",
        "        golds.append(gold_cache[k])\n",
        "\n",
        "    rewards = []\n",
        "    per_prompt_var, per_prompt_mean = [], []\n",
        "    zero_var_groups = 0\n",
        "\n",
        "    idx = 0\n",
        "    for g in golds:\n",
        "        grp = completions[idx: idx + group_size]\n",
        "        idx += group_size\n",
        "        grp_rewards = [shaped_reward(c, g, f1_weight=0.30) for c in grp]\n",
        "        rewards.extend(grp_rewards)\n",
        "\n",
        "        v = float(np.var(grp_rewards)) if len(grp_rewards) > 1 else 0.0\n",
        "        m = float(np.mean(grp_rewards))\n",
        "        per_prompt_var.append(v); per_prompt_mean.append(m)\n",
        "        if v == 0.0: zero_var_groups += 1\n",
        "\n",
        "    if wandb.run:\n",
        "        wandb.log({\n",
        "            \"train/unique_prompts_in_batch\": num_prompts,\n",
        "            \"train/group_size\": group_size,\n",
        "            \"train/reward_mean_batch\": float(np.mean(rewards)),\n",
        "            \"train/reward_std_batch\": float(np.std(rewards)),\n",
        "            \"train/per_prompt_variance_mean\": float(np.mean(per_prompt_var)),\n",
        "            \"train/fraction_zero_variance_groups\": zero_var_groups / max(1, num_prompts),\n",
        "            \"train/completion_len_mean_batch\": float(np.mean([len(c) for c in completions])),\n",
        "        })\n",
        "    print(f\"prompts={num_prompts}, completions={num_completions} rewards {rewards}\" )\n",
        "\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09e94fba-e8a3-46ac-91a8-32f3030f6abc",
      "metadata": {
        "id": "09e94fba-e8a3-46ac-91a8-32f3030f6abc",
        "outputId": "00734657-a928-40be-b9b1-4a9692d5c334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sentence-transformer model for reward calculation...\n",
            "Embedding model loaded and moved to device: cuda\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 5c Training - Reward Function Helpers - Embedding-Based Rewards\n",
        "#One time setup\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "from typing import Dict, List, Tuple, Set\n",
        "\n",
        "print(\"Loading sentence-transformer model for reward calculation...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "print(\"Embedding model loaded and moved to device:\", device)\n",
        "\n",
        "NODE_TYPES = {\"CLAUSE\", \"DEFINED_TERM\", \"PARTY\", \"VALUE\"}\n",
        "EDGE_TYPES = {\"IS_PART_OF\", \"REFERENCES\", \"DEFINES\", \"USES\", \"MENTIONS_PARTY\", \"CONTAINS\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c06066-0ef3-4239-9bbc-a273d4fbe9f0",
      "metadata": {
        "id": "84c06066-0ef3-4239-9bbc-a273d4fbe9f0"
      },
      "outputs": [],
      "source": [
        "#@title Cell 5d Training - Combined Hybrid Reward Function, Helpers, and Group Adapter\n",
        "\n",
        "def _graph_to_canonical_string(obj: Dict) -> str:\n",
        "    if not isinstance(obj, dict): return \"\"\n",
        "    nodes_str = sorted([f\"({n.get('node_type', '')}:{n.get('id', '')})\" for n in obj.get(\"nodes\", []) if isinstance(n, dict)])\n",
        "    edges_str = sorted([f\"({e.get('src', '')})-({e.get('type', '')})->({e.get('tgt', '')})\" for e in obj.get(\"edges\", []) if isinstance(e, dict)])\n",
        "    return \"NODES: \" + \" \".join(nodes_str) + \" EDGES: \" + \" \".join(edges_str)\n",
        "\n",
        "\n",
        "#Hybrid Reward\n",
        "def hybrid_shaped_reward(\n",
        "    completion_str: str,\n",
        "    gold_obj: dict,\n",
        "    semantic_similarity: float,\n",
        "    structural_weight: float = 0.7,\n",
        "    semantic_weight: float = 0.3\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculates a hybrid reward based on a weighted sum of:\n",
        "    1. Structural correctness (JSON parsing, schema, etc.).\n",
        "    2. Semantic similarity of the raw text using pre-computed embeddings.\n",
        "    \"\"\"\n",
        "    s = completion_str or \"\"\n",
        "    structural_score = 0.0\n",
        "\n",
        "    # --- Part 1: Calculate Structural Score (max value of 1.0) ---\n",
        "    if s.lstrip().startswith(\"{\"): structural_score += 0.05\n",
        "    if s.rstrip().endswith(\"}\"): structural_score += 0.05\n",
        "    if _balanced_braces(s): structural_score += 0.05\n",
        "\n",
        "    # B) Strict parse (0.35)\n",
        "\n",
        "    parsed = None\n",
        "    try:\n",
        "        json_str = t[t.find('{'):t.rfind('}')+1].strip()\n",
        "        obj = json.loads(json_str)\n",
        "        structural_score = 0.3 if \"nodes\" in obj and \"edges\" in obj else 0.1\n",
        "    except json.JSONDecodeError:\n",
        "        structural_score = 0.1\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(s)\n",
        "        structural_score += 0.35\n",
        "    except Exception:\n",
        "        # Parsing failed. We stop calculating structural score but will still use the semantic score.\n",
        "        return structural_score * structural_weight + semantic_similarity * semantic_weight\n",
        "\n",
        "    if not isinstance(parsed, dict):\n",
        "        return structural_score * structural_weight + semantic_similarity * semantic_weight\n",
        "\n",
        "    # C) Top-level keys / item quality (0.50)\n",
        "    nodes = parsed.get(\"nodes\")\n",
        "    edges = parsed.get(\"edges\")\n",
        "    if isinstance(nodes, list): structural_score += 0.25\n",
        "    if isinstance(edges, list): structural_score += 0.25\n",
        "\n",
        "    # --- Part 2: Combine with Semantic Score ---\n",
        "    final_score = (structural_score * structural_weight) + (semantic_similarity * semantic_weight)\n",
        "\n",
        "    return max(0.0, min(1.0, final_score))\n",
        "\n",
        "\n",
        "def reward_group_adapter(prompts: List[str], completions: List[str], **kwargs) -> List[float]:\n",
        "    num_prompts = len(prompts)\n",
        "    num_completions = len(completions)\n",
        "    group_size = num_completions // num_prompts\n",
        "\n",
        "    gold_cache, golds_obj = {}, []\n",
        "    for p in prompts:\n",
        "        k = _prompt_key(p)\n",
        "        if k not in gold_cache:\n",
        "            try:\n",
        "                cid, contid = extract_clause_id_contract_id_from_prompt(p)\n",
        "                gold_str = fetch_gold_completions(cid, contid, gold_index=full_index)\n",
        "                gold_cache[k] = json.loads(gold_str) if gold_str else {}\n",
        "            except (ValueError, json.JSONDecodeError, TypeError):\n",
        "                gold_cache[k] = {}\n",
        "        golds_obj.append(gold_cache[k])\n",
        "\n",
        "    gold_canonical_strings = []\n",
        "    for i in range(num_prompts):\n",
        "        gold_canonical_str = _graph_to_canonical_string(golds_obj[i])\n",
        "        gold_canonical_strings.extend([gold_canonical_str] * group_size)\n",
        "\n",
        "    completion_embeddings = embedding_model.encode(completions, convert_to_tensor=True)\n",
        "    gold_embeddings = embedding_model.encode(gold_canonical_strings, convert_to_tensor=True)\n",
        "\n",
        "    similarities = F.cosine_similarity(completion_embeddings, gold_embeddings)\n",
        "    scaled_similarities = (similarities + 1) / 2\n",
        "\n",
        "    rewards = []\n",
        "    for i in range(num_completions):\n",
        "        prompt_idx = i // group_size\n",
        "        reward = hybrid_shaped_reward(\n",
        "            completions[i],\n",
        "            golds_obj[prompt_idx],\n",
        "            semantic_similarity=scaled_similarities[i].item()\n",
        "        )\n",
        "        rewards.append(reward)\n",
        "\n",
        "    if wandb.run:\n",
        "        wandb.log({\n",
        "            \"train/unique_prompts_in_batch\": num_prompts,\n",
        "            \"train/group_size\": group_size,\n",
        "            \"train/reward_mean_batch\": float(np.mean(rewards)),\n",
        "            \"train/reward_std_batch\": float(np.std(rewards)),\n",
        "            \"train/completion_len_mean_batch\": float(np.mean([len(c) for c in completions])),\n",
        "        })\n",
        "    print(f\"prompts={num_prompts}, completions={num_completions} rewards {rewards}\" )\n",
        "\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db28766b-5a38-44da-aed1-39a78c3ec815",
      "metadata": {
        "id": "db28766b-5a38-44da-aed1-39a78c3ec815"
      },
      "outputs": [],
      "source": [
        "#@title Cell 6 Training - Gated Reward Function\n",
        "\n",
        "from typing import List, Dict, Tuple\n",
        "import json, numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "    _prompt_key\n",
        "except NameError:\n",
        "    def _prompt_key(p: str) -> str:\n",
        "        return p.strip()\n",
        "\n",
        "def _balanced_braces_local(s: str) -> bool:\n",
        "    depth = 0\n",
        "    for ch in s:\n",
        "        if ch == \"{\":\n",
        "            depth += 1\n",
        "        elif ch == \"}\":\n",
        "            depth -= 1\n",
        "            if depth < 0:\n",
        "                return False\n",
        "    return depth == 0\n",
        "\n",
        "def _balanced_braces(s: str) -> bool:\n",
        "    try:\n",
        "        return globals()[\"_balanced_braces\"](s)\n",
        "    except Exception:\n",
        "        return _balanced_braces_local(s)\n",
        "\n",
        "def _graph_to_canonical_string(obj: Dict) -> str:\n",
        "    if not isinstance(obj, dict):\n",
        "        return \"\"\n",
        "    nodes_str = sorted([\n",
        "        f\"({n.get('node_type', '')}:{n.get('id', '')})\"\n",
        "        for n in obj.get(\"nodes\", [])\n",
        "        if isinstance(n, dict)\n",
        "    ])\n",
        "    edges_str = sorted([\n",
        "        f\"({e.get('src', '')})-({e.get('type', '')})->({e.get('tgt', '')})\"\n",
        "        for e in obj.get(\"edges\", [])\n",
        "        if isinstance(e, dict)\n",
        "    ])\n",
        "    return \"NODES: \" + \" \".join(nodes_str) + \" EDGES: \" + \" \".join(edges_str)\n",
        "\n",
        "def _f1_from_sets(pred: set, gold: set) -> float:\n",
        "    if not pred and not gold:\n",
        "        return 1.0\n",
        "    if not pred or not gold:\n",
        "        return 0.0\n",
        "    inter = len(pred & gold)\n",
        "    prec  = inter / max(1, len(pred))\n",
        "    rec   = inter / max(1, len(gold))\n",
        "    return 0.0 if (prec + rec) == 0 else (2 * prec * rec) / (prec + rec)\n",
        "\n",
        "def _node_sig(n: Dict) -> Tuple[str, str]:\n",
        "    return (str(n.get(\"node_type\",\"\")).strip().lower(),\n",
        "            str(n.get(\"id\",\"\")).strip().lower())\n",
        "\n",
        "def _edge_sig(e: Dict) -> Tuple[str, str, str]:\n",
        "    return (str(e.get(\"type\",\"\")).strip().lower(),\n",
        "            str(e.get(\"src\",\"\")).strip().lower(),\n",
        "            str(e.get(\"tgt\",\"\")).strip().lower())\n",
        "\n",
        "def _nodes_f1(pred_nodes, gold_nodes) -> float:\n",
        "    P = {_node_sig(n) for n in (pred_nodes or []) if isinstance(n, dict)}\n",
        "    G = {_node_sig(n) for n in (gold_nodes or []) if isinstance(n, dict)}\n",
        "    return _f1_from_sets(P, G)\n",
        "\n",
        "def _edges_f1(pred_edges, gold_edges) -> float:\n",
        "    P = {_edge_sig(e) for e in (pred_edges or []) if isinstance(e, dict)}\n",
        "    G = {_edge_sig(e) for e in (gold_edges or []) if isinstance(e, dict)}\n",
        "    return _f1_from_sets(P, G)\n",
        "\n",
        "#------------------------#\n",
        "#Weight schedule & gating\n",
        "#------------------------#\n",
        "def _weight_schedule(global_step: int,\n",
        "                     warm_steps: int = 30,\n",
        "                     add_nodes_at: int = 60,\n",
        "                     add_edges_at: int = 90,\n",
        "                     add_sem_at: int   = 120) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Returns weights for {valid, schema, nodes, edges, sem} components.\n",
        "    Progressively turns on harder components.\n",
        "    \"\"\"\n",
        "    if global_step < warm_steps:\n",
        "        return dict(valid=1.0, schema=0.0, nodes=0.0, edges=0.0, sem=0.0)\n",
        "    if global_step < add_nodes_at:\n",
        "        return dict(valid=0.7, schema=0.3, nodes=0.0, edges=0.0, sem=0.0)\n",
        "    if global_step < add_edges_at:\n",
        "        return dict(valid=0.4, schema=0.3, nodes=0.3, edges=0.0, sem=0.0)\n",
        "    if global_step < add_sem_at:\n",
        "        return dict(valid=0.3, schema=0.25, nodes=0.3, edges=0.15, sem=0.0)\n",
        "    # full objective\n",
        "    return dict(valid=0.2, schema=0.2, nodes=0.3, edges=0.2, sem=0.1)\n",
        "\n",
        "def _gated_hybrid_reward(\n",
        "    completion_str: str,\n",
        "    gold_obj: Dict,\n",
        "    semantic_similarity: float,\n",
        "    *,\n",
        "    global_step: int,\n",
        "    nodes_gate: float = 0.60,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Components (each in [0,1]):\n",
        "      - valid: braces/parse\n",
        "      - schema: nodes/edges lists present\n",
        "      - nodes: F1 over node signatures\n",
        "      - edges: F1 over edge signatures (only if nodes >= nodes_gate)\n",
        "      - sem:   your precomputed semantic similarity (only after JSON valid)\n",
        "    \"\"\"\n",
        "    s = (completion_str or \"\").strip()\n",
        "    W = _weight_schedule(global_step)\n",
        "\n",
        "    #validity (0..1)\n",
        "    starts = 1.0 if s.startswith(\"{\") else 0.0\n",
        "    ends   = 1.0 if s.endswith(\"}\") else 0.0\n",
        "    bal    = 1.0 if _balanced_braces(s) else 0.0\n",
        "    soft_hints = (starts + ends + bal) / 3.0  # heuristic\n",
        "    parsed_obj = None\n",
        "    try:\n",
        "        parsed_obj = json.loads(s)\n",
        "        parsed_ok = 1.0\n",
        "    except Exception:\n",
        "        parsed_ok = 0.0\n",
        "\n",
        "    valid_comp = 0.2 * soft_hints + 0.8 * parsed_ok\n",
        "\n",
        "    if W[\"schema\"] == W[\"nodes\"] == W[\"edges\"] == W[\"sem\"] == 0.0:\n",
        "        return float(np.clip(W[\"valid\"] * valid_comp, 0.0, 1.0))\n",
        "\n",
        "    #schema (0..1)\n",
        "    schema_comp = 0.0\n",
        "    nodes_pred, edges_pred = None, None\n",
        "    nodes_gold, edges_gold = (gold_obj or {}).get(\"nodes\", []), (gold_obj or {}).get(\"edges\", [])\n",
        "    if isinstance(parsed_obj, dict):\n",
        "        nodes_pred, edges_pred = parsed_obj.get(\"nodes\"), parsed_obj.get(\"edges\")\n",
        "        if isinstance(nodes_pred, list): schema_comp += 0.5\n",
        "        if isinstance(edges_pred, list): schema_comp += 0.5\n",
        "\n",
        "    #nodes/edges F1\n",
        "    nodes_comp = 0.0\n",
        "    edges_comp = 0.0\n",
        "    if isinstance(nodes_pred, list):\n",
        "        nodes_comp = _nodes_f1(nodes_pred, nodes_gold)\n",
        "    if nodes_comp >= nodes_gate and isinstance(edges_pred, list):\n",
        "        edges_comp = _edges_f1(edges_pred, edges_gold)\n",
        "\n",
        "    #semantic (0..1); gate on parsed_ok\n",
        "    sem_comp = float(semantic_similarity) if parsed_ok >= 1.0 else 0.0\n",
        "\n",
        "    #weights\n",
        "    reward = (\n",
        "        W[\"valid\"]  * valid_comp +\n",
        "        W[\"schema\"] * schema_comp +\n",
        "        W[\"nodes\"]  * nodes_comp +\n",
        "        W[\"edges\"]  * edges_comp +\n",
        "        W[\"sem\"]    * sem_comp\n",
        "    )\n",
        "\n",
        "    return float(np.clip(reward, 0.0, 1.0))\n",
        "_gate_internal_step = 0\n",
        "\n",
        "def _bump_gate_internal_step():\n",
        "    global _gate_internal_step\n",
        "    s = _gate_internal_step\n",
        "    _gate_internal_step += 1\n",
        "    return s\n",
        "\n",
        "#Group adapter\n",
        "def reward_group_adapter(prompts: List[str], completions: List[str], **kwargs) -> List[float]:\n",
        "    \"\"\"\n",
        "    Same signature you use with GRPO. Adds a step-aware, gated structure/semantic reward.\n",
        "    Expects these globals/utilities to exist in your notebook:\n",
        "      - extract_clause_id_contract_id_from_prompt\n",
        "      - fetch_gold_completions\n",
        "      - full_index\n",
        "      - embedding_model  (SentenceTransformer-like)\n",
        "      - wandb            (optional)\n",
        "    \"\"\"\n",
        "    global_step = kwargs.get(\"global_step\", None)\n",
        "    if global_step is None:\n",
        "        global_step = _bump_gate_internal_step()\n",
        "    else:\n",
        "        global_step = int(global_step)\n",
        "\n",
        "    num_prompts = len(prompts)\n",
        "    num_completions = len(completions)\n",
        "    assert num_prompts > 0 and num_completions % num_prompts == 0, \\\n",
        "        \"completions must be a multiple of prompts (group sampling).\"\n",
        "    group_size = num_completions // num_prompts\n",
        "\n",
        "    gold_cache: Dict[str, Dict] = {}\n",
        "    golds_obj: List[Dict] = []\n",
        "    for p in prompts:\n",
        "        k = _prompt_key(p)\n",
        "        if k not in gold_cache:\n",
        "            try:\n",
        "                clause_id, contract_id = extract_clause_id_contract_id_from_prompt(p)\n",
        "                gold_str = fetch_gold_completions(clause_id, contract_id, gold_index=full_index)\n",
        "                gold_cache[k] = json.loads(gold_str) if gold_str else {}\n",
        "            except Exception:\n",
        "                gold_cache[k] = {}\n",
        "        golds_obj.append(gold_cache[k])\n",
        "\n",
        "    gold_canonical_strings: List[str] = []\n",
        "    for i in range(num_prompts):\n",
        "        gold_canonical_str = _graph_to_canonical_string(golds_obj[i])\n",
        "        gold_canonical_strings.extend([gold_canonical_str] * group_size)\n",
        "\n",
        "    completion_embeddings = embedding_model.encode(completions, convert_to_tensor=True)\n",
        "    gold_embeddings = embedding_model.encode(gold_canonical_strings, convert_to_tensor=True)\n",
        "    completion_embeddings = F.normalize(completion_embeddings, p=2, dim=1)\n",
        "    gold_embeddings = F.normalize(gold_embeddings, p=2, dim=1)\n",
        "\n",
        "    cos = F.cosine_similarity(completion_embeddings, gold_embeddings)\n",
        "    sem_sims = ((cos + 1.0) / 2.0).clamp(0.0, 1.0)  # to [0,1]\n",
        "    sem_sims = sem_sims.detach().cpu().tolist()\n",
        "\n",
        "    rewards: List[float] = []\n",
        "    for i in range(num_completions):\n",
        "        prompt_idx = i // group_size\n",
        "        r = _gated_hybrid_reward(\n",
        "            completion_str=completions[i],\n",
        "            gold_obj=golds_obj[prompt_idx],\n",
        "            semantic_similarity=sem_sims[i],\n",
        "            global_step=global_step,\n",
        "        )\n",
        "        rewards.append(r)\n",
        "\n",
        "    if \"wandb\" in globals() and getattr(wandb, \"run\", None):\n",
        "        W = _weight_schedule(global_step)\n",
        "        wandb.log({\n",
        "            \"train/unique_prompts_in_batch\": num_prompts,\n",
        "            \"train/group_size\": group_size,\n",
        "            \"train/reward_mean_batch\": float(np.mean(rewards)),\n",
        "            \"train/reward_std_batch\": float(np.std(rewards)),\n",
        "            \"train/completion_len_mean_batch\": float(np.mean([len(c) for c in completions])),\n",
        "            \"train/reward_w_valid\": W[\"valid\"],\n",
        "            \"train/reward_w_schema\": W[\"schema\"],\n",
        "            \"train/reward_w_nodes\": W[\"nodes\"],\n",
        "            \"train/reward_w_edges\": W[\"edges\"],\n",
        "            \"train/reward_w_sem\": W[\"sem\"],\n",
        "            \"train/global_step_for_reward\": global_step,\n",
        "        })\n",
        "    print(f\"prompts={num_prompts}, completions={num_completions}, step={global_step} rewards (first 8) {rewards[:8]}\")\n",
        "\n",
        "    return rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2867d34d-a05a-4801-92b5-cd8a1a1a3c97",
      "metadata": {
        "id": "2867d34d-a05a-4801-92b5-cd8a1a1a3c97",
        "outputId": "095dd3f7-6a34-4747-c0b0-5eb852002f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.SmartNewJsonStopper'> True\n"
          ]
        }
      ],
      "source": [
        "print(type(json_stopper), issubclass(type(json_stopper), StoppingCriteria))  # should be True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78817d06-a201-4cba-b602-d36c161d5b64",
      "metadata": {
        "id": "78817d06-a201-4cba-b602-d36c161d5b64"
      },
      "outputs": [],
      "source": [
        "#@title Cell 7a Training - Instantiate the Trainer\n",
        "# --- Trainer ---\n",
        "trainer = GRPOTrainerWithEvalControls(\n",
        "    model=model,\n",
        "    reward_funcs=[reward_group_adapter],\n",
        "    args=grpo_cfg,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds_small,\n",
        "    processing_class=tokenizer,\n",
        "    eval_generation_kwargs=eval_generation_kwargs,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63922fef-0601-413b-a4bc-45bcf0ecef0d",
      "metadata": {
        "id": "63922fef-0601-413b-a4bc-45bcf0ecef0d"
      },
      "outputs": [],
      "source": [
        "#@title Cell 7b Training - Custom generation stoppers and masks\n",
        "\n",
        "import re, torch\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList, LogitsProcessor, LogitsProcessorList\n",
        "\n",
        "#ASCII clamp\n",
        "def _build_ascii_allow_mask(tokenizer) -> torch.BoolTensor:\n",
        "    if getattr(tokenizer, \"_ascii_allow_mask\", None) is not None:\n",
        "        return tokenizer._ascii_allow_mask\n",
        "    V = tokenizer.vocab_size\n",
        "    allow = torch.zeros(V, dtype=torch.bool)\n",
        "    ascii_ok = re.compile(r'^[\\x09\\x0a\\x0d\\x20-\\x7e]+$')\n",
        "    specials = {\n",
        "        getattr(tokenizer, k)\n",
        "        for k in (\"eos_token_id\",\"pad_token_id\",\"bos_token_id\",\"unk_token_id\")\n",
        "        if getattr(tokenizer, k, None) is not None\n",
        "    }\n",
        "    for tid in range(V):\n",
        "        if tid in specials:\n",
        "            allow[tid] = True\n",
        "            continue\n",
        "        s = tokenizer.decode([tid], skip_special_tokens=True)\n",
        "        if s == \"\" or ascii_ok.match(s):\n",
        "            allow[tid] = True\n",
        "    tokenizer._ascii_allow_mask = allow\n",
        "    return allow\n",
        "\n",
        "import re, torch\n",
        "from transformers import LogitsProcessor, LogitsProcessorList\n",
        "\n",
        "class AsciiClamp(LogitsProcessor):\n",
        "    \"\"\"\n",
        "    Keeps generation in ASCII space by masking non-ASCII token pieces.\n",
        "    Auto-rebuilds the mask to match the current logits vocab size.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tok = tokenizer\n",
        "        self._mask = None\n",
        "        self._built_for = None\n",
        "        self._neg_inf = torch.finfo(torch.float32).min\n",
        "        self._ascii_ok = re.compile(r'^[\\x09\\x0a\\x0d\\x20-\\x7e]+$')\n",
        "\n",
        "    def _build_mask(self, V: int, device: torch.device):\n",
        "        allow = torch.zeros(V, dtype=torch.bool)\n",
        "        specials = {\n",
        "            getattr(self.tok, k)\n",
        "            for k in (\"eos_token_id\",\"pad_token_id\",\"bos_token_id\",\"unk_token_id\")\n",
        "            if getattr(self.tok, k, None) is not None\n",
        "        }\n",
        "        for tid in range(V):\n",
        "            if tid in specials:\n",
        "                allow[tid] = True\n",
        "                continue\n",
        "            try:\n",
        "                s = self.tok.decode([tid], skip_special_tokens=True)\n",
        "            except Exception:\n",
        "                s = \"\"\n",
        "            allow[tid] = (s == \"\" or self._ascii_ok.match(s) is not None)\n",
        "        self._mask = allow.to(device)\n",
        "        self._built_for = V\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        V = scores.shape[-1]\n",
        "        if self._mask is None or self._built_for != V or self._mask.device != scores.device:\n",
        "            self._build_mask(V, scores.device)\n",
        "        scores[:, ~self._mask] = self._neg_inf\n",
        "        return scores\n",
        "\n",
        "\n",
        "#sanitizer\n",
        "def _sanitize_sc(sc_like) -> StoppingCriteriaList:\n",
        "    def _valid(c): return isinstance(c, StoppingCriteria) and (type(c) is not StoppingCriteria)\n",
        "    out = []\n",
        "    if sc_like is None:\n",
        "        pass\n",
        "    elif isinstance(sc_like, StoppingCriteriaList):\n",
        "        out.extend([c for c in list(sc_like) if _valid(c)])\n",
        "    elif isinstance(sc_like, (list, tuple, set)):\n",
        "        for x in sc_like:\n",
        "            if isinstance(x, StoppingCriteriaList):\n",
        "                out.extend([c for c in list(x) if _valid(c)])\n",
        "            elif _valid(x):\n",
        "                out.append(x)\n",
        "    elif _valid(sc_like):\n",
        "        out.append(sc_like)\n",
        "    seen, dedup = set(), []\n",
        "    for c in out:\n",
        "        if id(c) not in seen:\n",
        "            dedup.append(c); seen.add(id(c))\n",
        "    return StoppingCriteriaList(dedup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d021e49c-4d07-459c-839a-ed0621ea4937",
      "metadata": {
        "id": "d021e49c-4d07-459c-839a-ed0621ea4937"
      },
      "outputs": [],
      "source": [
        "#@title Cell 7c Training - Wrap generation call with custom stoppers and masks\n",
        "\n",
        "import types\n",
        "\n",
        "def _has_class_generate(obj) -> bool:\n",
        "    try:\n",
        "        return callable(getattr(obj.__class__, \"generate\"))\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _resolve_generate_target(root):\n",
        "    \"\"\"\n",
        "    Climb through common PEFT/Accelerate wrappers to find an object whose CLASS defines `generate`.\n",
        "    Returns None if not found.\n",
        "    \"\"\"\n",
        "    seen = set()\n",
        "    def _walk(o):\n",
        "        if o is None or id(o) in seen:\n",
        "            return None\n",
        "        seen.add(id(o))\n",
        "        if _has_class_generate(o):\n",
        "            return o\n",
        "        # descend typical wrappers\n",
        "        for attr in (\"model\", \"module\", \"base_model\"):\n",
        "            nxt = getattr(o, attr, None)\n",
        "            tgt = _walk(nxt)\n",
        "            if tgt is not None:\n",
        "                return tgt\n",
        "        return None\n",
        "    return _walk(root)\n",
        "\n",
        "def wrap_generate_with_stopper_and_ascii(root_obj, tokenizer, stopper,\n",
        "                                         *, add_ascii_in_train=True,\n",
        "                                         min_new_tokens=24, max_new_tokens=350,\n",
        "                                         temperature=0.2, top_p=0.9, top_k=0):\n",
        "    \"\"\"\n",
        "    One wrapper: append JSON stopper (train+eval) + ASCII clamp (train only),\n",
        "    set tight train defaults, strip unknown kwargs. Safe on PEFT/Accelerate stacks.\n",
        "    \"\"\"\n",
        "    target = _resolve_generate_target(root_obj)\n",
        "    if target is None or getattr(target, \"_gen_guard_installed\", False):\n",
        "        return\n",
        "\n",
        "    #reset\n",
        "    target.generate = target.__class__.generate.__get__(target, target.__class__)\n",
        "    class_orig = target.__class__.generate\n",
        "\n",
        "    def _wrapped(self, *args, **kwargs):\n",
        "        #sanitize\n",
        "        sc = _sanitize_sc(kwargs.get(\"stopping_criteria\", None))\n",
        "        if all(c is not stopper for c in sc):\n",
        "            sc.append(stopper)\n",
        "        kwargs[\"stopping_criteria\"] = sc\n",
        "\n",
        "        #ASCII clamp\n",
        "        if add_ascii_in_train and self.training:\n",
        "            lp = kwargs.get(\"logits_processor\", None)\n",
        "            clamp = AsciiClamp(tokenizer)\n",
        "            if lp is None:\n",
        "                kwargs[\"logits_processor\"] = LogitsProcessorList([clamp])\n",
        "            else:\n",
        "                try:\n",
        "                    lp.append(clamp)\n",
        "                    kwargs[\"logits_processor\"] = lp\n",
        "                except Exception:\n",
        "                    kwargs[\"logits_processor\"] = LogitsProcessorList(list(lp) + [clamp])\n",
        "\n",
        "        #verify appropriate config defaults\n",
        "        if self.training:\n",
        "            kwargs.setdefault(\"do_sample\", True)\n",
        "            kwargs.setdefault(\"temperature\", temperature)\n",
        "            if top_k and top_k > 0:\n",
        "                kwargs.setdefault(\"top_k\", top_k); kwargs.setdefault(\"top_p\", 1.0)\n",
        "            else:\n",
        "                kwargs.setdefault(\"top_p\", top_p); kwargs.setdefault(\"top_k\", 0)\n",
        "            kwargs.setdefault(\"min_new_tokens\", min_new_tokens)\n",
        "            kwargs.setdefault(\"max_new_tokens\", max_new_tokens)\n",
        "\n",
        "        kwargs.pop(\"processing_class\", None)\n",
        "        kwargs.pop(\"generation_kwargs\", None)\n",
        "\n",
        "        return class_orig(self, *args, **kwargs)\n",
        "\n",
        "    target.generate = _wrapped.__get__(target, target.__class__)\n",
        "    target._gen_guard_installed = True\n",
        "    print(f\"[ok] stopper+ascii attached to {type(target).__name__}.generate\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f92711b-24c8-4a70-bc08-d86f1b63fd9b",
      "metadata": {
        "id": "5f92711b-24c8-4a70-bc08-d86f1b63fd9b",
        "outputId": "3ff19b87-0b2b-4452-a710-35208964b604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ok] stopper+ascii attached to PeftModelForCausalLM.generate\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 7d Training - Attach wrapper to trainer\n",
        "wrap_generate_with_stopper_and_ascii(trainer.model, tokenizer, json_stopper)\n",
        "\n",
        "if getattr(trainer, \"accelerator\", None):\n",
        "    try:\n",
        "        unwrapped = trainer.accelerator.unwrap_model(trainer.model)\n",
        "        if unwrapped is not trainer.model:\n",
        "            wrap_generate_with_stopper_and_ascii(unwrapped, tokenizer, json_stopper)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if hasattr(trainer.model, \"module\"):\n",
        "    wrap_generate_with_stopper_and_ascii(trainer.model.module, tokenizer, json_stopper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dbc6ccc-f553-4129-86e5-97883af8b493",
      "metadata": {
        "id": "2dbc6ccc-f553-4129-86e5-97883af8b493"
      },
      "outputs": [],
      "source": [
        "#@title Cell 8a Training Evaluation - Custom Graph Metrics For in-training evaluation\n",
        "\n",
        "import json, re\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple, Set\n",
        "\n",
        "def _safe_json(obj, max_depth=3):\n",
        "    x = obj\n",
        "    for _ in range(max_depth):\n",
        "        if isinstance(x, (dict, list)): return x\n",
        "        if x is None: return {}\n",
        "        s = str(x).strip()\n",
        "        i, j = s.find(\"{\"), s.rfind(\"}\")\n",
        "        cand = s[i:j+1] if (i!=-1 and j!=-1 and j>i) else s\n",
        "        try:\n",
        "            x = json.loads(cand); continue\n",
        "        except Exception:\n",
        "            break\n",
        "    return {}\n",
        "\n",
        "def _extract_nodes(o: Dict) -> List[Dict]:\n",
        "    arr = o.get(\"nodes\", []) if isinstance(o, dict) else []\n",
        "    if isinstance(arr, dict): arr = [arr]\n",
        "    out=[]\n",
        "    for it in arr:\n",
        "        if isinstance(it, dict): out.append(it)\n",
        "        elif isinstance(it, str):\n",
        "            try:\n",
        "                d=json.loads(it);\n",
        "                if isinstance(d, dict): out.append(d)\n",
        "            except: pass\n",
        "    return out\n",
        "\n",
        "def _extract_edges(o: Dict) -> List[Dict]:\n",
        "    arr = o.get(\"edges\", []) if isinstance(o, dict) else []\n",
        "    if isinstance(arr, dict): arr = [arr]\n",
        "    out=[]\n",
        "    for it in arr:\n",
        "        if isinstance(it, dict): out.append(it)\n",
        "        elif isinstance(it, str):\n",
        "            try:\n",
        "                d=json.loads(it);\n",
        "                if isinstance(d, dict): out.append(d)\n",
        "            except: pass\n",
        "    return out\n",
        "\n",
        "_WS_RE  = re.compile(r\"\\s+\")\n",
        "_CO_RE  = re.compile(r\"\\b(inc\\.?|ltd\\.?|llc|l\\.l\\.c\\.|corp\\.?|co\\.?|ag|gmbh)\\b\", re.I)\n",
        "_PCT_RE = re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*%\")\n",
        "_MON_RE = re.compile(r\"(\\$|usd)\\s*([\\d,]+(?:\\.\\d+)?)\", re.I)\n",
        "_DAY_RE = re.compile(r\"(\\d+)\\s*days?\")\n",
        "_YRS_RE = re.compile(r\"(\\d+)\\s*years?\")\n",
        "_NUMW   = {\"zero\":0,\"one\":1,\"two\":2,\"three\":3,\"four\":4,\"five\":5,\"six\":6,\"seven\":7,\"eight\":8,\"nine\":9,\n",
        "           \"ten\":10,\"eleven\":11,\"twelve\":12,\"thirteen\":13,\"fourteen\":14,\"fifteen\":15,\"sixteen\":16,\n",
        "           \"seventeen\":17,\"eighteen\":18,\"nineteen\":19,\"twenty\":20,\"thirty\":30,\"forty\":40,\"fifty\":50,\n",
        "           \"sixty\":60,\"seventy\":70,\"eighty\":80,\"ninety\":90}\n",
        "\n",
        "def _norm(s):\n",
        "    if not isinstance(s, str): s = str(s) if s is not None else \"\"\n",
        "    s = s.lower().replace(\"&\",\"and\")\n",
        "    s = _CO_RE.sub(\"\", s)\n",
        "    return _WS_RE.sub(\" \", s).strip()\n",
        "\n",
        "def _w2n(s):\n",
        "    s=s.lower()\n",
        "    for w,n in _NUMW.items():\n",
        "        if re.search(rf\"\\b{w}\\b\", s): return n\n",
        "    return None\n",
        "\n",
        "def _canon_value(text):\n",
        "    s=_norm(text)\n",
        "    m=_PCT_RE.search(s)\n",
        "    if m: return f\"{float(m.group(1)):.0f}%\"\n",
        "    if \"percent\" in s:\n",
        "        n=_w2n(s)\n",
        "        if n is not None: return f\"{n}%\"\n",
        "    m=_MON_RE.search(s)\n",
        "    if m: return f\"usd {m.group(2).replace(',','')}\"\n",
        "    m=_DAY_RE.search(s)\n",
        "    if m: return f\"{int(m.group(1))} days\"\n",
        "    m=_YRS_RE.search(s)\n",
        "    if m: return f\"{int(m.group(1))} years\"\n",
        "    return s\n",
        "\n",
        "def _keytext(n: Dict) -> Tuple[str,str]:\n",
        "    # supports \"node_type\" or \"type\"\n",
        "    t=(n.get(\"node_type\") or n.get(\"type\") or \"\").upper()\n",
        "    nid=str(n.get(\"id\") or \"\")\n",
        "    if t==\"CLAUSE\":\n",
        "        k=n.get(\"id\") or nid or n.get(\"title\") or \"\"; return t,_norm(k)\n",
        "    if t==\"DEFINED_TERM\":\n",
        "        k=n.get(\"name\") or nid.split(\":\",1)[-1]; return t,_norm(k)\n",
        "    if t==\"PARTY\":\n",
        "        k=n.get(\"name\") or n.get(\"text\") or nid.split(\":\",1)[-1]; return t,_norm(k)\n",
        "    if t==\"VALUE\":\n",
        "        k=n.get(\"text\") or nid.split(\":\",1)[-1]; return t,_canon_value(k)\n",
        "    k=n.get(\"text\") or n.get(\"term\") or n.get(\"name\") or nid; return t,_norm(k)\n",
        "\n",
        "def _toks(s): return re.findall(r\"[a-z0-9]+\", s.lower())\n",
        "def _jacc(a,b):\n",
        "    sa,sb=set(_toks(a)),set(_toks(b))\n",
        "    if not sa and not sb: return 1.0 if a.strip()==b.strip() and a.strip()!=\"\" else 0.0\n",
        "    if not sa or not sb:  return 0.0\n",
        "    return len(sa&sb)/max(1,len(sa|sb))\n",
        "\n",
        "_THRESH={\"CLAUSE\":0.90,\"DEFINED_TERM\":0.80,\"PARTY\":0.85,\"VALUE\":0.75}\n",
        "def _sim(t,a,b):\n",
        "    if t==\"VALUE\":\n",
        "        if a==b and (a.endswith(\"%\") or a.endswith(\"days\") or a.endswith(\"years\") or a.startswith(\"usd\")): return 1.0\n",
        "    return _jacc(a,b)\n",
        "\n",
        "def _bucket(nodes: List[Dict]):\n",
        "    b=defaultdict(list)\n",
        "    for n in nodes:\n",
        "        t,kt=_keytext(n)\n",
        "        if t and kt: b[t].append(kt)\n",
        "    return b\n",
        "\n",
        "def _match_type(G_list, P_list, t):\n",
        "    if not G_list or not P_list: return 0\n",
        "    pairs=[]\n",
        "    for i,g in enumerate(G_list):\n",
        "        for j,p in enumerate(P_list):\n",
        "            s=_sim(t,g,p)\n",
        "            if s>=_THRESH.get(t,0.8): pairs.append((s,i,j))\n",
        "    pairs.sort(reverse=True)\n",
        "    used_i=set(); used_j=set(); tp=0\n",
        "    for s,i,j in pairs:\n",
        "        if i in used_i or j in used_j: continue\n",
        "        used_i.add(i); used_j.add(j); tp+=1\n",
        "    return tp\n",
        "\n",
        "def _prf1(tp,fp,fn):\n",
        "    p=tp/(tp+fp) if (tp+fp) else 0.0\n",
        "    r=tp/(tp+fn) if (tp+fn) else 0.0\n",
        "    f=2*p*r/(p+r) if (p+r) else 0.0\n",
        "    return p,r,f\n",
        "\n",
        "def _edge_triplet(e, node_map):\n",
        "    def pick(d, keys):\n",
        "        return next((d[k] for k in keys if k in d and d[k] is not None), None)\n",
        "    typ = (pick(e, [\"type\",\"edge_type\",\"label\"]) or \"\").upper()\n",
        "    raw_src = pick(e, [\"src\",\"source\",\"from\"])\n",
        "    raw_tgt = pick(e, [\"tgt\",\"target\",\"to\"])\n",
        "    def resolve(v):\n",
        "        if v is None: return \"\"\n",
        "        v_str = str(v)\n",
        "        return node_map.get(v_str, _norm(v_str))\n",
        "    return (resolve(raw_src), typ, resolve(raw_tgt))\n",
        "\n",
        "def compute_graph_metrics_on_texts(pred_texts: List[str], gold_texts: List[str]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute strict/fuzzy node micro-F1 and edge micro-F1 from decoded strings.\n",
        "    \"\"\"\n",
        "    strict_tp=strict_fp=strict_fn=0\n",
        "    fuzzy_tp=fuzzy_fp=fuzzy_fn=0\n",
        "    e_tp=e_fp=e_fn=0\n",
        "    exact=invalid=0\n",
        "\n",
        "    def setify_strict(nodes):\n",
        "        S=set()\n",
        "        for nn in nodes:\n",
        "            t,k=_keytext(nn)\n",
        "            if t and k: S.add((t,k))\n",
        "        return S\n",
        "\n",
        "    for gstr,pstr in zip(gold_texts, pred_texts):\n",
        "        G_json=_safe_json(gstr); P_json=_safe_json(pstr)\n",
        "        G_nodes=_extract_nodes(G_json)\n",
        "        P_nodes=_extract_nodes(P_json)\n",
        "\n",
        "        if not isinstance(P_json, dict) or (\"nodes\" not in P_json and \"edges\" not in P_json):\n",
        "            print(f\"in calc metrics on eval {pstr}\")\n",
        "            invalid+=1\n",
        "\n",
        "        # strict node sets\n",
        "        Gs, Ps = setify_strict(G_nodes), setify_strict(P_nodes)\n",
        "        if Gs==Ps: exact+=1\n",
        "        strict_tp+=len(Gs&Ps); strict_fp+=len(Ps-Gs); strict_fn+=len(Gs-Ps)\n",
        "\n",
        "        # fuzzy nodes\n",
        "        Gb,_Pb = _bucket(G_nodes), _bucket(P_nodes)\n",
        "        all_types = set(Gb.keys()) | set(_Pb.keys())\n",
        "        for t in all_types:\n",
        "            tp=_match_type(Gb.get(t,[]), _Pb.get(t,[]), t)\n",
        "            fp=len(_Pb.get(t,[]))-tp; fn=len(Gb.get(t,[]))-tp\n",
        "            fuzzy_tp+=tp; fuzzy_fp+=fp; fuzzy_fn+=fn\n",
        "\n",
        "        # edges (map node ids -> canonical keytext, then compare triples)\n",
        "        def build_map(nodes):\n",
        "            m={}\n",
        "            for n in nodes:\n",
        "                nid=str(n.get(\"id\") or \"\")\n",
        "                if not nid: continue\n",
        "                t,k=_keytext(n)\n",
        "                m[nid]=f\"{t}|{k}\"\n",
        "            return m\n",
        "\n",
        "        Gmap, Pmap=build_map(G_nodes), build_map(P_nodes)\n",
        "        Ge={_edge_triplet(e,Gmap) for e in _extract_edges(G_json)}\n",
        "        Pe={_edge_triplet(e,Pmap) for e in _extract_edges(P_json)}\n",
        "        e_tp+=len(Ge&Pe); e_fp+=len(Pe-Ge); e_fn+=len(Ge-Pe)\n",
        "\n",
        "    sp,sr,sf1 = _prf1(strict_tp,strict_fp,strict_fn)\n",
        "    fp_,fr_,ff1 = _prf1(fuzzy_tp,fuzzy_fp,fuzzy_fn)\n",
        "    ep,er,ef1   = _prf1(e_tp,e_fp,e_fn)\n",
        "\n",
        "    n=max(1,len(pred_texts))\n",
        "    return {\n",
        "        \"strict_node_precision\": sp, \"strict_node_recall\": sr, \"strict_node_f1\": sf1,\n",
        "        \"fuzzy_node_precision\":  fp_, \"fuzzy_node_recall\": fr_, \"fuzzy_node_f1\": ff1,\n",
        "        \"edge_precision\":        ep,  \"edge_recall\":       er,  \"edge_f1\":       ef1,\n",
        "        \"exact_graph_match_rate\": exact/n,\n",
        "        \"invalid_json_rate\":      invalid/n,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b78caab-6e60-4854-a38b-b06e69d09467",
      "metadata": {
        "id": "9b78caab-6e60-4854-a38b-b06e69d09467"
      },
      "outputs": [],
      "source": [
        "#@title Cell 8b Training Evaluation -  Custom GRPO Evaluator Using Model Generation\n",
        "\n",
        "import gc, time, math, numpy as np, torch, re\n",
        "from typing import Dict, List\n",
        "from tqdm import tqdm\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "from transformers.trainer_utils import speed_metrics\n",
        "import wandb\n",
        "\n",
        "class JsonStopper(StoppingCriteria):\n",
        "    \"\"\"Batch-wide stopper for left-padded prompts; stops when nodes+edges JSON is complete.\"\"\"\n",
        "    def __init__(self, tokenizer, input_len: int):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_len = int(input_len)\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        gen_ids = input_ids[0, self.input_len:]\n",
        "        if gen_ids.numel() == 0:\n",
        "            return False\n",
        "        text = self.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
        "        return bool(re.search(r'\\{[^{}]*\"nodes\"\\s*:\\s*\\[.*?\\]\\s*,\\s*\"edges\"\\s*:\\s*\\[.*?\\]\\s*\\}', text, re.S))\n",
        "\n",
        "def _safe_eos_ids(tok):\n",
        "    eos = tok.eos_token_id\n",
        "    return eos if isinstance(eos, list) else ([eos] if eos is not None else None)\n",
        "\n",
        "def custom_eval_grpo(\n",
        "    trainer,\n",
        "    dataset,\n",
        "    num_samples: int = 100,\n",
        "    gen_batch_size: int = 8,\n",
        "    max_new_tokens: int = 256,\n",
        "    use_stop: bool = False,\n",
        "    prefix: str = \"gen\",\n",
        "    log_to_wandb: bool = True\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Deterministic eval for GRPO training:\n",
        "      - left padding + fixed-width slice (no per-row masks)\n",
        "      - one completion per prompt (do_sample=False)\n",
        "      - computes trainer._compute_custom_graph_metrics on decoded texts\n",
        "      - logs to W&B\n",
        "    \"\"\"\n",
        "    tok   = trainer.processing_class\n",
        "    model = trainer.model\n",
        "    device = trainer.args.device\n",
        "\n",
        "    n = len(dataset)\n",
        "    use = min(num_samples, n)\n",
        "    if use < n:\n",
        "        idxs = np.random.choice(n, use, replace=False)\n",
        "        ds = dataset.select(list(map(int, idxs)))\n",
        "    else:\n",
        "        ds = dataset\n",
        "\n",
        "    prompts  = list(ds[\"prompt\"])\n",
        "    gold_key = \"clean_completion\" if \"clean_completion\" in ds.column_names else \"completion\"\n",
        "    golds    = list(ds[gold_key])\n",
        "\n",
        "    old_pad, old_trunc = tok.padding_side, getattr(tok, \"truncation_side\", \"right\")\n",
        "    tok.padding_side = tok.truncation_side = \"left\"\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    EOS = _safe_eos_ids(tok)\n",
        "    PAD = tok.pad_token_id or tok.eos_token_id\n",
        "\n",
        "    model_was_training = model.training\n",
        "    orig_use_cache = getattr(model.config, \"use_cache\", None)\n",
        "    start = time.time()\n",
        "    outs: List[str] = []\n",
        "\n",
        "    try:\n",
        "        model.eval()\n",
        "        try: model.gradient_checkpointing_disable()\n",
        "        except Exception: pass\n",
        "        if orig_use_cache is not None:\n",
        "            model.config.use_cache = True\n",
        "\n",
        "        for i in tqdm(range(0, len(prompts), gen_batch_size), desc=\"[custom-eval] generate (SFT-style)\"):\n",
        "            batch_texts = prompts[i:i+gen_batch_size]\n",
        "            batch = tok(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            input_len = batch[\"input_ids\"].shape[1]\n",
        "            stop = StoppingCriteriaList([JsonStopper(tok, input_len)]) if use_stop else StoppingCriteriaList([])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = model.generate(\n",
        "                    **batch,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    min_new_tokens=1,\n",
        "                    do_sample=False, temperature=None, top_p=None, top_k=None,\n",
        "                    use_cache=True,\n",
        "                    eos_token_id=EOS, pad_token_id=PAD,\n",
        "                    max_time=60,\n",
        "                    stopping_criteria=stop,\n",
        "                )\n",
        "\n",
        "            gen = tok.batch_decode(out[:, input_len:], skip_special_tokens=True)\n",
        "            outs.extend(gen)\n",
        "\n",
        "            del out, batch\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    finally:\n",
        "        tok.padding_side, tok.truncation_side = old_pad, old_trunc\n",
        "        if orig_use_cache is not None:\n",
        "            model.config.use_cache = orig_use_cache\n",
        "        if model_was_training:\n",
        "            try:\n",
        "                model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
        "            except TypeError:\n",
        "                model.gradient_checkpointing_enable()\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    #graph metrics\n",
        "    custom = compute_graph_metrics_on_texts(outs, golds)\n",
        "\n",
        "\n",
        "    total_batch_size = trainer.args.eval_batch_size * trainer.args.world_size\n",
        "    num_steps = max(1, math.ceil(len(prompts) / max(1, total_batch_size)))\n",
        "    speed = speed_metrics(prefix, start, num_samples=len(prompts), num_steps=num_steps)\n",
        "\n",
        "    out = {f\"{prefix}_{k}\": v for k, v in custom.items()}\n",
        "    out.update(speed)\n",
        "\n",
        "    if log_to_wandb and wandb.run:\n",
        "        wandb.log(out, step=trainer.state.global_step)\n",
        "\n",
        "\n",
        "    if log_to_wandb and wandb.run:\n",
        "        step = getattr(trainer.state, \"global_step\", None)\n",
        "        log_payload = out.copy()\n",
        "        if extra_tags:\n",
        "            log_payload.update(extra_tags)\n",
        "        wandb.log(log_payload, step=int(step) if step is not None else None)\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0752a048-ce3f-47e8-98a0-6de23d0111eb",
      "metadata": {
        "id": "0752a048-ce3f-47e8-98a0-6de23d0111eb"
      },
      "outputs": [],
      "source": [
        "#@title Cell 8c Training Evaluation -  Custom GRPO Evaluator Using Trainer Generation\n",
        "\n",
        "def custom_eval_grpo_with_trainer_generate(\n",
        "    trainer,\n",
        "    dataset,\n",
        "    num_samples: int = 50,\n",
        "    gen_batch_size: int = 4,\n",
        "    max_new_tokens: int = 350,\n",
        "    prefix: str = \"gen\",\n",
        "    log_to_wandb: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Deterministic GRPO eval using trainer._generate.\n",
        "    Strategy:\n",
        "      1) Decode full sequences and try to cut AFTER the assistant header.\n",
        "      2) If no assistant header is found, fall back to per-row prompt-length slicing.\n",
        "    \"\"\"\n",
        "    import time, math, numpy as np, torch, gc\n",
        "    from tqdm import tqdm\n",
        "    from transformers.trainer_utils import speed_metrics\n",
        "    import wandb\n",
        "\n",
        "    def _cut_after_assistant(text: str) -> (str, bool):\n",
        "        markers = [\n",
        "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        "            \"<|assistant|>\\n\\n\",\n",
        "            \"<|assistant|>\",\n",
        "            \"\\nassistant\\n\\n\",\n",
        "            \"assistant\\n\\n\",\n",
        "            \"assistant\\n\",\n",
        "        ]\n",
        "        cut = -1\n",
        "        for m in markers:\n",
        "            j = text.rfind(m)\n",
        "            if j >= 0:\n",
        "                cut = max(cut, j + len(m))\n",
        "        if cut >= 0:\n",
        "            return text[cut:].lstrip(), True\n",
        "        return text.lstrip(), False\n",
        "\n",
        "    def _prompt_lengths(input_ids: torch.Tensor, attention_mask: torch.Tensor, tok) -> list:\n",
        "        if attention_mask is not None:\n",
        "            return attention_mask.sum(dim=1).tolist()\n",
        "        pad_id = getattr(tok, \"pad_token_id\", None)\n",
        "        if pad_id is not None:\n",
        "            lens = []\n",
        "            for row in input_ids.tolist():\n",
        "                n = 0\n",
        "                for t in row:\n",
        "                    if t != pad_id:\n",
        "                        n += 1\n",
        "                lens.append(n)\n",
        "            return lens\n",
        "        return [int(input_ids.shape[1])] * input_ids.shape[0]\n",
        "\n",
        "    tok   = trainer.processing_class\n",
        "    model = trainer.model\n",
        "    device = trainer.args.device\n",
        "\n",
        "    n = len(dataset)\n",
        "    use = min(num_samples, n)\n",
        "    if use < n:\n",
        "        idxs = np.random.choice(n, use, replace=False)\n",
        "        ds = dataset.select(list(map(int, idxs)))\n",
        "    else:\n",
        "        ds = dataset\n",
        "\n",
        "    prompts  = list(ds[\"prompt\"])\n",
        "    gold_key = \"clean_completion\" if \"clean_completion\" in ds.column_names else \"completion\"\n",
        "    golds    = list(ds[gold_key])\n",
        "\n",
        "    old_pad, old_trunc = tok.padding_side, getattr(tok, \"truncation_side\", \"right\")\n",
        "    tok.padding_side = tok.truncation_side = \"left\"\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    trainer._eval_generation_kwargs.setdefault(\"do_sample\", False)\n",
        "    trainer._eval_generation_kwargs.setdefault(\"temperature\", 0.0)\n",
        "    trainer._eval_generation_kwargs[\"max_new_tokens\"] = int(max_new_tokens)\n",
        "\n",
        "    model_was_training = model.training\n",
        "    orig_use_cache = getattr(model.config, \"use_cache\", None)\n",
        "    start = time.time()\n",
        "    outs = []\n",
        "\n",
        "    try:\n",
        "        model.eval()\n",
        "        try: model.gradient_checkpointing_disable()\n",
        "        except Exception: pass\n",
        "        if orig_use_cache is not None:\n",
        "            model.config.use_cache = True\n",
        "\n",
        "        bs = max(1, int(gen_batch_size))\n",
        "        for i in tqdm(range(0, len(prompts), bs), desc=\"[custom-eval] trainer.generate\"):\n",
        "            batch_texts = prompts[i:i+bs]\n",
        "            batch = tok(batch_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = trainer._generate(\n",
        "                    input_ids=batch[\"input_ids\"],\n",
        "                    attention_mask=batch.get(\"attention_mask\", None),\n",
        "                )\n",
        "\n",
        "            full_txts = tok.batch_decode(out, skip_special_tokens=True)\n",
        "            cut_txts, cut_flags = [], []\n",
        "            for txt in full_txts:\n",
        "                c, ok = _cut_after_assistant(txt)\n",
        "                cut_txts.append(c); cut_flags.append(ok)\n",
        "\n",
        "            if not all(cut_flags):\n",
        "                lens = _prompt_lengths(batch[\"input_ids\"], batch.get(\"attention_mask\", None), tok)\n",
        "                for row_idx, ok in enumerate(cut_flags):\n",
        "                    if ok:\n",
        "                        continue\n",
        "                    suffix = tok.decode(out[row_idx, int(lens[row_idx]):], skip_special_tokens=True)\n",
        "                    cut_txts[row_idx] = suffix.lstrip()\n",
        "\n",
        "            outs.extend(cut_txts)\n",
        "\n",
        "            del out, batch\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    finally:\n",
        "        tok.padding_side, tok.truncation_side = old_pad, old_trunc\n",
        "        if orig_use_cache is not None:\n",
        "            model.config.use_cache = orig_use_cache\n",
        "        if model_was_training:\n",
        "            try:\n",
        "                model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
        "            except TypeError:\n",
        "                model.gradient_checkpointing_enable()\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    custom = compute_graph_metrics_on_texts(outs, golds)\n",
        "\n",
        "    total_batch_size = trainer.args.eval_batch_size * trainer.args.world_size\n",
        "    num_steps = max(1, math.ceil(len(prompts) / max(1, total_batch_size)))\n",
        "    speed = speed_metrics(prefix, start, num_samples=len(prompts), num_steps=num_steps)\n",
        "\n",
        "    out = {f\"{prefix}_{k}\": float(v) for k, v in custom.items()}\n",
        "    print(f\"out logged metrics: {out}\")\n",
        "    out.update(speed)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27b7035b-9080-44eb-a5b6-9cb6fa9760ce",
      "metadata": {
        "id": "27b7035b-9080-44eb-a5b6-9cb6fa9760ce"
      },
      "outputs": [],
      "source": [
        "#@title Cell 8d Training Evaluation -  Context configs management for decoding during eval\n",
        "\n",
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def eval_decode_settings(trainer, do_sample=False, temperature=0.0, max_new_tokens=256):\n",
        "    old = dict(trainer.args.generation_kwargs or {})\n",
        "    try:\n",
        "        gk = dict(old)\n",
        "        gk[\"do_sample\"] = do_sample\n",
        "        #gk[\"use_stop\"] = True,\n",
        "        gk[\"temperature\"] = temperature\n",
        "        gk[\"max_new_tokens\"] = max_new_tokens\n",
        "        trainer.args.generation_kwargs = gk\n",
        "        yield\n",
        "    finally:\n",
        "        trainer.args.generation_kwargs = old\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46bfbaaf-b978-42cb-8269-6c46d29c0770",
      "metadata": {
        "id": "46bfbaaf-b978-42cb-8269-6c46d29c0770"
      },
      "outputs": [],
      "source": [
        "#@title Cell 8e Training Evaluation - Training Evaluation Loop\n",
        "\n",
        "def train_eval_cycles(\n",
        "    trainer,\n",
        "    cycles: int = 4,\n",
        "    steps_per_cycle: int = 4,\n",
        "    eval_ds_small=None,\n",
        "    num_samples_small: int = 10,\n",
        "):\n",
        "    assert eval_ds_small is not None and len(eval_ds_small) > 0, \"Provide a small eval dataset.\"\n",
        "\n",
        "    for c in range(cycles):\n",
        "        target = trainer.state.global_step + steps_per_cycle\n",
        "        trainer.args.max_steps = target\n",
        "        print(f\"\\n==== Cycle {c+1}/{cycles}: training to global_step {target} ====\")\n",
        "        trainer.train()\n",
        "        print(f\"---- Cycle {c+1}: custom eval (subset={num_samples_small}, cap=300) ----\")\n",
        "        with eval_decode_settings(trainer, do_sample=False, temperature=0.0, max_new_tokens=300):\n",
        "            m = custom_eval_grpo_with_trainer_generate(\n",
        "                trainer,\n",
        "                dataset=eval_ds_small,\n",
        "                num_samples=num_samples_small,\n",
        "                gen_batch_size=8,\n",
        "                max_new_tokens=300,\n",
        "                #use_stop=True,\n",
        "                prefix=\"eval\",\n",
        "                log_to_wandb=True,\n",
        "                #extra_tags={\"cycle\": c+1}   # NEW: log cycle as metadata\n",
        "            )\n",
        "        print(f\"printing metrics {type(m)}\")\n",
        "        prefixed_metrics = {f\"eval/{key}\": value for key, value in m.items()}\n",
        "        wandb.log(prefixed_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedf771b-ad55-42e3-95b4-6ffb1ac3f7d4",
      "metadata": {
        "id": "bedf771b-ad55-42e3-95b4-6ffb1ac3f7d4",
        "outputId": "15e9f257-9e94-4c3f-87e7-ef284ca61486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== Cycle 1/15: training to global_step 8 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=0 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.509327411651611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=1 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.41457986831665, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=2 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.561333656311035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=3 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.334188938140869, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=4 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1846089363098145, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=5 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3352532386779785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=6 rewards (first 8) [0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 11.164823532104492, 'learning_rate': 5e-07, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.474517345428467, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=7 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.477639675140381, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "{'train_runtime': 366.9756, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': 2.247946540023804e-08, 'epoch': 0.006097560975609756}\n",
            "---- Cycle 1: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:17<00:00, 36.78s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}], {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"value:ten (10) days\", \"type\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7947019867549668, 'eval_strict_node_recall': 0.5084745762711864, 'eval_strict_node_f1': 0.6201550387596899, 'eval_fuzzy_node_precision': 0.8079470198675497, 'eval_fuzzy_node_recall': 0.5169491525423728, 'eval_fuzzy_node_f1': 0.6304909560723514, 'eval_edge_precision': 0.6788990825688074, 'eval_edge_recall': 0.4, 'eval_edge_f1': 0.5034013605442177, 'eval_exact_graph_match_rate': 0.2, 'eval_invalid_json_rate': 0.16}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 2/15: training to global_step 16 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=8 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.385732650756836, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=9 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.143566131591797, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=10 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.716372013092041, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=11 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.114327430725098, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=12 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.625007152557373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=13 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.26143217086792, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=14 rewards (first 8) [0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 6.076781272888184, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.5254597663879395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=15 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.493497848510742, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=16 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.762012004852295, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=17 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.51259183883667, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=18 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.469635486602783, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=19 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.835277080535889, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=20 rewards (first 8) [0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 7.358145713806152, 'learning_rate': 5e-07, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.257745742797852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=21 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 10.27587604522705, 'learning_rate': 3.75e-07, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.235864639282227, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=22 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333]\n",
            "{'loss': 0.0, 'grad_norm': 6.9831109046936035, 'learning_rate': 2.5e-07, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.352219104766846, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=23 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.25e-07, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.833789825439453, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "{'train_runtime': 735.4736, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': 4.461833480462474e-08, 'epoch': 0.012195121951219513}\n",
            "---- Cycle 2: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:09<00:00, 35.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"USES\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisor\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"defined_term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"defined_term:Franchise Agreements\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchise Agreements\"}, {\"id\": \"defined_term:Parties\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Parties\"}, {\"id\": \"defined_term:Term And Condition\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term And Condition\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Franchise Agreements\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"value:ten (10) days\", \"type\":\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8208955223880597, 'eval_strict_node_recall': 0.4602510460251046, 'eval_strict_node_f1': 0.5898123324396782, 'eval_fuzzy_node_precision': 0.8283582089552238, 'eval_fuzzy_node_recall': 0.46443514644351463, 'eval_fuzzy_node_f1': 0.5951742627345844, 'eval_edge_precision': 0.6947368421052632, 'eval_edge_recall': 0.3548387096774194, 'eval_edge_f1': 0.46975088967971534, 'eval_exact_graph_match_rate': 0.22, 'eval_invalid_json_rate': 0.22}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 3/15: training to global_step 24 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=24 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 11.510505676269531, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.063674449920654, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=25 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.916666666666667e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2751030921936035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=26 rewards (first 8) [0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 10.732169151306152, 'learning_rate': 1.833333333333333e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.0833333432674408, 'rewards/reward_group_adapter/std': 0.03333333507180214, 'reward': 0.0833333432674408, 'reward_std': 0.03333333507180214, 'frac_reward_zero_std': 0.0, 'entropy': 5.372197151184082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=27 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.524985313415527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=28 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.53939151763916, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=29 rewards (first 8) [0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5833333333333331e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.06666667014360428, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.06666667014360428, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4883012771606445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=30 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.09333333333333332]\n",
            "{'loss': 0.0, 'grad_norm': 7.4210734367370605, 'learning_rate': 1.5e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.05833333358168602, 'rewards/reward_group_adapter/std': 0.023333333432674408, 'reward': 0.05833333358168602, 'reward_std': 0.023333333432674408, 'frac_reward_zero_std': 0.0, 'entropy': 5.590939521789551, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=31 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4166666666666667e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.339782238006592, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=32 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333332e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.635868549346924, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=33 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.286185264587402, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=34 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.047449588775635, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=35 rewards (first 8) [0.04666666666666666, 0.09333333333333332, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 5.896581172943115, 'learning_rate': 1.0833333333333333e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.05833333358168602, 'rewards/reward_group_adapter/std': 0.023333333432674408, 'reward': 0.05833333358168602, 'reward_std': 0.023333333432674408, 'frac_reward_zero_std': 0.0, 'entropy': 5.652876853942871, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=36 rewards (first 8) [0.09333333333333332, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 5.693622589111328, 'learning_rate': 1e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.05833333358168602, 'rewards/reward_group_adapter/std': 0.023333333432674408, 'reward': 0.05833333358168602, 'reward_std': 0.023333333432674408, 'frac_reward_zero_std': 0.0, 'entropy': 5.010901927947998, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=37 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.166666666666665e-07, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.722557067871094, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=38 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-07, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2443060874938965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=39 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.351461887359619, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=40 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.666666666666666e-07, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.280056476593018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=41 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.833333333333334e-07, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.064462661743164, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=42 rewards (first 8) [0.04666666666666666, 0.09333333333333332, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 7.749790668487549, 'learning_rate': 5e-07, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.05833333358168602, 'rewards/reward_group_adapter/std': 0.023333333432674408, 'reward': 0.05833333358168602, 'reward_std': 0.023333333432674408, 'frac_reward_zero_std': 0.0, 'entropy': 5.251425743103027, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=43 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3251471519470215, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=44 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.333333333333333e-07, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.583047389984131, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=45 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.773765563964844, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=46 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666665e-07, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.568730354309082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=47 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.515309810638428, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "{'train_runtime': 1109.698, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': 1.9697916483115325e-08, 'epoch': 0.018292682926829267}\n",
            "---- Cycle 3: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:34<00:00, 39.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"value:ten (10) days\", \"type\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"defined_term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"defined_term:Franchise Agreements\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchise Agreements\"}, {\"id\": \"defined_term:Parties\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Parties\"}, {\"id\": \"defined_term:Term And Condition\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term And Condition\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Franchise Agreements\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\n",
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}], {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7923076923076923, 'eval_strict_node_recall': 0.44206008583690987, 'eval_strict_node_f1': 0.5674931129476584, 'eval_fuzzy_node_precision': 0.8, 'eval_fuzzy_node_recall': 0.44635193133047213, 'eval_fuzzy_node_f1': 0.5730027548209368, 'eval_edge_precision': 0.6739130434782609, 'eval_edge_recall': 0.3425414364640884, 'eval_edge_f1': 0.45421245421245415, 'eval_exact_graph_match_rate': 0.16, 'eval_invalid_json_rate': 0.24}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 4/15: training to global_step 32 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=48 rewards (first 8) [0.09333333333333332, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 6.903642177581787, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.05833333358168602, 'rewards/reward_group_adapter/std': 0.023333333432674408, 'reward': 0.05833333358168602, 'reward_std': 0.023333333432674408, 'frac_reward_zero_std': 0.0, 'entropy': 5.688028812408447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=49 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9375e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.696741104125977, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=50 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.686928749084473, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=51 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8125e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.242928504943848, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=52 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.335037708282471, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=53 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6875e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.336119651794434, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=54 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.949944972991943, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=55 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5624999999999999e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.646716594696045, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=56 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.362621307373047, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=57 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4375e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.519939422607422, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=58 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2685933113098145, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=59 rewards (first 8) [0.04666666666666666, 0.04666666666666666, 0.04666666666666666, 0.04666666666666666]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3125e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.046666666865348816, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.046666666865348816, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.543124675750732, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=60 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.41313362121582, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=61 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1874999999999999e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.701590538024902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=62 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.501200199127197, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=63 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0625e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.47109317779541, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=64 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.05333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 9.647754669189453, 'learning_rate': 1e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.168344497680664, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=65 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.374999999999999e-07, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.378704071044922, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=66 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.05333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.7682390213012695, 'learning_rate': 8.75e-07, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.142092704772949, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=67 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.125e-07, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.944135665893555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=68 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.05333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 8.52377986907959, 'learning_rate': 7.5e-07, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.6998395919799805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=69 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.875e-07, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.698728561401367, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=70 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5724687576293945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=71 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.625e-07, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.511773109436035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=72 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.128889083862305, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=73 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.375e-07, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.20733118057251, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=74 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.75e-07, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.226691722869873, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=75 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.1249999999999997e-07, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.607792377471924, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=76 rewards (first 8) [0.05333333333333334, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.819850921630859, 'learning_rate': 2.5e-07, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.355892658233643, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=77 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.875e-07, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.251470565795898, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=78 rewards (first 8) [0.05333333333333334, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.501968860626221, 'learning_rate': 1.25e-07, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.404356956481934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=79 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.25e-08, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.762140274047852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "{'train_runtime': 1472.6926, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': -3.073896664984588e-08, 'epoch': 0.024390243902439025}\n",
            "---- Cycle 4: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:27<00:00, 38.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}], {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"value:ten (10) days\", \"type\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"defined_term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"defined_term:Franchise Agreements\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchise Agreements\"}, {\"id\": \"defined_term:Parties\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Parties\"}, {\"id\": \"defined_term:Term And Condition\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term And Condition\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Franchise Agreements\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\", \"tgt\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8129496402877698, 'eval_strict_node_recall': 0.4574898785425101, 'eval_strict_node_f1': 0.5854922279792746, 'eval_fuzzy_node_precision': 0.8273381294964028, 'eval_fuzzy_node_recall': 0.46558704453441296, 'eval_fuzzy_node_f1': 0.5958549222797928, 'eval_edge_precision': 0.7227722772277227, 'eval_edge_recall': 0.37628865979381443, 'eval_edge_f1': 0.49491525423728816, 'eval_exact_graph_match_rate': 0.16, 'eval_invalid_json_rate': 0.24}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 5/15: training to global_step 40 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=80 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6024169921875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=81 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.95e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.392590045928955, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=82 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8999999999999998e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.305876731872559, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=83 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.85e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.349498271942139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=84 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.545233726501465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=85 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5089216232299805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=86 rewards (first 8) [0.05333333333333334, 0.02666666666666667, 0.05333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 13.887494087219238, 'learning_rate': 1.6999999999999998e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03999999910593033, 'rewards/reward_group_adapter/std': 0.01539600733667612, 'reward': 0.03999999910593033, 'reward_std': 0.01539600733667612, 'frac_reward_zero_std': 0.0, 'entropy': 4.901423454284668, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=87 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6499999999999999e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.229109287261963, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=88 rewards (first 8) [0.05333333333333334, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.145999431610107, 'learning_rate': 1.6e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.03333333134651184, 'rewards/reward_group_adapter/std': 0.013333333656191826, 'reward': 0.03333333134651184, 'reward_std': 0.013333332724869251, 'frac_reward_zero_std': 0.0, 'entropy': 5.221637725830078, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=89 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.55e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02666666731238365, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.02666666731238365, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.164943695068359, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=90 rewards (first 8) [0.02, 0.04, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 8.758002281188965, 'learning_rate': 1.5e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.587103843688965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=91 rewards (first 8) [0.04, 0.02, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 7.229787826538086, 'learning_rate': 1.4499999999999999e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.65587043762207, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=92 rewards (first 8) [0.04, 0.02, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 12.450563430786133, 'learning_rate': 1.4e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.007794380187988, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=93 rewards (first 8) [0.02, 0.02, 0.04, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 12.572948455810547, 'learning_rate': 1.35e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.470728397369385, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=94 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2238969802856445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=95 rewards (first 8) [0.04, 0.02, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 6.565490245819092, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.308722019195557, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=96 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.472990989685059, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=97 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1499999999999998e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.368156909942627, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=98 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.994912147521973, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=99 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.05e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.669351100921631, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=100 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.176031589508057, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=101 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.499999999999999e-07, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.251752853393555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=102 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9e-07, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.135124206542969, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=103 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.499999999999999e-07, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7758355140686035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=104 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8e-07, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4948625564575195, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=105 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.181624412536621, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=106 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7e-07, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.951444149017334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=107 rewards (first 8) [0.04, 0.02, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 7.982929229736328, 'learning_rate': 6.5e-07, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.515488147735596, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=108 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6e-07, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.402652740478516, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=109 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.5e-07, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.357924938201904, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=110 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.393268585205078, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=111 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.5e-07, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.649033546447754, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=112 rewards (first 8) [0.02, 0.02, 0.04, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 5.585333824157715, 'learning_rate': 4e-07, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.0245561599731445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=113 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5e-07, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.253459453582764, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=114 rewards (first 8) [0.02, 0.04, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 10.867594718933105, 'learning_rate': 3e-07, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.145682334899902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=115 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.841984748840332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=116 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-07, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.443614959716797, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=117 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-07, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.407039642333984, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=118 rewards (first 8) [0.04, 0.02, 0.02, 0.02]\n",
            "{'loss': -0.0, 'grad_norm': 4.20694637298584, 'learning_rate': 1e-07, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.02499999850988388, 'rewards/reward_group_adapter/std': 0.009999999776482582, 'reward': 0.02499999850988388, 'reward_std': 0.009999999776482582, 'frac_reward_zero_std': 0.0, 'entropy': 5.288978576660156, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=119 rewards (first 8) [0.02, 0.02, 0.02, 0.02]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-08, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.019999999552965164, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.747228145599365, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "{'train_runtime': 1865.3899, 'train_samples_per_second': 0.086, 'train_steps_per_second': 0.021, 'train_loss': -3.235680665625296e-08, 'epoch': 0.03048780487804878}\n",
            "---- Cycle 5: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:29<00:00, 38.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8226950354609929, 'eval_strict_node_recall': 0.4773662551440329, 'eval_strict_node_f1': 0.6041666666666667, 'eval_fuzzy_node_precision': 0.8297872340425532, 'eval_fuzzy_node_recall': 0.48148148148148145, 'eval_fuzzy_node_f1': 0.609375, 'eval_edge_precision': 0.7156862745098039, 'eval_edge_recall': 0.3802083333333333, 'eval_edge_f1': 0.4965986394557823, 'eval_exact_graph_match_rate': 0.14, 'eval_invalid_json_rate': 0.22}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 6/15: training to global_step 48 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=120 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.249459266662598, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.9155473709106445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=121 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9583333333333334e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.450001239776611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=122 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.916666666666667e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.607477188110352, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=123 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.001754283905029, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.30594539642334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=124 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.833333333333333e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3315911293029785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=125 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.638267517089844, 'learning_rate': 1.7916666666666667e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.585944652557373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=126 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6351728439331055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=127 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7083333333333332e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.623234748840332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=128 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.404183864593506, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=129 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1194939613342285, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=130 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5833333333333331e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.996943473815918, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=131 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5416666666666666e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.127651691436768, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=132 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.01184368133545, 'learning_rate': 1.5e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.111891746520996, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=133 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4583333333333333e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.453038215637207, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=134 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 5.915679454803467, 'learning_rate': 1.4166666666666667e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.483793258666992, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=135 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.412947654724121, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=136 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333332e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.322146415710449, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=137 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2916666666666667e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.306251525878906, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=138 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.575412273406982, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=139 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2083333333333331e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.988333702087402, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=140 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.333523273468018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=141 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.569001197814941, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=142 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0833333333333333e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.162332534790039, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=143 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0416666666666667e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.577719211578369, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=144 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.169363021850586, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=145 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.583333333333334e-07, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.599405288696289, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=146 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 12.575308799743652, 'learning_rate': 9.166666666666665e-07, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.399078369140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=147 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.421353816986084, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=148 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-07, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.852347373962402, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=149 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.916666666666666e-07, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.313486099243164, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=150 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.450057506561279, 'learning_rate': 7.5e-07, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.334863185882568, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=151 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.083333333333334e-07, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.018121719360352, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=152 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.666666666666666e-07, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2514967918396, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=153 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.350868225097656, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=154 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.416118621826172, 'learning_rate': 5.833333333333334e-07, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.313671588897705, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=155 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.7790937423706055, 'learning_rate': 5.416666666666666e-07, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.3816819190979, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=156 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.383888244628906, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=157 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.5833333333333327e-07, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.575172424316406, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=158 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.236722946166992, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=159 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.75e-07, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.507537841796875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=160 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.333333333333333e-07, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.579146385192871, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=161 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.916666666666667e-07, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.299586296081543, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=162 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.344277858734131, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=163 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.0833333333333333e-07, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.357848167419434, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=164 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666665e-07, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.048655033111572, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=165 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.25e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.096946716308594, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=166 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.489001274108887, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=167 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.126418590545654, 'learning_rate': 4.166666666666666e-08, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.314264297485352, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "{'train_runtime': 2243.604, 'train_samples_per_second': 0.086, 'train_steps_per_second': 0.021, 'train_loss': -4.7087670059416574e-08, 'epoch': 0.036585365853658534}\n",
            "---- Cycle 6: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:22<00:00, 37.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}, {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8, 'eval_strict_node_recall': 0.4897959183673469, 'eval_strict_node_f1': 0.6075949367088609, 'eval_fuzzy_node_precision': 0.8133333333333334, 'eval_fuzzy_node_recall': 0.49795918367346936, 'eval_fuzzy_node_f1': 0.6177215189873417, 'eval_edge_precision': 0.6880733944954128, 'eval_edge_recall': 0.390625, 'eval_edge_f1': 0.4983388704318937, 'eval_exact_graph_match_rate': 0.12, 'eval_invalid_json_rate': 0.18}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 7/15: training to global_step 56 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=168 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.392840385437012, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.403186321258545, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=169 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.964285714285714e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.682803630828857, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=170 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9285714285714285e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.339180946350098, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=171 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.295806407928467, 'learning_rate': 1.8928571428571428e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.299729824066162, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=172 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.857142857142857e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.328454971313477, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=173 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8214285714285714e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.126707553863525, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=174 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.61964225769043, 'learning_rate': 1.7857142857142857e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.066105842590332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=175 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 9.670402526855469, 'learning_rate': 1.75e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.443579196929932, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=176 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.714285714285714e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3624043464660645, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=177 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6785714285714286e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.099514007568359, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=178 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6428571428571426e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.98872709274292, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=179 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6071428571428572e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.616044044494629, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=180 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5714285714285712e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.363067150115967, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=181 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5357142857142857e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.944330215454102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=182 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.421761512756348, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=183 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4642857142857141e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.31605863571167, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=184 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4285714285714286e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.505865097045898, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=185 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 7.519530296325684, 'learning_rate': 1.3928571428571427e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.073939323425293, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=186 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3571428571428572e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0448994636535645, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=187 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3214285714285713e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5008697509765625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=188 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2857142857142858e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.57627534866333, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=189 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.315972805023193, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=190 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2142857142857142e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.390356540679932, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=191 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1785714285714285e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.076443195343018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=192 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1428571428571428e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.365267753601074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=193 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.107142857142857e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.9424729347229, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=194 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0714285714285714e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.005884647369385, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=195 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0357142857142857e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.518348693847656, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=196 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.990274906158447, 'learning_rate': 1e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.603087425231934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=197 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.642857142857142e-07, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.469583034515381, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=198 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.285714285714285e-07, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.64510440826416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=199 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.304041862487793, 'learning_rate': 8.928571428571428e-07, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.309967041015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=200 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.57142857142857e-07, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.548640251159668, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=201 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.214285714285713e-07, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.806817531585693, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=202 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.193537712097168, 'learning_rate': 7.857142857142856e-07, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.945486068725586, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=203 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.439812183380127, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=204 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.142857142857143e-07, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.249258041381836, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=205 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.785714285714286e-07, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.430726051330566, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=206 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.428571428571429e-07, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.35215950012207, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=207 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.071428571428571e-07, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.21226167678833, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=208 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.714285714285714e-07, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.313950061798096, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=209 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.357142857142857e-07, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.389465808868408, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=210 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.639151573181152, 'learning_rate': 5e-07, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.585242748260498, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=211 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.6428571428571427e-07, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.972903728485107, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=212 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.285714285714285e-07, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.425221920013428, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=213 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.928571428571428e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.446950912475586, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=214 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5714285714285716e-07, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.680245399475098, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=215 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.2142857142857145e-07, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.111590385437012, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=216 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 4.069068431854248, 'learning_rate': 2.857142857142857e-07, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.499199867248535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=217 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.265280723571777, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=218 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.1428571428571426e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.507654190063477, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=219 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7857142857142858e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.367949962615967, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=220 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4285714285714285e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.240272045135498, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=221 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0714285714285713e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.281605243682861, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=222 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.142857142857142e-08, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2509565353393555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=223 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.571428571428571e-08, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.59017276763916, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "{'train_runtime': 2611.9425, 'train_samples_per_second': 0.086, 'train_steps_per_second': 0.021, 'train_loss': -3.839025732231351e-08, 'epoch': 0.042682926829268296}\n",
            "---- Cycle 7: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:26<00:00, 38.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"defined_term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"defined_term:Franchise Agreements\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchise Agreements\"}, {\"id\": \"defined_term:Parties\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Parties\"}, {\"id\": \"defined_term:Term And Condition\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term And Condition\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Franchise Agreements\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"value:ten (10) days\", \"type\":\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7786259541984732, 'eval_strict_node_recall': 0.4214876033057851, 'eval_strict_node_f1': 0.546916890080429, 'eval_fuzzy_node_precision': 0.7938931297709924, 'eval_fuzzy_node_recall': 0.4297520661157025, 'eval_fuzzy_node_f1': 0.5576407506702413, 'eval_edge_precision': 0.6702127659574468, 'eval_edge_recall': 0.3333333333333333, 'eval_edge_f1': 0.4452296819787986, 'eval_exact_graph_match_rate': 0.2, 'eval_invalid_json_rate': 0.26}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 8/15: training to global_step 64 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=224 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.193343162536621, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.374517917633057, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=225 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.96875e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.627962589263916, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=226 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9375e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.853531837463379, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=227 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.90625e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5409321784973145, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=228 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.8866963386535645, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=229 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.84375e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.501245498657227, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=230 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8125e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.487561225891113, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=231 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7812499999999999e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.226243019104004, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=232 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.291738986968994, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=233 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7187499999999998e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1171698570251465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=234 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.48609447479248, 'learning_rate': 1.6875e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.878568172454834, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=235 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.65625e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.614007949829102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=236 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4370551109313965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=237 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.619029521942139, 'learning_rate': 1.59375e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.1846184730529785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=238 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5624999999999999e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.718801021575928, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=239 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.738984107971191, 'learning_rate': 1.53125e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.448392391204834, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=240 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.506376266479492, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=241 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.46875e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.495284080505371, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=242 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4375e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.606706142425537, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=243 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4062499999999999e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.131420135498047, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=244 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.511724472045898, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=245 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.985018253326416, 'learning_rate': 1.3437499999999998e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.479912757873535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=246 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3125e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0746378898620605, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=247 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.28125e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.355545997619629, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=248 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.189664363861084, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=249 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.21875e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.466221332550049, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=250 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1874999999999999e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.30751895904541, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=251 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.15625e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.921689987182617, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=252 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.12673807144165, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=253 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.09375e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.343331336975098, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=254 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0625e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.56918478012085, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=255 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.576716899871826, 'learning_rate': 1.0312499999999999e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.454174041748047, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=256 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.309499740600586, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=257 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.6875e-07, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.515250205993652, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=258 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.002711296081543, 'learning_rate': 9.374999999999999e-07, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.242574691772461, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=259 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.0625e-07, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.177016735076904, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=260 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.140319347381592, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=261 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.4375e-07, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.568787097930908, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=262 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.125e-07, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.189064025878906, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=263 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.812499999999999e-07, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.149901866912842, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=264 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.251319885253906, 'learning_rate': 7.5e-07, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.27227783203125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=265 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.1875e-07, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.283075332641602, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=266 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.053559303283691, 'learning_rate': 6.875e-07, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.1545844078063965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=267 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.5625e-07, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.417933940887451, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=268 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.932229518890381, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.40334939956665, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=269 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.937499999999999e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.467768669128418, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=270 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.625e-07, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.349961280822754, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=271 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.3125e-07, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.105836868286133, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=272 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.416603088378906, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=273 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.356149673461914, 'learning_rate': 4.6874999999999996e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.2536187171936035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=274 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.375e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.325950622558594, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=275 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.0625e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6557440757751465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=276 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.40893840789795, 'learning_rate': 3.75e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.383877754211426, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=277 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.4375e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.407458305358887, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=278 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.4220685958862305, 'learning_rate': 3.1249999999999997e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.5244340896606445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=279 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.8125e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.530545711517334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=280 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.038753509521484, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=281 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.953559875488281, 'learning_rate': 2.1875e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.298954963684082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=282 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.875e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.898390293121338, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=283 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5624999999999999e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.155527114868164, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=284 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.25e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.868979454040527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=285 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.375e-08, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6265549659729, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=286 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.25e-08, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7218523025512695, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=287 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.125e-08, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.204742431640625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "{'train_runtime': 2999.2427, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.021, 'train_loss': -4.604458858636917e-08, 'epoch': 0.04878048780487805}\n",
            "---- Cycle 8: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:20<00:00, 37.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"defined_term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"defined_term:Franchise Agreements\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchise Agreements\"}, {\"id\": \"defined_term:Parties\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Parties\"}, {\"id\": \"defined_term:Term And Condition\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term And Condition\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Franchise Agreements\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"defined_term:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7923076923076923, 'eval_strict_node_recall': 0.42738589211618255, 'eval_strict_node_f1': 0.555256064690027, 'eval_fuzzy_node_precision': 0.8076923076923077, 'eval_fuzzy_node_recall': 0.43568464730290457, 'eval_fuzzy_node_f1': 0.5660377358490566, 'eval_edge_precision': 0.6595744680851063, 'eval_edge_recall': 0.3263157894736842, 'eval_edge_f1': 0.4366197183098592, 'eval_exact_graph_match_rate': 0.16, 'eval_invalid_json_rate': 0.26}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 9/15: training to global_step 72 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=288 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.367894649505615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=289 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9722222222222224e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.342244625091553, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=290 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.5573225021362305, 'learning_rate': 1.9444444444444444e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.249943733215332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=291 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.916666666666667e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.536741256713867, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=292 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8888888888888888e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.535227298736572, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=293 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.861111111111111e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.948901176452637, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=294 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.204888343811035, 'learning_rate': 1.833333333333333e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.306519985198975, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=295 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8055555555555555e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.444652080535889, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=296 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7777777777777775e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.052395343780518, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=297 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.743616580963135, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=298 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7222222222222222e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.614959239959717, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=299 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 17.717103958129883, 'learning_rate': 1.6944444444444444e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.299160003662109, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=300 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.987919807434082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=301 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6388888888888887e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.852546215057373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=302 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.421515464782715, 'learning_rate': 1.6111111111111111e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.327677249908447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=303 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5833333333333331e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.018889427185059, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=304 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5555555555555556e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.517572402954102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=305 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5277777777777776e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.279462814331055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=306 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.336133003234863, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=307 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4722222222222223e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.247547626495361, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=308 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4444444444444443e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.812411308288574, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=309 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4166666666666667e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.131278038024902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=310 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.193874359130859, 'learning_rate': 1.3888888888888887e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.103957176208496, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=311 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3611111111111112e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0228495597839355, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=312 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333332e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.745910167694092, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=313 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.682084083557129, 'learning_rate': 1.3055555555555554e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.971190929412842, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=314 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 3.9297375679016113, 'learning_rate': 1.2777777777777777e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.693800926208496, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=315 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.439762115478516, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=316 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2222222222222223e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.987784385681152, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=317 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1944444444444443e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.345304012298584, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=318 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.3422322273254395, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.729444980621338, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=319 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1388888888888888e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.084619998931885, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=320 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.111111111111111e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.01615047454834, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=321 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0833333333333333e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.479856967926025, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=322 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0555555555555555e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.755913734436035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=323 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0277777777777777e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.717845916748047, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=324 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.493807792663574, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=325 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.722222222222222e-07, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.313807964324951, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=326 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.444444444444444e-07, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.212212085723877, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=327 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.166666666666665e-07, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.031205177307129, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=328 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 14.472140312194824, 'learning_rate': 8.888888888888888e-07, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.882433891296387, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=329 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.611111111111111e-07, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.372048854827881, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=330 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-07, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.593471527099609, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=331 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.055555555555556e-07, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.516081809997559, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=332 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.764984607696533, 'learning_rate': 7.777777777777778e-07, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.549459934234619, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=333 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.53732967376709, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=334 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.222222222222221e-07, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.542679786682129, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=335 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.944444444444444e-07, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.829225540161133, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=336 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.666666666666666e-07, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.271615505218506, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=337 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.388888888888888e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.311685085296631, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=338 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.111111111111112e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.187666893005371, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=339 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.833333333333334e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.702638626098633, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=340 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.614654064178467, 'learning_rate': 5.555555555555555e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.470515251159668, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=341 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.277777777777777e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.695415019989014, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=342 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.1276469230651855, 'learning_rate': 5e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.412175178527832, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=343 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.722222222222222e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.730897903442383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=344 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.845798492431641, 'learning_rate': 4.444444444444444e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.208433151245117, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=345 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.529128074645996, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=346 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.888888888888889e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.417857646942139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=347 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 17.0643310546875, 'learning_rate': 3.6111111111111107e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.404123783111572, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=348 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.333333333333333e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.511456489562988, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=349 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.055555555555556e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.40323543548584, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=350 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.7777777777777776e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.561319828033447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=351 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.531148433685303, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=352 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.222222222222222e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.631636619567871, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=353 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9444444444444445e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.446476936340332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=354 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666665e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.832505226135254, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=355 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3888888888888888e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.571930408477783, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=356 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.111111111111111e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.185636043548584, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=357 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.690026760101318, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=358 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.555555555555555e-08, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.033785820007324, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=359 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.7777777777777774e-08, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.675807952880859, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "{'train_runtime': 3395.4722, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.021, 'train_loss': -4.2404447755630926e-08, 'epoch': 0.054878048780487805}\n",
            "---- Cycle 9: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:34<00:00, 39.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7862595419847328, 'eval_strict_node_recall': 0.42213114754098363, 'eval_strict_node_f1': 0.5493333333333335, 'eval_fuzzy_node_precision': 0.8015267175572519, 'eval_fuzzy_node_recall': 0.430327868852459, 'eval_fuzzy_node_f1': 0.56, 'eval_edge_precision': 0.6702127659574468, 'eval_edge_recall': 0.32642487046632124, 'eval_edge_f1': 0.43902439024390244, 'eval_exact_graph_match_rate': 0.2, 'eval_invalid_json_rate': 0.26}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 10/15: training to global_step 80 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=360 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6517333984375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=361 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.975e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.508314609527588, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=362 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.20323371887207, 'learning_rate': 1.95e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.151251316070557, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=363 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.503853797912598, 'learning_rate': 1.9249999999999998e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.953358173370361, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=364 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8999999999999998e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.172726154327393, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=365 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.395655155181885, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=366 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.85e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.834599494934082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=367 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8249999999999999e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.856325149536133, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=368 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.419618606567383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=369 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.19984245300293, 'learning_rate': 1.7749999999999997e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.820794582366943, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=370 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.18577766418457, 'learning_rate': 1.75e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.666125297546387, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=371 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.725e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.148692607879639, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=372 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 5.950798988342285, 'learning_rate': 1.6999999999999998e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.120673179626465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=373 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.675e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.066671848297119, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=374 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6499999999999999e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.405289649963379, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=375 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.710062026977539, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=376 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3447675704956055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=377 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.575e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.71791934967041, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=378 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.073085308074951, 'learning_rate': 1.55e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.460293769836426, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=379 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5249999999999998e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2502121925354, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=380 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.6379241943359375, 'learning_rate': 1.5e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.746583938598633, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=381 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.475e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.125660419464111, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=382 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4499999999999999e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5923590660095215, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=383 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.425e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.375887393951416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=384 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.206926345825195, 'learning_rate': 1.4e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.515764236450195, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=385 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.067686080932617, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=386 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.664498329162598, 'learning_rate': 1.35e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.152379512786865, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=387 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3249999999999998e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.749702453613281, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=388 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.148223876953125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=389 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2749999999999999e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.332514762878418, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=390 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.420750141143799, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.32432746887207, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=391 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2250000000000001e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.938168048858643, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=392 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.540194034576416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=393 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.175e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2928948402404785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=394 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1499999999999998e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.453042030334473, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=395 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2267022132873535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=396 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.483339309692383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=397 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0749999999999999e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.178160190582275, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=398 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.05e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.441025733947754, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=399 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.025e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.962112903594971, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=400 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.37238073348999, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=401 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.75e-07, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.790213584899902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=402 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.499999999999999e-07, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4742631912231445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=403 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.25e-07, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.8080153465271, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=404 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9e-07, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.717146396636963, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=405 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.626214981079102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=406 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.499999999999999e-07, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.296347618103027, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=407 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.249999999999999e-07, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.103913307189941, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=408 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8e-07, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.259133815765381, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=409 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.75e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.292911052703857, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=410 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.604086875915527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=411 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.249999999999999e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.237736225128174, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=412 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.536159038543701, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=413 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.76914644241333, 'learning_rate': 6.75e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.633557319641113, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=414 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.5e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.801514148712158, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=415 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.768729209899902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=416 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.146280765533447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=417 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.749999999999999e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.533912658691406, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=418 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.579747676849365, 'learning_rate': 5.5e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.293839454650879, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=419 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.25e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.668332576751709, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=420 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.4515380859375, 'learning_rate': 5e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.542590618133545, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=421 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.7499999999999995e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4273223876953125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=422 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.5e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.665813446044922, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=423 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.2499999999999995e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.09922456741333, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=424 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2638397216796875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=425 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.75e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.428654193878174, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=426 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.434149742126465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=427 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.25e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.827348232269287, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=428 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.375907897949219, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=429 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.431554317474365, 'learning_rate': 2.75e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.773927688598633, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=430 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.433237075805664, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=431 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.6707444190979, 'learning_rate': 2.25e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.519302845001221, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=432 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.544253826141357, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=433 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.585912227630615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=434 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.756015777587891, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=435 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.25e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.644459247589111, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=436 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.155472755432129, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=437 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-08, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.484669208526611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=438 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-08, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.419806480407715, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=439 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.356367588043213, 'learning_rate': 2.5e-08, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.212399005889893, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "{'train_runtime': 3749.7441, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.021, 'train_loss': -4.388604910587901e-08, 'epoch': 0.06097560975609756}\n",
            "---- Cycle 10: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:28<00:00, 38.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"10.2\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"10\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"14\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Annual Financial Statement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Annual Financial Statement\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}], {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8062015503875969, 'eval_strict_node_recall': 0.42105263157894735, 'eval_strict_node_f1': 0.553191489361702, 'eval_fuzzy_node_precision': 0.8217054263565892, 'eval_fuzzy_node_recall': 0.4291497975708502, 'eval_fuzzy_node_f1': 0.5638297872340426, 'eval_edge_precision': 0.7282608695652174, 'eval_edge_recall': 0.3435897435897436, 'eval_edge_f1': 0.4668989547038328, 'eval_exact_graph_match_rate': 0.2, 'eval_invalid_json_rate': 0.28}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 11/15: training to global_step 88 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=440 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.997908592224121, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=441 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 5.297087669372559, 'learning_rate': 1.977272727272727e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.479516506195068, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=442 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9545454545454545e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.312383651733398, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=443 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.931818181818182e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.153295040130615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=444 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.909090909090909e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.914430141448975, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=445 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8863636363636364e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5416975021362305, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=446 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 5.7598443031311035, 'learning_rate': 1.8636363636363635e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.319943428039551, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=447 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8409090909090908e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.546701431274414, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=448 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.818181818181818e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.580930709838867, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=449 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7954545454545454e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.270913600921631, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=450 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7727272727272727e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.247681617736816, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=451 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.956243515014648, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=452 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7272727272727273e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.251445770263672, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=453 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.229389190673828, 'learning_rate': 1.7045454545454546e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.2658162117004395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=454 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.746111869812012, 'learning_rate': 1.6818181818181819e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.35050106048584, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=455 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6590909090909092e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.10696268081665, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=456 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6363636363636365e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.539102077484131, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=457 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6136363636363635e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.099782943725586, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=458 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.6398491859436035, 'learning_rate': 1.5909090909090908e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.589627742767334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=459 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.755828380584717, 'learning_rate': 1.5681818181818181e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.200035572052002, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=460 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5454545454545454e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.456961631774902, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=461 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5227272727272727e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.117245197296143, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=462 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.203677177429199, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=463 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4772727272727271e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2995805740356445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=464 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4545454545454544e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.399716377258301, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=465 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.516240119934082, 'learning_rate': 1.4318181818181817e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.276859760284424, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=466 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.409090909090909e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.727696895599365, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=467 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3863636363636363e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.127701282501221, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=468 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3636363636363634e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.240829944610596, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=469 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.337793350219727, 'learning_rate': 1.3409090909090907e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.279037952423096, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=470 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.835651874542236, 'learning_rate': 1.318181818181818e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.384090900421143, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=471 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2954545454545453e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.315113067626953, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=472 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2727272727272726e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.121381759643555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=473 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.062994956970215, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.209099769592285, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=474 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2272727272727272e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.362006664276123, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=475 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2045454545454545e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.456539630889893, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=476 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.4954705238342285, 'learning_rate': 1.1818181818181818e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.079720497131348, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=477 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.159090909090909e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.643703460693359, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=478 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1363636363636364e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.930384159088135, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=479 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1136363636363635e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.580699920654297, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=480 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 5.8584065437316895, 'learning_rate': 1.0909090909090908e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.62056827545166, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=481 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.068181818181818e-06, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1876044273376465, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=482 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0454545454545454e-06, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6281938552856445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=483 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0227272727272727e-06, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.266735553741455, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=484 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4657087326049805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=485 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.772727272727273e-07, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6539225578308105, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=486 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.545454545454546e-07, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.341729164123535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=487 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.318181818181817e-07, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.709023475646973, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=488 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.09090909090909e-07, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.270074844360352, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=489 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.863636363636363e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.376562595367432, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=490 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.636363636363636e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.660012245178223, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=491 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.409090909090909e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1077728271484375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=492 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.181818181818182e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.835403919219971, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=493 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.954545454545454e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.386779308319092, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=494 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.727272727272727e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.09330415725708, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=495 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.528784275054932, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=496 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.272727272727272e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.508111953735352, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=497 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.045454545454545e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.11151123046875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=498 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.5345659255981445, 'learning_rate': 6.818181818181817e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.3818440437316895, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=499 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.59090909090909e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.44217586517334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=500 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 3.724824905395508, 'learning_rate': 6.363636363636363e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.947803974151611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=501 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.203254699707031, 'learning_rate': 6.136363636363636e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.097195148468018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=502 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.6211256980896, 'learning_rate': 5.909090909090909e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.373231887817383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=503 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.514383792877197, 'learning_rate': 5.681818181818182e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.267386436462402, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=504 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.454545454545454e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.134089946746826, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=505 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.227272727272727e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.492661952972412, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=506 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.445001602172852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=507 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.051671981811523, 'learning_rate': 4.772727272727273e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.46811580657959, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=508 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.545454545454545e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.280776500701904, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=509 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.318181818181818e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.160030364990234, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=510 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.090909090909091e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2945122718811035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=511 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.8636363636363636e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.262235164642334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=512 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.636363636363636e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.444348335266113, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=513 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.4090909090909085e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.532622814178467, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=514 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.177304744720459, 'learning_rate': 3.1818181818181815e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.5257182121276855, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=515 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.9545454545454545e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.221839427947998, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=516 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.301956176757812, 'learning_rate': 2.727272727272727e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.026399612426758, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=517 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.5e-07, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.527984142303467, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=518 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.2727272727272726e-07, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1193742752075195, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=519 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.0454545454545456e-07, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2838134765625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "prompts=4, completions=4, step=520 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.818181818181818e-07, 'num_tokens': 453600.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.742409706115723, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06173780487804878}\n",
            "prompts=4, completions=4, step=521 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 4.854197978973389, 'learning_rate': 1.5909090909090907e-07, 'num_tokens': 459420.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.020966053009033, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0625}\n",
            "prompts=4, completions=4, step=522 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3636363636363635e-07, 'num_tokens': 464876.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.726125717163086, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06326219512195122}\n",
            "prompts=4, completions=4, step=523 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 9.79154109954834, 'learning_rate': 1.1363636363636363e-07, 'num_tokens': 470348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.53329610824585, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06402439024390244}\n",
            "prompts=4, completions=4, step=524 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.677480220794678, 'learning_rate': 9.09090909090909e-08, 'num_tokens': 476080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.349518299102783, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06478658536585366}\n",
            "prompts=4, completions=4, step=525 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.102912902832031, 'learning_rate': 6.818181818181817e-08, 'num_tokens': 481616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.470164775848389, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06554878048780488}\n",
            "prompts=4, completions=4, step=526 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 8.973053932189941, 'learning_rate': 4.545454545454545e-08, 'num_tokens': 487396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.193968296051025, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0663109756097561}\n",
            "prompts=4, completions=4, step=527 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.2727272727272725e-08, 'num_tokens': 492860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.451163291931152, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06707317073170732}\n",
            "{'train_runtime': 4049.0254, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': -5.8087436275141874e-08, 'epoch': 0.06707317073170732}\n",
            "---- Cycle 11: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:20<00:00, 37.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"exhibit:a\", \"node_type\": \"CLAUSE\", \"title\": \"Exhibit A\", \"level\": null}, {\"id\": \"party:Bkc\", \"node_type\": \"PARTY\", \"name\": \"Bkc\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"exhibit:a\", \"type\": \"REFERENCES\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Bkc\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Fr\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"DIVERSINETCORP_03_01_2012-EX-4-RESELLER AGREEMENT\", \"nodes\": [{\"id\": \"\", \"node_type\": \"CLAUSE\", \"title\": null, \"level\": -1}, {\"id\": \"(a\", \"node_type\": \"CLAUSE\", \"title\": \"\"'\"s Request, Diversinet Will Provide Reseller With Pre-Sales Consulting And Post-\", \"level\": 0}], {\"id\": \"party:Diversinet\", \"node_type\": \"PARTY\", \"name\": \"Diversinet\"}, {\"id\": \"party:Reseller\", \"node_type\": \"PARTY\", \"name\": \"Reseller\"}], \"edges\": [{\"src\": \"(a\", \"tgt\": \"\", \"type\": \"IS_PART_OF\"}, {\"src\": \"(a\", \"tgt\": \"party:Diversinet\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"(a\", \"tgt\": \"party:Reseller\", \"type\": \"MENTIONS_PARTY\"}]}\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10.2\", \"tgt\": \"10\", \"type\": \"IS_PART_OF\"}, {\"src\": \"10.2\", \"tgt\": \"14\", \"type\": \"REFERENCES\"}, {\"src\": \"10.2\", \"tgt\": \"party:Franchisee\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"party:Licensor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"18.2\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "out logged metrics: {'eval_strict_node_precision': 0.7744360902255639, 'eval_strict_node_recall': 0.42386831275720166, 'eval_strict_node_f1': 0.5478723404255319, 'eval_fuzzy_node_precision': 0.7894736842105263, 'eval_fuzzy_node_recall': 0.43209876543209874, 'eval_fuzzy_node_f1': 0.5585106382978723, 'eval_edge_precision': 0.65625, 'eval_edge_recall': 0.33157894736842103, 'eval_edge_f1': 0.4405594405594406, 'eval_exact_graph_match_rate': 0.2, 'eval_invalid_json_rate': 0.26}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 12/15: training to global_step 96 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=528 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.765183925628662, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=529 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9791666666666666e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.469365119934082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=530 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9583333333333334e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.433859348297119, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=531 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9375e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.546492576599121, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=532 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.916666666666667e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6494550704956055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=533 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8958333333333331e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.223184108734131, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=534 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.045499324798584, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=535 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8541666666666666e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.021056652069092, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=536 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.833333333333333e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5223565101623535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=537 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.120253086090088, 'learning_rate': 1.8125e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.037450313568115, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=538 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7916666666666667e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.091329097747803, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=539 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7708333333333332e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.281990051269531, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=540 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.660907745361328, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=541 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7291666666666667e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.687941074371338, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=542 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7083333333333332e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.255951881408691, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=543 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.87732458114624, 'learning_rate': 1.6875e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.216317653656006, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=544 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.011551856994629, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.5549821853637695, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=545 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6458333333333332e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.42903995513916, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=546 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.625e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.42730712890625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=547 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6041666666666666e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.286299228668213, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=548 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.200382232666016, 'learning_rate': 1.5833333333333331e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.988978862762451, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=549 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 7.3830342292785645, 'learning_rate': 1.5624999999999999e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.059897422790527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=550 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5416666666666666e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.695250034332275, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=551 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.070843696594238, 'learning_rate': 1.520833333333333e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.076569080352783, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=552 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.278414249420166, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=553 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4791666666666668e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.508764266967773, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=554 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.375668525695801, 'learning_rate': 1.4583333333333333e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.953145503997803, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=555 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.824733734130859, 'learning_rate': 1.4375e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.354086399078369, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=556 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4166666666666667e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4541425704956055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=557 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3958333333333332e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2573347091674805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=558 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.460381031036377, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=559 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3541666666666667e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.251009464263916, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=560 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333332e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.580824375152588, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=562 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2916666666666667e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.593806743621826, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=563 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 6.752236366271973, 'learning_rate': 1.2708333333333332e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.658682823181152, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=564 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4591755867004395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=565 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2291666666666666e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3786187171936035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=566 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2083333333333331e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.786152362823486, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=567 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1874999999999999e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.185028076171875, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=568 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.054514408111572, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=569 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.077200889587402, 'learning_rate': 1.1458333333333333e-06, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.261545181274414, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=570 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.375855922698975, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=571 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1041666666666668e-06, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.913973331451416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=572 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0833333333333333e-06, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.032353401184082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=573 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0625e-06, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7541608810424805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=574 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0416666666666667e-06, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.444342613220215, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=575 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0208333333333332e-06, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.180328369140625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=576 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.285872459411621, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=577 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.791666666666667e-07, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.589088439941406, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=578 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.583333333333334e-07, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.181257724761963, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=579 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.374999999999999e-07, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.159838676452637, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=580 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.166666666666665e-07, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.66861629486084, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=581 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.958333333333334e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.314335346221924, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=582 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.123795509338379, 'learning_rate': 8.75e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.802469253540039, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=583 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.541666666666666e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.307039737701416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=584 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.864785194396973, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=585 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.125e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.281685829162598, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=586 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.916666666666666e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.374528408050537, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=587 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.708333333333333e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.34438943862915, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=588 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2154059410095215, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=589 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.291666666666666e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.042663097381592, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=590 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.083333333333334e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.291223526000977, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=591 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 14.470060348510742, 'learning_rate': 6.875e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.656991958618164, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=592 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.220120906829834, 'learning_rate': 6.666666666666666e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.7656049728393555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=593 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.458333333333333e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.732430934906006, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=594 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.463000297546387, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=595 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.041666666666666e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.132105827331543, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=596 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.833333333333334e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.20273494720459, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=597 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.625e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.550344467163086, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=598 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.416666666666666e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.211343765258789, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=599 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 7.499959945678711, 'learning_rate': 5.208333333333334e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.103953838348389, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=600 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 7.440028190612793, 'learning_rate': 5e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.43729829788208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=601 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.791666666666667e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.373815059661865, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=602 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.5833333333333327e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.233463287353516, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=603 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.375e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0810675621032715, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=604 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.286576271057129, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=605 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.958333333333333e-07, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.459718227386475, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=606 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.75e-07, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.671139240264893, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=607 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.85334300994873, 'learning_rate': 3.541666666666667e-07, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.712768077850342, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "prompts=4, completions=4, step=608 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.333333333333333e-07, 'num_tokens': 453600.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.971986770629883, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06173780487804878}\n",
            "prompts=4, completions=4, step=609 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.1249999999999997e-07, 'num_tokens': 459420.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.303643226623535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0625}\n",
            "prompts=4, completions=4, step=610 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.916666666666667e-07, 'num_tokens': 464876.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.145399570465088, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06326219512195122}\n",
            "prompts=4, completions=4, step=611 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 5.656121253967285, 'learning_rate': 2.708333333333333e-07, 'num_tokens': 470348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.167547225952148, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06402439024390244}\n",
            "prompts=4, completions=4, step=612 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.311148643493652, 'learning_rate': 2.5e-07, 'num_tokens': 476080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.868844985961914, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06478658536585366}\n",
            "prompts=4, completions=4, step=613 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.899868965148926, 'learning_rate': 2.2916666666666663e-07, 'num_tokens': 481616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.816746711730957, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06554878048780488}\n",
            "prompts=4, completions=4, step=614 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.0833333333333333e-07, 'num_tokens': 487396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.177155017852783, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0663109756097561}\n",
            "prompts=4, completions=4, step=615 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.875e-07, 'num_tokens': 492860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.784229755401611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06707317073170732}\n",
            "prompts=4, completions=4, step=616 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666665e-07, 'num_tokens': 498436.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.515524387359619, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06783536585365854}\n",
            "prompts=4, completions=4, step=617 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4583333333333335e-07, 'num_tokens': 504248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.073373794555664, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06859756097560976}\n",
            "prompts=4, completions=4, step=618 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.25e-07, 'num_tokens': 509628.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.224576950073242, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06935975609756098}\n",
            "prompts=4, completions=4, step=619 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.837554931640625, 'learning_rate': 1.0416666666666667e-07, 'num_tokens': 515132.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.381998538970947, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0701219512195122}\n",
            "prompts=4, completions=4, step=620 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 520916.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.097449779510498, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07088414634146341}\n",
            "prompts=4, completions=4, step=621 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.684749603271484, 'learning_rate': 6.25e-08, 'num_tokens': 526840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.9698262214660645, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07164634146341463}\n",
            "prompts=4, completions=4, step=622 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.1653470993042, 'learning_rate': 4.166666666666666e-08, 'num_tokens': 532408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.363076686859131, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07240853658536585}\n",
            "prompts=4, completions=4, step=623 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.4818501472473145, 'learning_rate': 2.083333333333333e-08, 'num_tokens': 537828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.70845365524292, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07317073170731707}\n",
            "{'train_runtime': 4411.7364, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': -4.639228246006155e-08, 'epoch': 0.07317073170731707}\n",
            "---- Cycle 12: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:27<00:00, 38.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.6\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.6\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"11.1.6\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.6\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) Days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) Days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"ANNUAL FINANCIAL STATEMENT\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ninety (90) days\"}], \"edges\": [{\"src\": \"10.2\", \"tgt\": \"10\", \"type\": \"IS_PART_OF\"}, {\"src\": \"10.2\", \"tgt\": \"14\", \"type\": \"REFERENCES\"}, {\"src\": \"10.2\", \"tgt\": \"party:Franchisee\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8657718120805369, 'eval_strict_node_recall': 0.5352697095435685, 'eval_strict_node_f1': 0.6615384615384615, 'eval_fuzzy_node_precision': 0.8657718120805369, 'eval_fuzzy_node_recall': 0.5352697095435685, 'eval_fuzzy_node_f1': 0.6615384615384615, 'eval_edge_precision': 0.7636363636363637, 'eval_edge_recall': 0.44680851063829785, 'eval_edge_f1': 0.563758389261745, 'eval_exact_graph_match_rate': 0.24, 'eval_invalid_json_rate': 0.2}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 13/15: training to global_step 104 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=624 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.24448823928833, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=625 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9807692307692306e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.070434093475342, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=626 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.690771579742432, 'learning_rate': 1.9615384615384612e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.173280715942383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=627 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9423076923076923e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.789118766784668, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=628 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 7.213197231292725, 'learning_rate': 1.923076923076923e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.227436542510986, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=629 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9038461538461536e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3160505294799805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=630 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8846153846153845e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.34824800491333, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=631 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.697387218475342, 'learning_rate': 1.8653846153846154e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.463141918182373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=632 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.26757287979126, 'learning_rate': 1.8461538461538462e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.053751468658447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=633 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8269230769230767e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.255723476409912, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=634 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8076923076923076e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.260248184204102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=635 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7884615384615384e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.031806468963623, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=636 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.769230769230769e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.068056583404541, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=637 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.342411994934082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=638 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7307692307692308e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.454755783081055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=639 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7115384615384613e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2958455085754395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=640 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.692564964294434, 'learning_rate': 1.6923076923076922e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.345980644226074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=641 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.673076923076923e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.615251541137695, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=642 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.20663833618164, 'learning_rate': 1.6538461538461537e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.909593105316162, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=643 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.577540397644043, 'learning_rate': 1.6346153846153846e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.612346649169922, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=644 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6153846153846154e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7837700843811035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=645 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.596153846153846e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.353747844696045, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=646 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5769230769230768e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6378655433654785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=647 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5576923076923076e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.227471351623535, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=648 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5384615384615385e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.375637054443359, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=649 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5192307692307692e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.294053077697754, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=650 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.716240882873535, 'learning_rate': 1.5e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.2926506996154785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=651 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4807692307692307e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.676955699920654, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=652 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4615384615384614e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.098138809204102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=653 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4423076923076922e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.351908206939697, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=654 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.423076923076923e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.067365646362305, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=655 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4038461538461538e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.558666706085205, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=656 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3846153846153844e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.096546173095703, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=657 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 12.29094123840332, 'learning_rate': 1.3653846153846153e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.9111008644104, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=658 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.107858657836914, 'learning_rate': 1.3461538461538462e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.903927326202393, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=659 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3269230769230768e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.491888046264648, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=660 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 8.580220222473145, 'learning_rate': 1.3076923076923077e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.84950590133667, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=661 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.503103256225586, 'learning_rate': 1.2884615384615386e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.013730049133301, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=662 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.269230769230769e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.073390960693359, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=663 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.964099884033203, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.231136322021484, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=664 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.797233581542969, 'learning_rate': 1.2307692307692308e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.466495513916016, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=665 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2115384615384614e-06, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.908143997192383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=666 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.77331829071045, 'learning_rate': 1.1923076923076923e-06, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.364506721496582, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=667 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1730769230769232e-06, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.94333553314209, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=668 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.23309326171875, 'learning_rate': 1.1538461538461536e-06, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.029202938079834, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=669 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.098800659179688, 'learning_rate': 1.1346153846153845e-06, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.1364874839782715, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=670 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.688339233398438, 'learning_rate': 1.1153846153846154e-06, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.127275466918945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=671 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0961538461538462e-06, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.711797714233398, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=672 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 20.380077362060547, 'learning_rate': 1.0769230769230769e-06, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.5284295082092285, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=673 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0576923076923078e-06, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.379845142364502, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=674 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0384615384615384e-06, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.898310661315918, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=675 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.759910583496094, 'learning_rate': 1.019230769230769e-06, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.803953647613525, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=676 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1245832443237305, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=677 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.993522644042969, 'learning_rate': 9.807692307692306e-07, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.976097106933594, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=678 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.940597534179688, 'learning_rate': 9.615384615384615e-07, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.56941556930542, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=679 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.37601375579834, 'learning_rate': 9.423076923076923e-07, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.6978349685668945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=680 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.230769230769231e-07, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.945330619812012, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=681 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.038461538461538e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.134280681610107, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=682 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.846153846153846e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.003581523895264, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=683 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 7.673610687255859, 'learning_rate': 8.653846153846154e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.922787189483643, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=684 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.89295768737793, 'learning_rate': 8.461538461538461e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.2533745765686035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=685 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 13.72531509399414, 'learning_rate': 8.269230769230768e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.023859024047852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=686 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.076923076923077e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.187218189239502, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=687 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.315441131591797, 'learning_rate': 7.884615384615384e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.815645217895508, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=688 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.692307692307693e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.115396976470947, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=689 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.5e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.004096031188965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=690 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 12.411314010620117, 'learning_rate': 7.307692307692307e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.237040042877197, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=691 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 9.698873519897461, 'learning_rate': 7.115384615384616e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.269783020019531, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=692 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.923076923076922e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.307356357574463, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=693 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.730769230769231e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.753069877624512, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=694 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.538461538461538e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.694868087768555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=695 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.346153846153845e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.205190181732178, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=696 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.153846153846154e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.9214186668396, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=697 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.961538461538461e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.081026554107666, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=698 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.497092247009277, 'learning_rate': 5.769230769230768e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.021071910858154, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=699 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.576923076923077e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1780219078063965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=700 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.384615384615384e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0391998291015625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=701 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.420190811157227, 'learning_rate': 5.192307692307692e-07, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.8333210945129395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=702 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 9.7219820022583, 'learning_rate': 5e-07, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.70475435256958, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=703 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.807692307692307e-07, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.422266483306885, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "prompts=4, completions=4, step=704 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.6153846153846156e-07, 'num_tokens': 453600.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.916453838348389, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06173780487804878}\n",
            "prompts=4, completions=4, step=705 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.423076923076923e-07, 'num_tokens': 459420.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.218664169311523, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0625}\n",
            "prompts=4, completions=4, step=706 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.2307692307692304e-07, 'num_tokens': 464876.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.806911468505859, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06326219512195122}\n",
            "prompts=4, completions=4, step=707 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.77415943145752, 'learning_rate': 4.0384615384615386e-07, 'num_tokens': 470348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.765376091003418, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06402439024390244}\n",
            "prompts=4, completions=4, step=708 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.631012916564941, 'learning_rate': 3.8461538461538463e-07, 'num_tokens': 476080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.9096574783325195, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06478658536585366}\n",
            "prompts=4, completions=4, step=709 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.6538461538461534e-07, 'num_tokens': 481616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3184661865234375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06554878048780488}\n",
            "prompts=4, completions=4, step=710 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 16.656827926635742, 'learning_rate': 3.461538461538461e-07, 'num_tokens': 487396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.565732479095459, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0663109756097561}\n",
            "prompts=4, completions=4, step=711 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.269230769230769e-07, 'num_tokens': 492860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.323321342468262, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06707317073170732}\n",
            "prompts=4, completions=4, step=712 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.076923076923077e-07, 'num_tokens': 498436.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.8541579246521, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06783536585365854}\n",
            "prompts=4, completions=4, step=713 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.483591079711914, 'learning_rate': 2.884615384615384e-07, 'num_tokens': 504248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.2061614990234375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06859756097560976}\n",
            "prompts=4, completions=4, step=714 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.692307692307692e-07, 'num_tokens': 509628.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.913968086242676, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06935975609756098}\n",
            "prompts=4, completions=4, step=715 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.744454383850098, 'learning_rate': 2.5e-07, 'num_tokens': 515132.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.2630815505981445, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0701219512195122}\n",
            "prompts=4, completions=4, step=716 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.3076923076923078e-07, 'num_tokens': 520916.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.579184532165527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07088414634146341}\n",
            "prompts=4, completions=4, step=717 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.1153846153846152e-07, 'num_tokens': 526840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.027821063995361, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07164634146341463}\n",
            "prompts=4, completions=4, step=718 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9230769230769231e-07, 'num_tokens': 532408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.69326639175415, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07240853658536585}\n",
            "prompts=4, completions=4, step=719 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.394371032714844, 'learning_rate': 1.7307692307692305e-07, 'num_tokens': 537828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.0642619132995605, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07317073170731707}\n",
            "prompts=4, completions=4, step=720 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5384615384615385e-07, 'num_tokens': 543332.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.088168144226074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07393292682926829}\n",
            "prompts=4, completions=4, step=721 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.158866882324219, 'learning_rate': 1.346153846153846e-07, 'num_tokens': 548752.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.642350196838379, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07469512195121951}\n",
            "prompts=4, completions=4, step=722 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.9109392166137695, 'learning_rate': 1.1538461538461539e-07, 'num_tokens': 554104.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.502834796905518, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07545731707317073}\n",
            "prompts=4, completions=4, step=723 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.908483505249023, 'learning_rate': 9.615384615384616e-08, 'num_tokens': 559768.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.823670387268066, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07621951219512195}\n",
            "prompts=4, completions=4, step=724 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.692307692307692e-08, 'num_tokens': 565268.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.136406421661377, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07698170731707317}\n",
            "prompts=4, completions=4, step=725 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.7692307692307695e-08, 'num_tokens': 571032.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.877003192901611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07774390243902439}\n",
            "prompts=4, completions=4, step=726 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 13.86758041381836, 'learning_rate': 3.846153846153846e-08, 'num_tokens': 576868.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.543650150299072, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07850609756097561}\n",
            "prompts=4, completions=4, step=727 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.014808654785156, 'learning_rate': 1.923076923076923e-08, 'num_tokens': 582624.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.072395324707031, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07926829268292683}\n",
            "{'train_runtime': 4810.4748, 'train_samples_per_second': 0.086, 'train_steps_per_second': 0.022, 'train_loss': -8.111471754108817e-08, 'epoch': 0.07926829268292683}\n",
            "---- Cycle 13: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:19<00:00, 37.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5\", \"node_type\": \"CLAUSE\", \"title\": \"5\", \"level\": 1}, {\"id\": \"5.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.1\", \"level\": 2}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Burger King System\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King System\"}], \"edges\": [{\"src\": \"5.1\", \"tgt\": \"5\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.1\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.1\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"5.1\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADEL TECHNOLOGIES INC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8251748251748252, 'eval_strict_node_recall': 0.48360655737704916, 'eval_strict_node_f1': 0.6098191214470283, 'eval_fuzzy_node_precision': 0.8391608391608392, 'eval_fuzzy_node_recall': 0.4918032786885246, 'eval_fuzzy_node_f1': 0.6201550387596898, 'eval_edge_precision': 0.6981132075471698, 'eval_edge_recall': 0.387434554973822, 'eval_edge_f1': 0.4983164983164984, 'eval_exact_graph_match_rate': 0.16, 'eval_invalid_json_rate': 0.22}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 14/15: training to global_step 112 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=728 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.416050910949707, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=729 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.982142857142857e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.826542854309082, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=730 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.964285714285714e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.10380220413208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=731 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 6.887955188751221, 'learning_rate': 1.9464285714285712e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.188076972961426, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=732 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9285714285714285e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.500103950500488, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=733 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9107142857142858e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.203943729400635, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=734 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8928571428571428e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7707624435424805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=735 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.99014663696289, 'learning_rate': 1.8749999999999998e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.0931620597839355, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=736 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.857142857142857e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.460198402404785, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=737 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.423762321472168, 'learning_rate': 1.8392857142857141e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.925835132598877, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=738 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.596421241760254, 'learning_rate': 1.8214285714285714e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.170275688171387, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=739 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8035714285714284e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1543402671813965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=740 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7857142857142857e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.906106472015381, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=741 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7678571428571427e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.76272439956665, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=742 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.75e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.005990982055664, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=743 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 17.339401245117188, 'learning_rate': 1.7321428571428572e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.74667501449585, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=744 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 16.317737579345703, 'learning_rate': 1.714285714285714e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.862257480621338, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=745 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6964285714285713e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.138663291931152, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=746 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.83718204498291, 'learning_rate': 1.6785714285714286e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.937706470489502, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=747 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.246728897094727, 'learning_rate': 1.6607142857142858e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.002893924713135, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=748 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 16.919116973876953, 'learning_rate': 1.6428571428571426e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.09757661819458, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=749 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 17.511350631713867, 'learning_rate': 1.625e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.728613376617432, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=750 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6071428571428572e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.0554609298706055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=751 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.405672073364258, 'learning_rate': 1.5892857142857142e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.369688987731934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=752 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 12.46002197265625, 'learning_rate': 1.5714285714285712e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.865506649017334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=753 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5535714285714285e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.943198204040527, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=754 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5357142857142857e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.900395393371582, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=755 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5178571428571428e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.349680423736572, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=756 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.068413257598877, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=757 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.151239395141602, 'learning_rate': 1.482142857142857e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.811157703399658, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=758 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4642857142857141e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.333571434020996, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=759 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4464285714285714e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.889397144317627, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=760 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.682723045349121, 'learning_rate': 1.4285714285714286e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.618821144104004, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=761 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.547627449035645, 'learning_rate': 1.4107142857142857e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.805668830871582, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=762 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3928571428571427e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.659564018249512, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=763 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.375e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.9042649269104, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=764 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3571428571428572e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.065170764923096, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=765 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.339285714285714e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.170289993286133, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=766 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3214285714285713e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.95223331451416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=767 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3035714285714286e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.932318687438965, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=768 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 13.25005054473877, 'learning_rate': 1.2857142857142858e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.895593643188477, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=769 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2678571428571426e-06, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.303584575653076, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=770 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.939602851867676, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=771 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.009072303771973, 'learning_rate': 1.2321428571428571e-06, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.902907848358154, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=772 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.320695877075195, 'learning_rate': 1.2142857142857142e-06, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.900523662567139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=773 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1964285714285714e-06, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.6919074058532715, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=774 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1785714285714285e-06, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.910584449768066, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=775 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1607142857142857e-06, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.908698558807373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=776 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1428571428571428e-06, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.106963634490967, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=777 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.125e-06, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.609166622161865, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=778 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.107142857142857e-06, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.580700397491455, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=779 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0892857142857141e-06, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.096005916595459, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=780 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0714285714285714e-06, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0907769203186035, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=781 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0535714285714286e-06, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.892350196838379, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=782 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0357142857142857e-06, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.66541051864624, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=783 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0178571428571427e-06, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.066173076629639, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=784 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.365792274475098, 'learning_rate': 1e-06, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.265007019042969, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=785 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.82142857142857e-07, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2291259765625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=786 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.642857142857142e-07, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.67517614364624, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=787 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.464285714285714e-07, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.220355033874512, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=788 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.285714285714285e-07, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.934070110321045, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=789 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.107142857142857e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.167195796966553, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=790 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.928571428571428e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.108337879180908, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=791 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 22.12812614440918, 'learning_rate': 8.75e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.931911945343018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=792 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 18.901241302490234, 'learning_rate': 8.57142857142857e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.810261249542236, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=793 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 20.46637725830078, 'learning_rate': 8.392857142857143e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.4126081466674805, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=794 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.063023567199707, 'learning_rate': 8.214285714285713e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.001407623291016, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=795 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.035714285714286e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.554834842681885, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=796 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.857142857142856e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.1937575340271, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=797 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.678571428571429e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.900146961212158, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=798 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.838179588317871, 'learning_rate': 7.5e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.77128267288208, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=799 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.321428571428571e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.664098262786865, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=800 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.142857142857143e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.984462261199951, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=801 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.075618743896484, 'learning_rate': 6.964285714285714e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.1007890701293945, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=802 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.785714285714286e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.922351837158203, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=803 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.398716926574707, 'learning_rate': 6.607142857142857e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.290224075317383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=804 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 18.042377471923828, 'learning_rate': 6.428571428571429e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.085236549377441, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=805 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.642382621765137, 'learning_rate': 6.249999999999999e-07, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.968883037567139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=806 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.071428571428571e-07, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.079654216766357, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=807 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.892857142857142e-07, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.131144046783447, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "prompts=4, completions=4, step=808 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.714285714285714e-07, 'num_tokens': 453600.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.04897403717041, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06173780487804878}\n",
            "prompts=4, completions=4, step=809 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.535714285714285e-07, 'num_tokens': 459420.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.987637519836426, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0625}\n",
            "prompts=4, completions=4, step=810 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.357142857142857e-07, 'num_tokens': 464876.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.085370063781738, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06326219512195122}\n",
            "prompts=4, completions=4, step=811 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.471345901489258, 'learning_rate': 5.178571428571428e-07, 'num_tokens': 470348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.501930236816406, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06402439024390244}\n",
            "prompts=4, completions=4, step=812 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 476080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.609253406524658, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06478658536585366}\n",
            "prompts=4, completions=4, step=813 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 12.955489158630371, 'learning_rate': 4.821428571428571e-07, 'num_tokens': 481616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.057064533233643, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06554878048780488}\n",
            "prompts=4, completions=4, step=814 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.361167907714844, 'learning_rate': 4.6428571428571427e-07, 'num_tokens': 487396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.794052600860596, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0663109756097561}\n",
            "prompts=4, completions=4, step=815 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.006610870361328, 'learning_rate': 4.464285714285714e-07, 'num_tokens': 492860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.904479026794434, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06707317073170732}\n",
            "prompts=4, completions=4, step=816 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.285714285714285e-07, 'num_tokens': 498436.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.868391513824463, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06783536585365854}\n",
            "prompts=4, completions=4, step=817 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.1071428571428566e-07, 'num_tokens': 504248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.965503215789795, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06859756097560976}\n",
            "prompts=4, completions=4, step=818 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 14.52631950378418, 'learning_rate': 3.928571428571428e-07, 'num_tokens': 509628.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.604362487792969, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06935975609756098}\n",
            "prompts=4, completions=4, step=819 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.75e-07, 'num_tokens': 515132.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.948709487915039, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0701219512195122}\n",
            "prompts=4, completions=4, step=820 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5714285714285716e-07, 'num_tokens': 520916.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.039556980133057, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07088414634146341}\n",
            "prompts=4, completions=4, step=821 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.392857142857143e-07, 'num_tokens': 526840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.006058216094971, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07164634146341463}\n",
            "prompts=4, completions=4, step=822 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.2142857142857145e-07, 'num_tokens': 532408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.357165813446045, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07240853658536585}\n",
            "prompts=4, completions=4, step=823 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.0357142857142855e-07, 'num_tokens': 537828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.796882152557373, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07317073170731707}\n",
            "prompts=4, completions=4, step=824 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.857142857142857e-07, 'num_tokens': 543332.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.725072383880615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07393292682926829}\n",
            "prompts=4, completions=4, step=825 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.6785714285714284e-07, 'num_tokens': 548752.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.112553119659424, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07469512195121951}\n",
            "prompts=4, completions=4, step=826 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.331464767456055, 'learning_rate': 2.5e-07, 'num_tokens': 554104.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.720649242401123, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07545731707317073}\n",
            "prompts=4, completions=4, step=827 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.3214285714285714e-07, 'num_tokens': 559768.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.057575225830078, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07621951219512195}\n",
            "prompts=4, completions=4, step=828 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.1428571428571426e-07, 'num_tokens': 565268.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.520796775817871, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07698170731707317}\n",
            "prompts=4, completions=4, step=829 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.964285714285714e-07, 'num_tokens': 571032.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.852262020111084, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07774390243902439}\n",
            "prompts=4, completions=4, step=830 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7857142857142858e-07, 'num_tokens': 576868.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.924564838409424, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07850609756097561}\n",
            "prompts=4, completions=4, step=831 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 17.511638641357422, 'learning_rate': 1.6071428571428573e-07, 'num_tokens': 582624.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.2756757736206055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07926829268292683}\n",
            "prompts=4, completions=4, step=832 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.183847427368164, 'learning_rate': 1.4285714285714285e-07, 'num_tokens': 588448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.911385536193848, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08003048780487805}\n",
            "prompts=4, completions=4, step=833 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.053976058959961, 'learning_rate': 1.25e-07, 'num_tokens': 594036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.418724536895752, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08079268292682927}\n",
            "prompts=4, completions=4, step=834 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0714285714285713e-07, 'num_tokens': 599660.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.325878143310547, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08155487804878049}\n",
            "prompts=4, completions=4, step=835 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.928571428571429e-08, 'num_tokens': 605248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.58169412612915, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08231707317073171}\n",
            "prompts=4, completions=4, step=836 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.142857142857142e-08, 'num_tokens': 610652.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.5283708572387695, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08307926829268293}\n",
            "prompts=4, completions=4, step=837 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.3571428571428564e-08, 'num_tokens': 616204.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.018937110900879, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08384146341463415}\n",
            "prompts=4, completions=4, step=838 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.651991844177246, 'learning_rate': 3.571428571428571e-08, 'num_tokens': 621828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.596851825714111, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08460365853658537}\n",
            "prompts=4, completions=4, step=839 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7857142857142856e-08, 'num_tokens': 627692.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.511858940124512, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08536585365853659}\n",
            "{'train_runtime': 5152.4141, 'train_samples_per_second': 0.087, 'train_steps_per_second': 0.022, 'train_loss': -6.805877372784153e-08, 'epoch': 0.08536585365853659}\n",
            "---- Cycle 14: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:21<00:00, 37.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"18\", \"node_type\": \"CLAUSE\", \"title\": \"18\", \"level\": 1}, {\"id\": \"18.2\", \"node_type\": \"CLAUSE\", \"title\": \"18.2\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Licensor\", \"node_type\": \"PARTY\", \"name\": \"Licensor\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Term Of The Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term Of The Agreement\"}, {\"id\": \"value:thirty(30) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"thirty(30) days\"}, {\"id\": \"value:sixty(60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty(60) days\"}], \"edges\": [{\"src\": \"18.2\", \"tgt\": \"18\", \"type\": \"IS_PART_OF\"}, {\"src\": \"18.2\",\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELITECHNOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"defined_term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"value:ten (10) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Arbitration Committee\", \"type\": \"USES\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"defined_term:P\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"4\", \"node_type\": \"CLAUSE\", \"title\": \"4\", \"level\": 1}, {\"id\": \"4.4\", \"node_type\": \"CLAUSE\", \"title\": \"4.4\", \"level\": 2}, {\"id\": \"8\", \"node_type\": \"CLAUSE\", \"title\": \"PRICES AND TERMS\", \"level\": 1}, {\"id\": \"defined_term:Distributor\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Distributor\"}, {\"id\": \"defined_term:Ppg Shanghai\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"defined_term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"4.4\", \"tgt\": \"4\", \"type\": \"IS_PART_OF\"}, {\"src\": \"4.4\", \"tgt\": \"8\", \"type\": \"REFERENCES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Distributor\", \"type\": \"USES\"}, {\"src\": \"4.4\", \"tgt\": \"defined_term:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"4.4\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.16\", \"node_type\": \"CLAUSE\", \"title\": \"5.16\", \"level\": 2}, {\"id\": \"5.16.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.16.2\", \"level\": 3}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Approved Suppliers And/Or Distributors\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Approved Suppliers And/Or Distributors\"}, {\"id\": \"term:Frischased Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischased Restaurant\"}], \"edges\": [{\"src\": \"5.16.2\", \"tgt\": \"5.16\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.16.2\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.16.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"10.2\", \"node_type\": \"CLAUSE\", \"title\": \"10.2\", \"level\": 2}, {\"id\": \"10\", \"node_type\": \"CLAUSE\", \"title\": \"10\", \"level\": 1}, {\"id\": \"14\", \"node_type\": \"CLAUSE\", \"title\": \"14\", \"level\": 0}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Certified Public Accountant\", \"node_type\": \"PARTY\", \"name\": \"Certified Public Accountant\"}, {\"id\": \"defined_term:Annual Financial Statement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Annual Financial Statement\"}, {\"id\": \"defined_term:Fiscal Year\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Fiscal Year\"}, {\"id\": \"defined_term:Franchisee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchisee\"}, {\"id\": \"defined_term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}, {\"id\": \"value:ninety (90) days\", \"node_type\": \"VALUE\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADEL TECHNOLOGIES INC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8432835820895522, 'eval_strict_node_recall': 0.47478991596638653, 'eval_strict_node_f1': 0.6075268817204301, 'eval_fuzzy_node_precision': 0.8582089552238806, 'eval_fuzzy_node_recall': 0.4831932773109244, 'eval_fuzzy_node_f1': 0.6182795698924731, 'eval_edge_precision': 0.7244897959183674, 'eval_edge_recall': 0.3817204301075269, 'eval_edge_f1': 0.5, 'eval_exact_graph_match_rate': 0.22, 'eval_invalid_json_rate': 0.24}\n",
            "printing metrics <class 'dict'>\n",
            "\n",
            "==== Cycle 15/15: training to global_step 120 ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompts=4, completions=4, step=840 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2e-06, 'num_tokens': 5376.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.986189365386963, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0007621951219512195}\n",
            "prompts=4, completions=4, step=841 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.983333333333333e-06, 'num_tokens': 11080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.047249794006348, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.001524390243902439}\n",
            "prompts=4, completions=4, step=842 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.9666666666666663e-06, 'num_tokens': 16516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.078446388244629, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0022865853658536584}\n",
            "prompts=4, completions=4, step=843 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.95e-06, 'num_tokens': 22232.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.636259078979492, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.003048780487804878}\n",
            "prompts=4, completions=4, step=844 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.933333333333333e-06, 'num_tokens': 27688.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.709500789642334, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0038109756097560975}\n",
            "prompts=4, completions=4, step=845 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.916666666666667e-06, 'num_tokens': 33024.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.0347394943237305, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.004573170731707317}\n",
            "prompts=4, completions=4, step=846 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8999999999999998e-06, 'num_tokens': 38712.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.394223213195801, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.005335365853658537}\n",
            "prompts=4, completions=4, step=847 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8833333333333332e-06, 'num_tokens': 44524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.059630393981934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006097560975609756}\n",
            "prompts=4, completions=4, step=848 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.8666666666666667e-06, 'num_tokens': 49860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.906676769256592, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.006859756097560976}\n",
            "prompts=4, completions=4, step=849 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.85e-06, 'num_tokens': 55840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3767409324646, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.007621951219512195}\n",
            "prompts=4, completions=4, step=850 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.833333333333333e-06, 'num_tokens': 61256.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.627230644226074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.008384146341463415}\n",
            "prompts=4, completions=4, step=851 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 16.78201675415039, 'learning_rate': 1.8166666666666665e-06, 'num_tokens': 66888.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.136863708496094, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009146341463414634}\n",
            "prompts=4, completions=4, step=852 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.64294147491455, 'learning_rate': 1.8e-06, 'num_tokens': 72520.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.89170503616333, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.009908536585365854}\n",
            "prompts=4, completions=4, step=853 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7833333333333333e-06, 'num_tokens': 78120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.2185750007629395, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.010670731707317074}\n",
            "prompts=4, completions=4, step=854 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7666666666666666e-06, 'num_tokens': 83640.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.521296977996826, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.011432926829268292}\n",
            "prompts=4, completions=4, step=855 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.532943725585938, 'learning_rate': 1.75e-06, 'num_tokens': 89148.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.841425895690918, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012195121951219513}\n",
            "prompts=4, completions=4, step=856 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7333333333333334e-06, 'num_tokens': 94704.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.389284610748291, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.012957317073170731}\n",
            "prompts=4, completions=4, step=857 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.7166666666666664e-06, 'num_tokens': 100516.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.026045322418213, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.013719512195121951}\n",
            "prompts=4, completions=4, step=858 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6999999999999998e-06, 'num_tokens': 106004.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.76386022567749, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.014481707317073171}\n",
            "prompts=4, completions=4, step=859 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6833333333333332e-06, 'num_tokens': 111464.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.008801460266113, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01524390243902439}\n",
            "prompts=4, completions=4, step=860 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.454535484313965, 'learning_rate': 1.6666666666666667e-06, 'num_tokens': 117036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.814077377319336, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01600609756097561}\n",
            "prompts=4, completions=4, step=861 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6499999999999999e-06, 'num_tokens': 122408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.052475929260254, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01676829268292683}\n",
            "prompts=4, completions=4, step=862 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6333333333333333e-06, 'num_tokens': 128028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.982650279998779, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.01753048780487805}\n",
            "prompts=4, completions=4, step=863 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6166666666666667e-06, 'num_tokens': 133788.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.32990026473999, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.018292682926829267}\n",
            "prompts=4, completions=4, step=864 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.483816146850586, 'learning_rate': 1.6e-06, 'num_tokens': 139428.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.895884990692139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019054878048780487}\n",
            "prompts=4, completions=4, step=865 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5833333333333331e-06, 'num_tokens': 145320.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.6340742111206055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.019817073170731708}\n",
            "prompts=4, completions=4, step=866 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5666666666666666e-06, 'num_tokens': 150928.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.170443534851074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.020579268292682928}\n",
            "prompts=4, completions=4, step=867 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.55e-06, 'num_tokens': 156544.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.10031795501709, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.021341463414634148}\n",
            "prompts=4, completions=4, step=868 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5333333333333334e-06, 'num_tokens': 162492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.073094844818115, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022103658536585365}\n",
            "prompts=4, completions=4, step=869 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5166666666666666e-06, 'num_tokens': 168044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.965101718902588, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.022865853658536585}\n",
            "prompts=4, completions=4, step=870 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.695528984069824, 'learning_rate': 1.5e-06, 'num_tokens': 173408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.197012424468994, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.023628048780487805}\n",
            "prompts=4, completions=4, step=871 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4833333333333332e-06, 'num_tokens': 178908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.674066543579102, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.024390243902439025}\n",
            "prompts=4, completions=4, step=872 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4666666666666665e-06, 'num_tokens': 184644.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.713901996612549, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025152439024390245}\n",
            "prompts=4, completions=4, step=873 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4499999999999999e-06, 'num_tokens': 190344.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.023605823516846, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.025914634146341462}\n",
            "prompts=4, completions=4, step=874 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 17.15069007873535, 'learning_rate': 1.4333333333333333e-06, 'num_tokens': 196348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.002278804779053, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.026676829268292682}\n",
            "prompts=4, completions=4, step=875 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4166666666666667e-06, 'num_tokens': 202180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.861788272857666, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.027439024390243903}\n",
            "prompts=4, completions=4, step=876 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.4e-06, 'num_tokens': 207748.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.091982841491699, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028201219512195123}\n",
            "prompts=4, completions=4, step=877 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3833333333333331e-06, 'num_tokens': 213120.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.708235263824463, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.028963414634146343}\n",
            "prompts=4, completions=4, step=878 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3666666666666666e-06, 'num_tokens': 218728.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.036856651306152, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.02972560975609756}\n",
            "prompts=4, completions=4, step=879 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.35e-06, 'num_tokens': 224616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7099289894104, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03048780487804878}\n",
            "prompts=4, completions=4, step=880 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3333333333333332e-06, 'num_tokens': 229972.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.898470878601074, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03125}\n",
            "prompts=4, completions=4, step=881 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3166666666666666e-06, 'num_tokens': 235540.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.338375568389893, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03201219512195122}\n",
            "prompts=4, completions=4, step=882 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.3e-06, 'num_tokens': 241108.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.158177852630615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03277439024390244}\n",
            "prompts=4, completions=4, step=883 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.30367374420166, 'learning_rate': 1.2833333333333335e-06, 'num_tokens': 246696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.050187110900879, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03353658536585366}\n",
            "prompts=4, completions=4, step=884 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2666666666666665e-06, 'num_tokens': 252116.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.299745559692383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.03429878048780488}\n",
            "prompts=4, completions=4, step=885 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.67106819152832, 'learning_rate': 1.2499999999999999e-06, 'num_tokens': 257508.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.996856212615967, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0350609756097561}\n",
            "prompts=4, completions=4, step=886 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 29.998634338378906, 'learning_rate': 1.2333333333333333e-06, 'num_tokens': 262952.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.421650409698486, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.035823170731707314}\n",
            "prompts=4, completions=4, step=887 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.2166666666666665e-06, 'num_tokens': 268848.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.629401206970215, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.036585365853658534}\n",
            "prompts=4, completions=4, step=888 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.090232849121094, 'learning_rate': 1.2e-06, 'num_tokens': 274396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.991106033325195, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.037347560975609755}\n",
            "prompts=4, completions=4, step=889 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1833333333333334e-06, 'num_tokens': 280000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.844907283782959, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038109756097560975}\n",
            "prompts=4, completions=4, step=890 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 285492.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.075547695159912, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.038871951219512195}\n",
            "prompts=4, completions=4, step=891 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1499999999999998e-06, 'num_tokens': 291308.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.235278606414795, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.039634146341463415}\n",
            "prompts=4, completions=4, step=892 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1333333333333332e-06, 'num_tokens': 296824.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.370478630065918, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.040396341463414635}\n",
            "prompts=4, completions=4, step=893 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1166666666666666e-06, 'num_tokens': 302416.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.095129013061523, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041158536585365856}\n",
            "prompts=4, completions=4, step=894 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 18.947439193725586, 'learning_rate': 1.1e-06, 'num_tokens': 308084.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.934438705444336, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.041920731707317076}\n",
            "prompts=4, completions=4, step=895 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0833333333333333e-06, 'num_tokens': 313696.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.3124775886535645, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.042682926829268296}\n",
            "prompts=4, completions=4, step=896 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0666666666666667e-06, 'num_tokens': 319404.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.262072563171387, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04344512195121951}\n",
            "prompts=4, completions=4, step=897 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.985536575317383, 'learning_rate': 1.05e-06, 'num_tokens': 324776.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.91098165512085, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04420731707317073}\n",
            "prompts=4, completions=4, step=898 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0333333333333333e-06, 'num_tokens': 330372.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.236954212188721, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04496951219512195}\n",
            "prompts=4, completions=4, step=899 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.212977409362793, 'learning_rate': 1.0166666666666665e-06, 'num_tokens': 335796.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.917875289916992, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04573170731707317}\n",
            "prompts=4, completions=4, step=900 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-06, 'num_tokens': 341524.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.188811302185059, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04649390243902439}\n",
            "prompts=4, completions=4, step=901 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.833333333333332e-07, 'num_tokens': 347324.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.439057350158691, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04725609756097561}\n",
            "prompts=4, completions=4, step=902 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.075920104980469, 'learning_rate': 9.666666666666666e-07, 'num_tokens': 353212.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.195639133453369, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04801829268292683}\n",
            "prompts=4, completions=4, step=903 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.499999999999999e-07, 'num_tokens': 359052.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.736932754516602, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04878048780487805}\n",
            "prompts=4, completions=4, step=904 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 9.181028366088867, 'learning_rate': 9.333333333333333e-07, 'num_tokens': 365000.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.440458297729492, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.04954268292682927}\n",
            "prompts=4, completions=4, step=905 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.166666666666665e-07, 'num_tokens': 370480.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.126682281494141, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05030487804878049}\n",
            "prompts=4, completions=4, step=906 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9e-07, 'num_tokens': 376044.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.336808681488037, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051067073170731704}\n",
            "prompts=4, completions=4, step=907 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.833333333333333e-07, 'num_tokens': 381460.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.063048362731934, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.051829268292682924}\n",
            "prompts=4, completions=4, step=908 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.666666666666667e-07, 'num_tokens': 386932.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.213078498840332, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.052591463414634144}\n",
            "prompts=4, completions=4, step=909 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.499999999999999e-07, 'num_tokens': 392448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.627723693847656, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.053353658536585365}\n",
            "prompts=4, completions=4, step=910 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-07, 'num_tokens': 398040.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.234431266784668, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054115853658536585}\n",
            "prompts=4, completions=4, step=911 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.166666666666666e-07, 'num_tokens': 403648.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.882559299468994, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.054878048780487805}\n",
            "prompts=4, completions=4, step=912 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8e-07, 'num_tokens': 409532.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.188796043395996, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.055640243902439025}\n",
            "prompts=4, completions=4, step=913 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.833333333333333e-07, 'num_tokens': 415028.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.20738410949707, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.056402439024390245}\n",
            "prompts=4, completions=4, step=914 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.78861141204834, 'learning_rate': 7.666666666666667e-07, 'num_tokens': 420536.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.425098419189453, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057164634146341466}\n",
            "prompts=4, completions=4, step=915 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.79129409790039, 'learning_rate': 7.5e-07, 'num_tokens': 425908.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.759210586547852, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.057926829268292686}\n",
            "prompts=4, completions=4, step=916 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.333333333333332e-07, 'num_tokens': 431356.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.750491142272949, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0586890243902439}\n",
            "prompts=4, completions=4, step=917 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.166666666666667e-07, 'num_tokens': 436800.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.9425048828125, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.05945121951219512}\n",
            "prompts=4, completions=4, step=918 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7e-07, 'num_tokens': 442604.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.936655044555664, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06021341463414634}\n",
            "prompts=4, completions=4, step=919 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.833333333333333e-07, 'num_tokens': 448236.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.244966506958008, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06097560975609756}\n",
            "prompts=4, completions=4, step=920 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 14.53078556060791, 'learning_rate': 6.666666666666666e-07, 'num_tokens': 453600.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.502108097076416, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06173780487804878}\n",
            "prompts=4, completions=4, step=921 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.5e-07, 'num_tokens': 459420.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.246800899505615, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0625}\n",
            "prompts=4, completions=4, step=922 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 12.207539558410645, 'learning_rate': 6.333333333333332e-07, 'num_tokens': 464876.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.149813652038574, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06326219512195122}\n",
            "prompts=4, completions=4, step=923 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.166666666666667e-07, 'num_tokens': 470348.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.550384521484375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06402439024390244}\n",
            "prompts=4, completions=4, step=924 rewards (first 8) [0.02666666666666667, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.213741302490234, 'learning_rate': 6e-07, 'num_tokens': 476080.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 5.104542255401611, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06478658536585366}\n",
            "prompts=4, completions=4, step=925 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 18.837970733642578, 'learning_rate': 5.833333333333334e-07, 'num_tokens': 481616.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.708503723144531, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06554878048780488}\n",
            "prompts=4, completions=4, step=926 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.48367977142334, 'learning_rate': 5.666666666666666e-07, 'num_tokens': 487396.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.807876110076904, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0663109756097561}\n",
            "prompts=4, completions=4, step=927 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.5e-07, 'num_tokens': 492860.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.214003562927246, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06707317073170732}\n",
            "prompts=4, completions=4, step=928 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.784334182739258, 'learning_rate': 5.333333333333333e-07, 'num_tokens': 498436.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.044884204864502, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06783536585365854}\n",
            "prompts=4, completions=4, step=929 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 13.755399703979492, 'learning_rate': 5.166666666666667e-07, 'num_tokens': 504248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.495471477508545, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06859756097560976}\n",
            "prompts=4, completions=4, step=930 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-07, 'num_tokens': 509628.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.865235805511475, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.06935975609756098}\n",
            "prompts=4, completions=4, step=931 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.833333333333333e-07, 'num_tokens': 515132.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.849742412567139, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0701219512195122}\n",
            "prompts=4, completions=4, step=932 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.516129493713379, 'learning_rate': 4.6666666666666666e-07, 'num_tokens': 520916.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.670163631439209, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07088414634146341}\n",
            "prompts=4, completions=4, step=933 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 10.534736633300781, 'learning_rate': 4.5e-07, 'num_tokens': 526840.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.78830623626709, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07164634146341463}\n",
            "prompts=4, completions=4, step=934 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4.3333333333333335e-07, 'num_tokens': 532408.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.900445461273193, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07240853658536585}\n",
            "prompts=4, completions=4, step=935 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 8.382782936096191, 'learning_rate': 4.1666666666666667e-07, 'num_tokens': 537828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 5.128665447235107, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07317073170731707}\n",
            "prompts=4, completions=4, step=936 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 4e-07, 'num_tokens': 543332.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.252213954925537, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07393292682926829}\n",
            "prompts=4, completions=4, step=937 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.8333333333333335e-07, 'num_tokens': 548752.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.025906085968018, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07469512195121951}\n",
            "prompts=4, completions=4, step=938 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.666666666666666e-07, 'num_tokens': 554104.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.964370250701904, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07545731707317073}\n",
            "prompts=4, completions=4, step=939 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.5e-07, 'num_tokens': 559768.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.091647624969482, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07621951219512195}\n",
            "prompts=4, completions=4, step=940 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 19.58255386352539, 'learning_rate': 3.333333333333333e-07, 'num_tokens': 565268.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.604979991912842, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07698170731707317}\n",
            "prompts=4, completions=4, step=941 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 10.176321029663086, 'learning_rate': 3.166666666666666e-07, 'num_tokens': 571032.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.551649570465088, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07774390243902439}\n",
            "prompts=4, completions=4, step=942 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-07, 'num_tokens': 576868.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.9780683517456055, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07850609756097561}\n",
            "prompts=4, completions=4, step=943 rewards (first 8) [0.013333333333333334, 0.02666666666666667, 0.02666666666666667, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 15.332728385925293, 'learning_rate': 2.833333333333333e-07, 'num_tokens': 582624.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.019999999552965164, 'rewards/reward_group_adapter/std': 0.00769800366833806, 'reward': 0.019999999552965164, 'reward_std': 0.00769800366833806, 'frac_reward_zero_std': 0.0, 'entropy': 4.77529239654541, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.07926829268292683}\n",
            "prompts=4, completions=4, step=944 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 14.784608840942383, 'learning_rate': 2.6666666666666667e-07, 'num_tokens': 588448.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 3.9347450733184814, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08003048780487805}\n",
            "prompts=4, completions=4, step=945 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.396116256713867, 'learning_rate': 2.5e-07, 'num_tokens': 594036.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.817413806915283, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08079268292682927}\n",
            "prompts=4, completions=4, step=946 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.3333333333333333e-07, 'num_tokens': 599660.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.8997602462768555, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08155487804878049}\n",
            "prompts=4, completions=4, step=947 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 2.1666666666666667e-07, 'num_tokens': 605248.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.285569190979004, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08231707317073171}\n",
            "prompts=4, completions=4, step=948 rewards (first 8) [0.02666666666666667, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': -0.0, 'grad_norm': 11.136266708374023, 'learning_rate': 2e-07, 'num_tokens': 610652.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.992931842803955, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08307926829268293}\n",
            "prompts=4, completions=4, step=949 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.833333333333333e-07, 'num_tokens': 616204.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.360687255859375, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08384146341463415}\n",
            "prompts=4, completions=4, step=950 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666665e-07, 'num_tokens': 621828.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.461582183837891, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08460365853658537}\n",
            "prompts=4, completions=4, step=951 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.5e-07, 'num_tokens': 627692.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.7807769775390625, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08536585365853659}\n",
            "prompts=4, completions=4, step=952 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.02666666666666667]\n",
            "{'loss': -0.0, 'grad_norm': 11.911421775817871, 'learning_rate': 1.3333333333333334e-07, 'num_tokens': 633276.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.01666666567325592, 'rewards/reward_group_adapter/std': 0.006666666828095913, 'reward': 0.01666666567325592, 'reward_std': 0.006666666362434626, 'frac_reward_zero_std': 0.0, 'entropy': 4.589489936828613, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0861280487804878}\n",
            "prompts=4, completions=4, step=953 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.1666666666666667e-07, 'num_tokens': 638784.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.628847122192383, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08689024390243902}\n",
            "prompts=4, completions=4, step=954 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1e-07, 'num_tokens': 644400.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.4277729988098145, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08765243902439024}\n",
            "prompts=4, completions=4, step=955 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333333e-08, 'num_tokens': 649948.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.109251022338867, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08841463414634146}\n",
            "prompts=4, completions=4, step=956 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 6.666666666666667e-08, 'num_tokens': 655620.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.265737533569336, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.08917682926829268}\n",
            "prompts=4, completions=4, step=957 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-08, 'num_tokens': 661180.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.201376438140869, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.0899390243902439}\n",
            "prompts=4, completions=4, step=958 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3.3333333333333334e-08, 'num_tokens': 666676.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 4.902090549468994, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.09070121951219512}\n",
            "prompts=4, completions=4, step=959 rewards (first 8) [0.013333333333333334, 0.013333333333333334, 0.013333333333333334, 0.013333333333333334]\n",
            "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.6666666666666667e-08, 'num_tokens': 672168.0, 'completions/mean_length': 350.0, 'completions/min_length': 350.0, 'completions/max_length': 350.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_group_adapter/mean': 0.013333333656191826, 'rewards/reward_group_adapter/std': 0.0, 'reward': 0.013333333656191826, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'entropy': 5.097695350646973, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'epoch': 0.09146341463414634}\n",
            "{'train_runtime': 5561.5339, 'train_samples_per_second': 0.086, 'train_steps_per_second': 0.022, 'train_loss': -6.146658115824266e-08, 'epoch': 0.09146341463414634}\n",
            "---- Cycle 15: custom eval (subset=50, cap=300) ----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[custom-eval] trainer.generate: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [04:26<00:00, 38.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADELCOLOGIESINC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"1\", \"node_type\": \"CLAUSE\", \"title\": \"1\", \"level\": 1}, {\"id\": \"1.3\", \"node_type\": \"CLAUSE\", \"title\": \"1.3\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Products\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Products\"}, {\"id\": \"term:TERRITORY\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Territory\"}], \"edges\": [{\"src\": \"1.3\", \"tgt\": \"1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"1.3\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"1.3\", \"tgt\": \"term:Products\", \"type\": \"USES\"}, {\"src\": \"1.3\", \"tgt\": \"term:TERR\n",
            "in calc metrics on eval {\"contract_id\": \"NEOMIDADEL TECHNOLOGIES INC_12_15_2005-EX-16.1-DISTRIBUTOR AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"20.4\", \"node_type\": \"CLAUSE\", \"title\": \"20.4\", \"level\": 2}, {\"id\": \"party:Distributor\", \"node_type\": \"PARTY\", \"name\": \"Distributor\"}, {\"id\": \"party:Ppg Shanghai\", \"node_type\": \"PARTY\", \"name\": \"Ppg Shanghai\"}, {\"id\": \"term:Arbitration Committee\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Arbitration Committee\"}, {\"id\": \"value:ten (10) Days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"ten (10) Days\"}], \"edges\": [{\"src\": \"20.4\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"20.4\", \"tgt\": \"party:Distributor\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"party:Ppg Shanghai\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"20.4\", \"tgt\": \"term:Arbitration Committee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.16\", \"node_type\": \"CLAUSE\", \"title\": \"5.16\", \"level\": 2}, {\"id\": \"5.16.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.16.2\", \"level\": 3}, {\"id\": \"party:Burger King\", \"node_type\": \"PARTY\", \"name\": \"Burger King\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Approved Suppliers And/Or Distributors\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Approved Suppliers And/Or Distributors\"}, {\"id\": \"term:Frischased Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischased Restaurant\"}], \"edges\": [{\"src\": \"5.16.2\", \"tgt\": \"5.16\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.16.2\", \"tgt\": \"party:Burger King\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.16.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"19\", \"node_type\": \"CLAUSE\", \"title\": \"19\", \"level\": 1}, {\"id\": \"19.6\", \"node_type\": \"CLAUSE\", \"title\": \"19.6\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}], \"edges\": [{\"src\": \"19.6\", \"tgt\": \"17.2\", \"type\": \"REFERENCES\"}, {\"src\": \"19.6\", \"tgt\": \"19\", \"type\": \"IS_PART_OF\"}, {\"src\": \"19.6\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"19.6\",\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.1\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.1\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"party:Franchisor\", \"node_type\": \"PARTY\", \"name\": \"Franchisor\"}, {\"id\": \"term:Current Image\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Current Image\"}], \"edges\": [{\"src\": \"5.3.1\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.1\", \"tgt\": \"party:Franch\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"5.3\", \"node_type\": \"CLAUSE\", \"title\": \"5.3\", \"level\": 2}, {\"id\": \"5.3.2\", \"node_type\": \"CLAUSE\", \"title\": \"5.3.2\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Frischised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Frischised Restaurant\"}, {\"id\": \"term:Term\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Term\"}], \"edges\": [{\"src\": \"5.3.2\", \"tgt\": \"5.3\", \"type\": \"IS_PART_OF\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"5.3.2\", \"tgt\": \"party:Franchisee\", \"type\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"11.1\", \"node_type\": \"CLAUSE\", \"title\": \"11.1\", \"level\": 2}, {\"id\": \"11.1.8\", \"node_type\": \"CLAUSE\", \"title\": \"11.1.8\", \"level\": 3}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Burger King Marks\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Burger King Marks\"}, {\"id\": \"term:Exhibit A\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Exhibit A\"}], \"edges\": [{\"src\": \"11.1.8\", \"tgt\": \"11.1\", \"type\": \"IS_PART_OF\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"11.1.8\", \"tgt\": \"term\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"20\", \"node_type\": \"CLAUSE\", \"title\": \"20\", \"level\": 1}, {\"id\": \"34\", \"node_type\": \"CLAUSE\", \"title\": \"34\", \"level\": 0}, {\"id\": \"party:Parties\", \"node_type\": \"PARTY\", \"name\": \"Parties\"}, {\"id\": \"term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"term:Development Or Target Reservation Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Development Or Target Reservation Agreement\"}, {\"id\": \"term:Franchised Restaurant\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Franchised Restaurant\"}], \"edges\": [{\"src\": \"34\", \"tgt\": \"20\", \"type\": \"IS_PART_OF\"}, {\"src\": \"34\", \"tgt\": \"party:Parties\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"34\", \"tgt\": \"term:Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Development Or Target Reservation Agreement\", \"type\": \"USES\"}, {\"src\": \"34\", \"tgt\": \"term:Franchised Restaurant\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15.5.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2\", \"level\": 3}, {\"id\": \"15.5.2.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.5.2.2\", \"level\": 4}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Franchisee\", \"node_type\": \"PARTY\", \"name\": \"Franchisee\"}, {\"id\": \"term:Securities Exchange Act Of 1934\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Securities Exchange Act Of 1934\"}], \"edges\": [{\"src\": \"15.5.2.2\", \"tgt\": \"15.5.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"party:Franchisee\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.5.2.2\", \"tgt\": \"\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"17.2\", \"node_type\": \"CLAUSE\", \"title\": \"17.2\", \"level\": 2}, {\"id\": \"17.2.1\", \"node_type\": \"CLAUSE\", \"title\": \"17.2.1\", \"level\": 3}, {\"id\": \"defined_term:Event Of Bkc Default\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Event Of Bkc Default\"}, {\"id\": \"defined_term:Bkc\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Bkc\"}, {\"id\": \"defined_term:Agreement\", \"node_type\": \"DEFINED_TERM\", \"name\": \"Agreement\"}, {\"id\": \"value:sixty (60) days\", \"node_type\": \"VALUE\", \"unit\": \"Days\", \"text\": \"sixty (60) days\"}], \"edges\": [{\"src\": \"17.2.1\", \"tgt\": \"17.2\", \"type\": \"IS_PART_OF\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Event Of Bkc Default\", \"type\": \"DEFINES\"}, {\"src\": \"17.2.1\", \"tgt\": \"defined_term:Bkc\", \"type\": \"USES\"}, {\"src\":\n",
            "in calc metrics on eval {\"contract_id\": \"INTERNATIONALFASTFOODCORP_04_04_1997-EX-99-FRANCHISE AGREEMENT\", \"nodes\": [{\"id\": \"15\", \"node_type\": \"CLAUSE\", \"title\": \"15\", \"level\": 1}, {\"id\": \"15.1\", \"node_type\": \"CLAUSE\", \"title\": \"15.1\", \"level\": 2}, {\"id\": \"15.2\", \"node_type\": \"CLAUSE\", \"title\": \"15.2\", \"level\": 2}, {\"id\": \"15.3\", \"node_type\": \"CLAUSE\", \"title\": \"15.3\", \"level\": 2}, {\"id\": \"party:BKC\", \"node_type\": \"PARTY\", \"name\": \"BKC\"}, {\"id\": \"party:Transferor\", \"node_type\": \"PARTY\", \"name\": \"Transferor\"}], \"edges\": [{\"src\": \"15.3\", \"tgt\": \"15\", \"type\": \"IS_PART_OF\"}, {\"src\": \"15.3\", \"tgt\": \"15.1\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"15.2\", \"type\": \"REFERENCES\"}, {\"src\": \"15.3\", \"tgt\": \"party:BKC\", \"type\": \"MENTIONS_PARTY\"}, {\"src\": \"15.3\", \"\n",
            "out logged metrics: {'eval_strict_node_precision': 0.8611111111111112, 'eval_strict_node_recall': 0.5102880658436214, 'eval_strict_node_f1': 0.640826873385013, 'eval_fuzzy_node_precision': 0.875, 'eval_fuzzy_node_recall': 0.5185185185185185, 'eval_fuzzy_node_f1': 0.6511627906976744, 'eval_edge_precision': 0.7523809523809524, 'eval_edge_recall': 0.41578947368421054, 'eval_edge_f1': 0.535593220338983, 'eval_exact_graph_match_rate': 0.24, 'eval_invalid_json_rate': 0.22}\n",
            "printing metrics <class 'dict'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 9 Execute Full Training with eval cycles\n",
        "\n",
        "train_eval_cycles(\n",
        "    trainer,\n",
        "    cycles=15,\n",
        "    steps_per_cycle=8,\n",
        "    eval_ds_small=eval_ds_small,\n",
        "    num_samples_small=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00c3b95b-2d33-4ba5-878f-f789ac15d96f",
      "metadata": {
        "id": "00c3b95b-2d33-4ba5-878f-f789ac15d96f"
      },
      "outputs": [],
      "source": [
        "#@title Cell 10 Training Checkpointing - Save model and adapter\n",
        "\n",
        "#base model with merged LoRA adapters\n",
        "output_dir = \"./checkpoints/grpo_final_embed_stopper_gated_final\"\n",
        "\n",
        "#save adapter\n",
        "if hasattr(model, \"save_pretrained\"):\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "#save QLoRA weights\n",
        "if hasattr(model, \"peft_config\"):\n",
        "    model.save_pretrained(output_dir, save_embedding_layers=True)\n",
        "\n",
        "#save trainer\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "model.save_pretrained(\"./adapters\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37e17380-ac4c-48f4-95ce-8079c559e3e7",
      "metadata": {
        "id": "37e17380-ac4c-48f4-95ce-8079c559e3e7"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (llm)",
      "language": "python",
      "name": "llm"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}